:_content-type: PROCEDURE
[id="backing-up-red-hat-quay-operator"]
= Backing up {productname}

Database backups should be performed regularly using either the supplied tools on the PostgreSQL image or your own backup infrastructure. The {productname} Operator does not currently ensure that the PostgreSQL database is backed up.

[NOTE]
====
This procedure covers backing up your {productname} PostgreSQL database. It does not cover backing up the Clair PostgreSQL database. Strictly speaking, backing up the Clair PostgreSQL database is not needed because it can be recreated. If you opt to recreate it from scratch, you will wait for the information to be repopulated after all images inside of your {productname} deployment are scanned. During this downtime, security reports are unavailable. 

If you are considering backing up the Clair PostgreSQL database, you must consider that its size is dependent upon the number of images stored inside of {productname}. As a result, the database can be extremely large. 
====

This procedure describes how to create a backup of {productname} deployed on {ocp} using the {productname} Operator. 

.Prerequisites

* A healthy {productname} deployment on {ocp} using the {productname} Operator. The status condition `Available` is set to `true`.
* The components `quay`, `postgres` and `objectstorage` are set to `managed: true`
* If the component `clair` is set to `managed: true` the component `clairpostgres` is also set to `managed: true` (starting with {productname} Operator v3.7 or later)

[NOTE]
====
If your deployment contains partially unmanaged database or storage components and you are using external services for PostgreSQL or S3-compatible object storage to run your {productname} deployment, you must refer to the service provider or vendor documentation to create a backup of the data.
You can refer to the tools described in this guide as a starting point on how to backup your external PostgreSQL database or object storage.
====

[id="quay-configuration-backup"]
== {productname} configuration backup

Use the following procedure to back up your {productname} configuration. 

.Procedure

. To back the `QuayRegistry` custom resource by exporting it, enter the following command:
+
[source,terminal]
----
$ oc get quayregistry <quay_registry_name> -n <quay_namespace> -o yaml > quay-registry.yaml
----

. Edit the resulting `quayregistry.yaml` and remove the status section and the following metadata fields:
+
[source,yaml]
----
  metadata.creationTimestamp
  metadata.finalizers
  metadata.generation
  metadata.resourceVersion
  metadata.uid
----

. Backup the managed keys secret by entering the following command:
+
[NOTE]
====
If you are running a version older than {productname} 3.7.0, this step can be skipped. Some secrets are automatically generated while deploying {productname} for the first time. These are stored in a secret called `<quay_registry_name>-quay_registry_managed_secret_keys` in the namespace of the `QuayRegistry` resource.
====
+
[source,terminal]
----
$ oc get secret -n <quay_namespace> <quay_registry_name>_quay_registry_managed_secret_keys -o yaml > managed_secret_keys.yaml
----

. Edit the resulting `managed_secret_keys.yaml` file and remove the entry `metadata.ownerReferences`. Your `managed_secret_keys.yaml` file should look similar to the following:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: <quayname>_quay_registry_managed_secret_keys>
  namespace: <quay_namespace>
data:
  CONFIG_EDITOR_PW: <redacted>
  DATABASE_SECRET_KEY: <redacted>
  DB_ROOT_PW: <redacted>
  DB_URI: <redacted>
  SECRET_KEY: <redacted>
  SECURITY_SCANNER_V4_PSK: <redacted>
----
+
All information under the `data` property should remain the same.

. Redirect the current `Quay` configuration file by entering the following command:
+
[source,terminal]
----
$ oc get secret -n <quay-namespace>  $(oc get quayregistry <quay_registry_name> -n <quay_namespace>  -o jsonpath='{.spec.configBundleSecret}') -o yaml > config-bundle.yaml
----

. Backup the `/conf/stack/config.yaml` file mounted inside of the `Quay` pods:
+
[source,terminal]
----
$ oc exec -it quay_pod_name -- cat /conf/stack/config.yaml > quay_config.yaml
----

[id="scaling-down-quay-deployment"]
== Scaling down your {productname} deployment

Use the following procedure to scale down your {productname} deployment. 

[IMPORTANT]
====
This step is needed to create a consistent backup of the state of your {productname} deployment. Do not omit this step, including in setups where PostgreSQL databases and/or S3-compatible object storage are provided by external services (unmanaged by the {productname} Operator).
====

.Procedure

. Depending on the version of your {productname} deployment, scale down your deployment using one of the following options. 

.. *For Operator version 3.7 and newer:* Scale down the {productname} deployment by disabling auto scaling and overriding the replica count for {productname}, mirror workers, and Clair (if managed). Your `QuayRegistry` resource should look similar to the following:
+
[source,yaml]
----
apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: registry
  namespace: ns
spec:
  components:
    …
    - kind: horizontalpodautoscaler
      managed: false <1>
    - kind: quay
      managed: true
      overrides: <2>
        replicas: 0
    - kind: clair
      managed: true
      overrides:
        replicas: 0
    - kind: mirror
      managed: true
      overrides:
        replicas: 0
    …
----
<1> Disable auto scaling of Quay, Clair and Mirroring workers
<2> Set the replica count to 0 for components accessing the database and objectstorage

.. *For Operator version 3.6 and earlier*: Scale down the {productname} deployment by scaling down the {productname} Operator first and then the managed {productname} resources:
+
[source,terminal]
----
$ oc scale --replicas=0 deployment $(oc get deployment -n <quay-operator-namespace>|awk '/^quay-operator/ {print $1}') -n <quay-operator-namespace>
----
+
[source,terminal]
----
$ oc scale --replicas=0 deployment $(oc get deployment -n <quay-namespace>|awk '/quay-app/ {print $1}') -n <quay-namespace>
----
+
[source,terminal]
----
$ oc scale --replicas=0 deployment $(oc get deployment -n <quay-namespace>|awk '/quay-mirror/ {print $1}') -n <quay-namespace>
----
+
[source,terminal]
----
$ oc scale --replicas=0 deployment $(oc get deployment -n <quay-namespace>|awk '/clair-app/ {print $1}') -n <quay-namespace>
----

. Wait for the `registry-quay-app`, `registry-quay-mirror` and `registry-clair-app` pods (depending on which components you set to be managed by the {productname} Operator) to disappear. You can check their status by running the following command:
+
[source,terminal]
----
$ oc get pods -n <quay_namespace>
----
+
Example output:
+
[source,terminal]
----
$ oc get pod
----
+
.Example output
+
[source,terminal]
----
quay-operator.v3.7.1-6f9d859bd-p5ftc               1/1     Running     0             12m
quayregistry-clair-postgres-7487f5bd86-xnxpr       1/1     Running     1 (12m ago)   12m
quayregistry-quay-app-upgrade-xq2v6                0/1     Completed   0             12m
quayregistry-quay-config-editor-6dfdcfc44f-hlvwm   1/1     Running     0             73s
quayregistry-quay-database-859d5445ff-cqthr        1/1     Running     0             12m
quayregistry-quay-redis-84f888776f-hhgms           1/1     Running     0             12m
----

[id="backing-up-managed-database"]
== Backing up the {productname} managed database

Use the following procedure to back up the {productname} managed database. 

[NOTE]
====
If your {productname} deployment is configured with external, or unmanged, PostgreSQL database(s), refer to your vendor's documentation on how to create a consistent backup of these databases.
====

.Procedure

. Identify the Quay PostgreSQL pod name:
+
[source,terminal]
----
$ oc get pod -l quay-component=postgres -n <quay_namespace> -o jsonpath='{.items[0].metadata.name}'
----
+
Example output:
+
[source,terminal]
----
quayregistry-quay-database-59f54bb7-58xs7
----

. Obtain the Quay database name:
+
[source,terminal]
----
$ oc -n <quay_namespace> rsh $(oc get pod -l app=quay -o NAME -n <quay_namespace> |head -n 1) cat /conf/stack/config.yaml|awk -F"/" '/^DB_URI/ {print $4}'
quayregistry-quay-database
----

. Download a backup database:
+
[source,terminal]
----
$ oc exec quayregistry-quay-database-59f54bb7-58xs7 -- /usr/bin/pg_dump -C quayregistry-quay-database  > backup.sql
----

[id="backing-up-managed-object-storage"]
=== Backing up the {productname} managed object storage

Use the following procedure to back up the {productname} managed object storage. The instructions in this section apply to the following configurations:

* Standalone, multi-cloud object gateway configurations
* OpenShift Data Foundations storage requires that the {productname} Operator provisioned an S3 object storage bucket from, through the ObjectStorageBucketClaim API

[NOTE]
====
If your {productname} deployment is configured with external (unmanged) object storage, refer to your vendor's documentation on how to create a copy of the content of Quay's storage bucket.
====

.Procedure

. Decode and export the `AWS_ACCESS_KEY_ID` by entering the following command:
+
[source,terminal]
----
$ export AWS_ACCESS_KEY_ID=$(oc get secret -l app=noobaa -n <quay-namespace>  -o jsonpath='{.items[0].data.AWS_ACCESS_KEY_ID}' |base64 -d)
----

. Decode and export the `AWS_SECRET_ACCESS_KEY_ID` by entering the following command:
+
[source,terminal]
----
$ export AWS_SECRET_ACCESS_KEY=$(oc get secret -l app=noobaa -n <quay-namespace> -o jsonpath='{.items[0].data.AWS_SECRET_ACCESS_KEY}' |base64 -d)
----

. Create a new directory:
+
[source,terminal]
----
$ mkdir blobs
----

[NOTE]
====
You can also use link:https://rclone.org/[rclone] or link:https://s3tools.org/s3cmd[sc3md] instead of the AWS command line utility.
====

. Copy all blobs to the directory by entering the following command:
+
[source,terminal]
----
$ aws s3 sync --no-verify-ssl --endpoint https://$(oc get route s3 -n openshift-storage  -o jsonpath='{.spec.host}')  s3://$(oc get cm -l app=noobaa -n <quay-namespace> -o jsonpath='{.items[0].data.BUCKET_NAME}') ./blobs
----

[id="scaling-up-quay-deployment"]
== Scale the {productname} deployment back up

. Depending on the version of your {productname} deployment, scale up your deployment using one of the following options. 

.. *For Operator version 3.7 and newer:* Scale up the {productname} deployment by re-enabling auto scaling, if desired, and removing the replica overrides for Quay, mirror workers and Clair as applicable. Your `QuayRegistry` resource should look similar to the following:
+
[source,yaml]
----
apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: registry
  namespace: ns
spec:
  components:
    …
    - kind: horizontalpodautoscaler
      managed: true <1>
    - kind: quay <2>
      managed: true
    - kind: clair
      managed: true
    - kind: mirror
      managed: true
    …
----
<1> Re-enables auto scaling of Quay, Clair and Mirroring workers again (if desired)
<2> Replica overrides are removed again to scale the Quay components back up

.. *For Operator version 3.6 and earlier:* Scale up the {productname} deployment by scaling up the {productname} Operator again:
+
[source,terminal]
----
$ oc scale --replicas=1 deployment $(oc get deployment -n <quay_operator_namespace> | awk '/^quay-operator/ {print $1}') -n <quay_operator_namespace>
----

. Check the status of the {productname} deployment by entering the following command:
+
[source,terminal]
----
$ oc wait quayregistry registry --for=condition=Available=true -n <quay_namespace>
----
+
Example output:
+
[source,yaml]
----
apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  ...
  name: registry
  namespace: <quay-namespace>
  ...
spec:
  ...
status:
  - lastTransitionTime: '2022-06-20T05:31:17Z'
    lastUpdateTime: '2022-06-20T17:31:13Z'
    message: All components reporting as healthy
    reason: HealthChecksPassing
    status: 'True'
    type: Available
----
