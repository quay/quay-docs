:_content-type: CONCEPT
[id="build-support"]
= Automatically building Dockerfiles with Build workers

{productname} supports building Dockerfiles using a set of worker nodes on {ocp} or Kubernetes. Build triggers, such as GitHub webhooks, can be configured to automatically build new versions of your repositories when new code is committed. 

This document shows you how to enable Builds with your {productname}
installation, and set up one more more {ocp} or Kubernetes clusters to accept Builds from {productname}.

[id="setting-up-builders"]
== Setting up {productname} Builders with {ocp}

You must pre-configure {productname} Builders prior to using it with {ocp}. 

[id="configuring-openshift-tls-component"]
=== Configuring the {ocp} TLS component

The `tls` component allows you to control TLS configuration.

[NOTE]
====
{productname} does not support Builders when the TLS component is managed by the {productname} Operator.
====

If you set `tls` to `unmanaged`, you supply your own `ssl.cert` and `ssl.key` files. In this instance, if you want your cluster to support Builders, you must add both the `Quay` route and the Builder route name to the SAN list in the certificate; alternatively you can use a wildcard.

To add the builder route, use the following format:

[source,bash]
----
[quayregistry-cr-name]-quay-builder-[ocp-namespace].[ocp-domain-name]
----

[id="prepare-ocp-for-quay-builds"]
=== Preparing {ocp} for {productname} Builders

Prepare {productname} Builders for {ocp} by using the following procedure. 

.Prerequisites 

* You have configured the {ocp} TLS component. 

.Procedure 

. Enter the following command to create a project where Builds will be run, for example, `builder`:
+
[source,terminal]
----
$ oc new-project builder
----

. Create a new `ServiceAccount` in the the `builder` namespace by entering the following command:
+
[source,terminal]
----
$ oc create sa -n builder quay-builder
----

. Enter the following command to grant a user the `edit` role within the `builder` namespace:
+
[source,terminal]
----
$ oc policy add-role-to-user -n builder edit system:serviceaccount:builder:quay-builder
----

. Enter the following command to retrieve a token associated with the `quay-builder` service account in the `builder` namespace. This token is used to authenticate and interact with the {ocp} cluster's API server.
+
[source,terminal]
----
$ oc sa get-token -n builder quay-builder
----
+
. Identify the URL for the {ocp} cluster's API server. This can be found in the {ocp} Web Console.

. Identify a worker node label to be used when schedule Build `jobs`. Because Build pods need to run on bare metal worker nodes, typically these are identified with specific labels.
+
Check with your cluster administrator to determine exactly which node label should be used. 

. Optional. If the cluster is using a self-signed certificate, you must get the Kube API Server's certificate authority (CA) to add to {productname}'s extra certificates. 

.. Enter the following command to obtain the name of the secret containing the CA:
+
[source,terminal]
----
$ oc get sa openshift-apiserver-sa --namespace=openshift-apiserver -o json | jq '.secrets[] | select(.name | contains("openshift-apiserver-sa-token"))'.name
----

.. Obtain the `ca.crt` key value from the secret in the {ocp} Web Console. The value begins with *"-----BEGIN CERTIFICATE-----"`*. 

.. Import the CA to {productname}. Ensure that the name of this file matches `K8S_API_TLS_CA`. 

. Create the following `SecurityContextConstraints` resource for the `ServiceAccount`:
+
[source,yaml]
----
apiVersion: security.openshift.io/v1
kind: SecurityContextConstraints
metadata:
  name: quay-builder
priority: null
readOnlyRootFilesystem: false
requiredDropCapabilities: null
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
seccompProfiles:
- '*'
supplementalGroups:
  type: RunAsAny
volumes:
- '*'
allowHostDirVolumePlugin: true
allowHostIPC: true
allowHostNetwork: true
allowHostPID: true
allowHostPorts: true
allowPrivilegeEscalation: true
allowPrivilegedContainer: true
allowedCapabilities:
- '*'
allowedUnsafeSysctls:
- '*'
defaultAddCapabilities: null
fsGroup:
  type: RunAsAny
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: quay-builder-scc
  namespace: builder
rules:
- apiGroups:
  - security.openshift.io
  resourceNames:
  - quay-builder
  resources:
  - securitycontextconstraints
  verbs:
  - use
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: quay-builder-scc
  namespace: builder
subjects:
- kind: ServiceAccount
  name: quay-builder
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: quay-builder-scc
----

[id="enabling-builds-add-build-config-to-quay-bundle"]
=== Configuring {productname} Builders

Use the following procedure to enable {productname} Builders. 

.Procedure 

. Ensure that your {productname} `config.yaml` file has Builds enabled, for example:
+
[source,yaml]
----
FEATURE_BUILD_SUPPORT: True
----

. Add the following information to your {productname} `config.yaml` file, replacing each value with information that is relevant to your specific installation:
+
[source,yaml]
----
BUILD_MANAGER:
- ephemeral
- ALLOWED_WORKER_COUNT: 1
  ORCHESTRATOR_PREFIX: buildman/production/
  ORCHESTRATOR:
    REDIS_HOST: quay-redis-host
    REDIS_PASSWORD: quay-redis-password
    REDIS_SSL: true
    REDIS_SKIP_KEYSPACE_EVENT_SETUP: false
  EXECUTORS:
  - EXECUTOR: kubernetes
    BUILDER_NAMESPACE: builder
    K8S_API_SERVER: api.openshift.somehost.org:6443
    K8S_API_TLS_CA: /conf/stack/extra_ca_certs/build_cluster.crt
    VOLUME_SIZE: 8G
    KUBERNETES_DISTRIBUTION: openshift
    CONTAINER_MEMORY_LIMITS: 1G
    CONTAINER_CPU_LIMITS: 300m
    CONTAINER_MEMORY_REQUEST: 1G
    CONTAINER_CPU_REQUEST: 300m
    NODE_SELECTOR_LABEL_KEY: beta.kubernetes.io/instance-type
    NODE_SELECTOR_LABEL_VALUE: n1-standard-4
    CONTAINER_RUNTIME: podman
    SERVICE_ACCOUNT_NAME: *****
    SERVICE_ACCOUNT_TOKEN: *****
    QUAY_USERNAME: quay-username
    QUAY_PASSWORD: quay-password
    WORKER_IMAGE: <registry>/quay-quay-builder
    WORKER_TAG: some_tag
    BUILDER_VM_CONTAINER_IMAGE: <registry>/quay-quay-builder-qemu-rhcos:v3.4.0
    SETUP_TIME: 180
    MINIMUM_RETRY_THRESHOLD: 0
    SSH_AUTHORIZED_KEYS:
    - ssh-rsa 12345 someuser@email.com
    - ssh-rsa 67890 someuser2@email.com
----
+
For more information about each configuration field, see 

////
Each configuration field is explained below.

ALLOWED_WORKER_COUNT:: Defines how many Build Workers are instantiated per {productname} Pod.  Typically this is ‘1’.
ORCHESTRATOR_PREFIX:: Defines a unique prefix to be added to all Redis keys (useful to isolate Orchestrator values from other Redis keys).
REDIS_HOST:: Hostname for your Redis service.
REDIS_PASSWORD:: Password to authenticate into your Redis service.
REDIS_SSL:: Defines whether or not your Redis connection uses SSL.
REDIS_SKIP_KEYSPACE_EVENT_SETUP:: By default, {productname} does not set up the keyspace events required for key events at runtime. To do so, set REDIS_SKIP_KEYSPACE_EVENT_SETUP to `false`.
EXECUTOR:: Starts a definition of an Executor of this type.  Valid values are ‘kubernetes’ and ‘ec2’
BUILDER_NAMESPACE:: Kubernetes namespace where {productname} builds will take place
K8S_API_SERVER:: Hostname for API Server of OpenShift cluster where builds will take place
K8S_API_TLS_CA:: The filepath in the `Quay` container of the build cluster's CA certificate for the Quay app to trust when making API calls.
KUBERNETES_DISTRIBUTION:: Indicates which type of Kubernetes is being used.  Valid values are ‘openshift’ and ‘k8s’.
CONTAINER_*:: Define the resource requests and limits for each build pod.
NODE_SELECTOR_*:: Defines the node selector label name/value pair where build Pods should be scheduled.
CONTAINER_RUNTIME:: Specifies whether the builder should run `docker` or `podman`.  Customers using Red Hat’s `quay-builder` image should set this to `podman`.
SERVICE_ACCOUNT_NAME/SERVICE_ACCOUNT_TOKEN:: Defines the Service Account name/token that will be used by build Pods.
QUAY_USERNAME/QUAY_PASSWORD:: Defines the registry credentials needed to pull the {productname} build worker image that is specified in the WORKER_IMAGE field.
ifdef::upstream[]
This is useful if pulling a non-public quay-builder image from quay.io.
endif::upstream[]
ifdef::downstream[]
Customers should provide a Red Hat Service Account credential as defined in the section "Creating Registry Service Accounts" against registry.redhat.io in the article at https://access.redhat.com/RegistryAuthentication.
endif::downstream[]
WORKER_IMAGE:: Image reference for the {productname} builder image.
ifdef::upstream[]
quay.io/quay/quay-builder
endif::upstream[]
ifdef::downstream[]
registry.redhat.io/quay/quay-builder
endif::downstream[]
WORKER_TAG:: Tag for the builder image desired.
ifdef::upstream[]
Typically this is latest.
endif::upstream[]
ifdef::downstream[]
The latest version is v3.4.0.
endif::downstream[]
BUILDER_VM_CONTAINER_IMAGE:: The full reference to the container image holding the internal VM needed to run each {productname} build
ifdef::upstream[]
(`quay.io/quay/quay-builder-qemu-fedoracoreos:latest`).
endif::upstream[]
ifdef::downstream[]
(`registry.redhat.io/quay/quay-builder-qemu-rhcos:v3.4.0`).
endif::downstream[]
SETUP_TIME:: Specifies the number of seconds at which a build times out if it has not yet registered itself with the Build Manager (default is 500 seconds).  Builds that time out are attempted to be restarted three times.  If the build does not register itself after three attempts it is considered failed.
MINIMUM_RETRY_THRESHOLD:: This setting is used with multiple Executors; it indicates how many retries are attempted to start a build before a different Executor is chosen.  Setting to 0 means there are no restrictions on how many tries the build job needs to have.  This value should be kept intentionally small (three or less) to ensure failovers happen quickly in the event of infrastructure failures. You must specify a value for this setting.
E.g Kubernetes is set as the first executor and EC2 as the second executor. If we want the last attempt to run a job to always be executed on EC2 and not Kubernetes, we would set the Kubernetes executor’s `MINIMUM_RETRY_THRESHOLD` to 1 and EC2’s `MINIMUM_RETRY_THRESHOLD` to 0 (defaults to 0 if not set).
In this case, kubernetes’ `MINIMUM_RETRY_THRESHOLD` > retries_remaining(1) would evaluate to False, thus falling back to the second executor configured
SSH_AUTHORIZED_KEYS:: List of ssh keys to bootstrap in the ignition config. This allows other keys to be used to ssh into the EC2 instance or QEMU VM
////

ifdef::upstream[]
[id="setting-up-builds-aws"]
== {productname} Builder configuration with Amazon Elastic Compute Cloud

{productname} can also be configured to use Amazon Elastic Compute Cloud (EC2) instances as Build worker nodes. This is useful for situations where you might want to have EC2 based Builds available as a backup solution in the event that your {ocp} Build workers are overloaded or unavailable.

[NOTE]
====
Amazon EC2 Builds are not supported by Red Hat. This is currently provided as an upstream feature only.
====

You can follow the steps in "Preparing {ocp} for {productname} Builders" and substitute the following changes in your configuration bundle to enable Amazon EC2. 

[source,yaml]
----
  EXECUTORS:
    - EXECUTOR: ec2
      QUAY_USERNAME: <quay_username>
      QUAY_PASSWORD: <quay_pass>
      WORKER_IMAGE: quay.io/quay/quay-builder
      WORKER_TAG: latest
      EC2_REGION: us-east-1
      COREOS_AMI: ami-02545325b519192df # Fedora CoreOS <1>
      AWS_ACCESS_KEY: *****
      AWS_SECRET_KEY: *****
      EC2_INSTANCE_TYPE: t2.large
      EC2_VPC_SUBNET_ID: <some_subnet>
      EC2_SECURITY_GROUP_IDS:
      - sg-somesg
      EC2_KEY_NAME: <some_key>
      BLOCK_DEVICE_SIZE: 58
      SSH_AUTHORIZED_KEYS:
      - ssh-rsa 12345 user1@email.com
      - ssh-rsa 67890 user2@email.com
----
<1> Specifies an AMI name where Builds will be run. Unlike the {ocp} based Builds, these container Builds are done directly within an ephemeral EC2 instance. This AMI must utilize ignition and contain a docker. The AMI shown in this example is used by {quay.io} for its build system.
endif::upstream[]

[id="openshift-routes-limitations"]
== {ocp} _Routes_ limitations

The following limitations apply when you are using the {productname} Operator on {ocp} with a managed `route` component:

* Currently, {ocp} _Routes_ are only able to serve traffic to a single port. Additional steps are required to set up {productname} Builds. 

* Ensure that your `kubectl` or `oc` CLI tool is configured to work with the cluster where the {productname} Operator is installed and that your `QuayRegistry` exists; the `QuayRegistry` does not have to be on the same bare metal cluster where _Builders_ run. 

* Ensure that HTTP/2 ingress is enabled on the OpenShift cluster by following link:https://docs.openshift.com/container-platform/{ocp-y}/networking/ingress-operator.html#nw-http2-haproxy_configuring-ingress[these steps].

* The {productname} Operator creates a `Route` resource that directs gRPC traffic to the Build manager server running inside of the existing `Quay` pod, or pods. If you want to use a custom hostname, or a subdomain like `<builder-registry.example.com>`, ensure that you create a CNAME record with your DNS provider that points to the `status.ingress[0].host` of the create `Route` resource. For example:
+
----
$ kubectl get -n <namespace> route <quayregistry-name>-quay-builder -o jsonpath={.status.ingress[0].host}
----

* Using the {ocp} UI or CLI, update the `Secret` referenced by `spec.configBundleSecret` of the `QuayRegistry` with the Build cluster CA certificate. Name the key `extra_ca_cert_build_cluster.cert`. Update the `config.yaml` file entry with the correct values referenced in the Builder configuration that you created when you configured {productname} Builders, and add the `BUILDMAN_HOSTNAME` CONFIGURATION FIELD:
+
[source,yaml]
----
BUILDMAN_HOSTNAME: <build-manager-hostname> <1>
BUILD_MANAGER:
- ephemeral
- ALLOWED_WORKER_COUNT: 1
  ORCHESTRATOR_PREFIX: buildman/production/
  JOB_REGISTRATION_TIMEOUT: 600
  ORCHESTRATOR:
    REDIS_HOST: <quay_redis_host
    REDIS_PASSWORD: <quay_redis_password>
    REDIS_SSL: true
    REDIS_SKIP_KEYSPACE_EVENT_SETUP: false
  EXECUTORS:
  - EXECUTOR: kubernetes
    BUILDER_NAMESPACE: builder
    ...
----
<1> The externally accessible server hostname which the build jobs use to communicate back to the Build manager. Default is the same as `SERVER_HOSTNAME`. For OpenShift `Route`, it is either `status.ingress[0].host` or the CNAME entry if using a custom hostname. `BUILDMAN_HOSTNAME` must include the port number, for example, `somehost:443` for an {ocp} Route, as the gRPC client used to communicate with the build manager does not infer any port if omitted.

[id="troubleshooting-builds"]
== Troubleshooting Builds

The _Builder_ instances started by the Build manager are ephemeral. This means that they will either get shut down by {productname} on timeouts or failure, or garbage collected by the control plane (EC2/K8s). In order to obtain the Build logs, you must do so while the Builds are running.

[id="debug-config-flag"]
=== DEBUG config flag

The `DEBUG` flag can be set to `true` in order to prevent the Builder instances from getting cleaned up after completion or failure. For example:

[source,yaml]
----
  EXECUTORS:
    - EXECUTOR: ec2
      DEBUG: true
      ...
    - EXECUTOR: kubernetes
      DEBUG: true
      ...
----

When set to `true`, the debug feature prevents the Build nodes from shutting down after the `quay-builder` service is done or fails. It also prevents the Build manager from cleaning up the instances by terminating EC2 instances or deleting Kubernetes jobs. This allows debugging Builder node issues. 

Debugging should not be set in a production cycle. The lifetime service still exists; for example, the instance still shuts down after approximately two hours. When this happens, EC2 instances are terminated, and Kubernetes jobs are completed. 

Enabling debug also affects the `ALLOWED_WORKER_COUNT`, because the unterminated instances and jobs still count toward the total number of running workers. As a result, the existing Builder workers must be manually deleted if `ALLOWED_WORKER_COUNT` is reached to be able to schedule new Builds. 

Setting DEBUG will also affect `ALLOWED_WORKER_COUNT`, as the unterminated instances/jobs will still count towards the total number of running workers. This means the existing builder workers will need to manually be deleted if `ALLOWED_WORKER_COUNT` is reached to be able to schedule new Builds.

ifdef::upstream[]
[id="troubleshooting-amazon-ec2"]
=== Troubleshooting Amazon EC2

Use the following procedure to troubleshoot Amazon EC2 Builds.

.Procedure

. Start a Build in {productname}.

. In the EC2 console, identify the Build instance. Build instances are named `Quay Ephemeral Builder` and have the tag {`<Build_UUID>: <uuid>`}

. Using the SSH key set by the `EC2_KEY_NAME` configuration field, log in to the Builder instance by running the following command:
+
[source,terminal]
----
$ ssh -i /path/to/ssh/key/in/ec2/or/config/id_rsa core@<instance_ip>
----

. Obtain the `quay-builder` service logs by entering the following commands:
+
[source,terminal]
----
$ systemctl status quay-builder
----
+
[source,terminal]
----
$ journalctl -f -u quay-builder
----
endif::upstream[]

[id="openshift-kubernetes-troubleshooting"]
=== Troubleshooting {ocp} and Kubernetes Builds

Use the following procedure to troubleshooting {ocp} Kubernetes Builds.

.Procedure

. Create a port forwarding tunnel between your local machine and a pod running with either an {ocp} cluster or a Kubernetes cluster by entering the following command:
+
[source,terminal]
----
$ oc port-forward <builder_pod> 9999:2222

----

. Establish an SSH connection to the remote host using a specified SSH key and port, for example:
+
[source,terminal]
----
$ ssh -i /path/to/ssh/key/set/in/ssh_authorized_keys -p 9999 core@localhost
----

. Obtain the `quay-builder` service logs by entering the following commands:
+
[source,terminal]
----
$ systemctl status quay-builder
----
+
[source,terminal]
----
$ journalctl -f -u quay-builder
----

[id="set-up-github-build"]
== Setting up Github builds 

If your organization plans to have Builds be conducted by pushes to Github, or Github Enterprise, continue with _Creating an OAuth application in GitHub_.
