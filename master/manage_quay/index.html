<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" class="chrometwo"><head><title>Manage Red Hat Quay</title><link rel="stylesheet" type="text/css" href="Common_Content/css/default.css"/><meta name="generator" content="publican v4.3.4"/><meta name="description" content="Manage Red Hat Quay"/><link rel="next" href="#idm45642557062592" title="Preface"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><script type="text/javascript" src="Common_Content/scripts/jquery-1.7.1.min.js"> </script><script type="text/javascript" src="Common_Content/scripts/utils.js"> </script><script type="text/javascript" src="Common_Content/scripts/highlight.js/highlight.pack.js"> </script></head><body><div id="chrometwo"><div id="main"><div xml:lang="en-US" class="book" id="idm45642578031616"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Quay</span> <span class="productnumber">3.7</span></div><div><h1 class="title">Manage Red Hat Quay</h1></div><div><h2 class="subtitle">Manage Red Hat Quay</h2></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat OpenShift Documentation Team</span></div></div><div><a href="#idm45642554420480">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				Manage Red Hat Quay
			</div></div></div></div><hr/></div><div class="toc"><ul class="toc"><li><span class="preface"><a href="#idm45642557062592">Preface</a></span></li><li><span class="chapter"><a href="#advanced-quay-configuration">1. Advanced Red Hat Quay configuration</a></span><ul><li><span class="section"><a href="#using-the-config-tool">1.1. Using Red Hat Quay Config Tool to modify Red Hat Quay</a></span><ul><li><span class="section"><a href="#running_the_config_tool_from_the_red_hat_quay_operator">1.1.1. Running the Config Tool from the Red Hat Quay Operator</a></span></li><li><span class="section"><a href="#running_the_config_tool_from_the_command_line">1.1.2. Running the Config Tool from the command line</a></span></li></ul></li><li><span class="section"><a href="#overview-advanced-config">1.2. Using the API to modify Red Hat Quay</a></span></li><li><span class="section"><a href="#editing_the_literal_config_yaml_literal_file_to_modify_red_hat_quay">1.3. Editing the <code class="literal">config.yaml</code> file to modify Red Hat Quay</a></span><ul><li><span class="section"><a href="#add_name_and_company_to_red_hat_quay_sign_in">1.3.1. Add name and company to Red Hat Quay sign-in</a></span></li><li><span class="section"><a href="#disable_tls_protocols">1.3.2. Disable TLS Protocols</a></span></li><li><span class="section"><a href="#rate_limit_api_calls">1.3.3. Rate limit API calls</a></span></li><li><span class="section"><a href="#adjust_database_connection_pooling">1.3.4. Adjust database connection pooling</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#using_the_configuration_api">2. Using the configuration API</a></span><ul><li><span class="section"><a href="#retrieving_the_default_configuration">2.1. Retrieving the default configuration</a></span></li><li><span class="section"><a href="#retrieving_the_current_configuration">2.2. Retrieving the current configuration</a></span></li><li><span class="section"><a href="#validating_configuration_using_the_api">2.3. Validating configuration using the API</a></span></li><li><span class="section"><a href="#determining_the_required_fields">2.4. Determining the required fields</a></span></li></ul></li><li><span class="chapter"><a href="#release-notifications">3. Getting Red Hat Quay release notifications</a></span></li><li><span class="chapter"><a href="#using-ssl-to-protect-quay">4. Using SSL to protect connections to Red Hat Quay</a></span><ul><li><span class="section"><a href="#introduction_to_using_ssl">4.1. Introduction to using SSL</a></span></li><li><span class="section"><a href="#create-a-ca-and-sign-a-certificate">4.2. Create a Certificate Authority and sign a certificate</a></span><ul><li><span class="section"><a href="#create_a_certificate_authority">4.2.1. Create a Certificate Authority</a></span></li><li><span class="section"><a href="#sign_a_certificate">4.2.2. Sign a certificate</a></span></li></ul></li><li><span class="section"><a href="#configuring_ssl_using_the_command_line">4.3. Configuring SSL using the command line</a></span></li><li><span class="section"><a href="#configuring_ssl_using_the_ui">4.4. Configuring SSL using the UI</a></span></li><li><span class="section"><a href="#testing_ssl_configuration_using_the_command_line">4.5. Testing SSL configuration using the command line</a></span></li><li><span class="section"><a href="#testing_ssl_configuration_using_the_browser">4.6. Testing SSL configuration using the browser</a></span></li><li><span class="section"><a href="#configuring_podman_to_trust_the_certificate_authority">4.7. Configuring podman to trust the Certificate Authority</a></span></li><li><span class="section"><a href="#configuring_the_system_to_trust_the_certificate_authority">4.8. Configuring the system to trust the certificate authority</a></span></li></ul></li><li><span class="chapter"><a href="#config-custom-ssl-certs-manual">5. Adding TLS Certificates to the Red Hat Quay Container</a></span><ul><li><span class="section"><a href="#add-certificates-to-quay-container">5.1. Add TLS certificates to Red Hat Quay</a></span></li><li><span class="section"><a href="#config-custom-ssl-cert-kubernetes">5.2. Add certs when deployed on Kubernetes</a></span></li></ul></li><li><span class="chapter"><a href="#proc_manage-log-storage">6. Configuring action log storage for Elasticsearch</a></span></li><li><span class="chapter"><a href="#clair-intro2">7. Clair Security Scanning</a></span><ul><li><span class="section"><a href="#clair-openshift">7.1. Setting Up Clair on a Red Hat Quay OpenShift deployment</a></span><ul><li><span class="section"><a href="#deploying_via_the_quay_operator">7.1.1. Deploying Via the Quay Operator</a></span></li><li><span class="section"><a href="#clair-openshift-manual">7.1.2. Manually Deploying Clair</a></span></li></ul></li><li><span class="section"><a href="#clair-standalone">7.2. Setting up Clair on a non-OpenShift Red Hat Quay deployment</a></span></li><li><span class="section"><a href="#clair-unmanaged">7.3. Advanced Clair configuration</a></span><ul><li><span class="section"><a href="#unmanaged_clair_configuration">7.3.1. Unmanaged Clair configuration</a></span></li><li><span class="section"><a href="#running_a_custom_clair_configuration_with_a_literal_managed_literal_database">7.3.2. Running a custom Clair configuration with a <code class="literal">managed</code> database</a></span></li></ul></li><li><span class="section"><a href="#clair-using">7.4. Using Clair</a></span></li><li><span class="section"><a href="#clair-cve">7.5. CVE ratings from the National Vulnerability Database</a></span></li><li><span class="section"><a href="#clair-disconnected">7.6. Configuring Clair for Disconnected Environments</a></span></li><li><span class="section"><a href="#clair-updater-urls">7.7. Clair updater URLs</a></span></li><li><span class="section"><a href="#clair-add-info">7.8. Additional Information</a></span></li></ul></li><li><span class="chapter"><a href="#container-security-operator-setup">8. Scan pod images with the Container Security Operator</a></span><ul><li><span class="section"><a href="#run_the_cso_in_openshift">8.1. Run the CSO in OpenShift</a></span></li><li><span class="section"><a href="#query_image_vulnerabilities_from_the_cli">8.2. Query image vulnerabilities from the CLI</a></span></li></ul></li><li><span class="chapter"><a href="#quay-bridge-operator">9. Integrate Red Hat Quay into OpenShift with the Bridge Operator</a></span><ul><li><span class="section"><a href="#running_the_quay_bridge_operator">9.1. Running the Quay Bridge Operator</a></span><ul><li><span class="section"><a href="#prerequisites">9.1.1. Prerequisites</a></span></li><li><span class="section"><a href="#setting_up_and_configuring_openshift_and_red_hat_quay">9.1.2. Setting up and configuring OpenShift and Red Hat Quay</a></span></li><li><span class="section"><a href="#red_hat_quay_setup">9.1.3. Red Hat Quay setup</a></span></li><li><span class="section"><a href="#openshift_setup">9.1.4. OpenShift Setup</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#repo-mirroring-in-red-hat-quay">10. Repository mirroring</a></span><ul><li><span class="section"><a href="#mirroring-intro">10.1. Repository mirroring</a></span></li><li><span class="section"><a href="#mirroring-versus-georepl">10.2. Repository mirroring versus geo-replication</a></span></li><li><span class="section"><a href="#mirroring-using">10.3. Using repository mirroring</a></span></li><li><span class="section"><a href="#mirroring_configuration_ui">10.4. Mirroring configuration UI</a></span></li><li><span class="section"><a href="#config-fields-mirroring">10.5. Mirroring configuration fields</a></span></li><li><span class="section"><a href="#mirroring-worker">10.6. Mirroring worker</a></span></li><li><span class="section"><a href="#mirroring-creating-repo">10.7. Creating a mirrored repository</a></span><ul><li><span class="section"><a href="#repository_mirroring_settings">10.7.1. Repository mirroring settings</a></span></li><li><span class="section"><a href="#advanced_settings">10.7.2. Advanced settings</a></span></li><li><span class="section"><a href="#synchronize_now">10.7.3. Synchronize now</a></span></li></ul></li><li><span class="section"><a href="#mirroring-events">10.8. Event notifications for mirroring</a></span></li><li><span class="section"><a href="#mirroring-tag-patterns">10.9. Mirroring tag patterns</a></span><ul><li><span class="section"><a href="#pattern_syntax">10.9.1. Pattern syntax</a></span></li><li><span class="section"><a href="#example_tag_patterns">10.9.2. Example tag patterns</a></span></li></ul></li><li><span class="section"><a href="#mirroring-working-with">10.10. Working with mirrored repositories</a></span></li><li><span class="section"><a href="#mirroring-recommend">10.11. Repository mirroring recommendations</a></span></li></ul></li><li><span class="chapter"><a href="#ldap-authentication-setup-for-quay-enterprise">11. LDAP Authentication Setup for Red Hat Quay</a></span><ul><li><span class="section"><a href="#considerations_prior_to_enabling_ldap">11.1. Considerations prior to enabling LDAP</a></span><ul><li><span class="section"><a href="#considerations-for-existing-quay-deployments">11.1.1. Existing Quay deployments</a></span></li><li><span class="section"><a href="#considerations-for-manual-user-creation">11.1.2. Manual User Creation and LDAP authentication</a></span></li></ul></li><li><span class="section"><a href="#setup-ldap-configuration">11.2. Set Up LDAP Configuration</a></span><ul><li><span class="section"><a href="#full_ldap_uri">11.2.1. Full LDAP URI</a></span></li><li><span class="section"><a href="#team_synchronization">11.2.2. Team Synchronization</a></span></li><li><span class="section"><a href="#base_and_relative_distinguished_names">11.2.3. Base and Relative Distinguished Names</a></span></li><li><span class="section"><a href="#additional_user_filters">11.2.4. Additional User Filters</a></span></li><li><span class="section"><a href="#administrator_dn">11.2.5. Administrator DN</a></span></li><li><span class="section"><a href="#uid_and_mail_attributes">11.2.6. UID and Mail attributes</a></span></li><li><span class="section"><a href="#validation">11.2.7. Validation</a></span></li></ul></li><li><span class="section"><a href="#common-issues">11.3. Common Issues</a></span></li><li><span class="section"><a href="#configure-ldap-superuser">11.4. Configure an LDAP user as superuser</a></span></li></ul></li><li><span class="chapter"><a href="#prometheus-metrics-under-quay-enterprise">12. Prometheus and Grafana metrics under Red Hat Quay</a></span><ul><li><span class="section"><a href="#exposing-the-prometheus-endpoint">12.1. Exposing the Prometheus endpoint</a></span><ul><li><span class="section"><a href="#standalone_red_hat_quay">12.1.1. Standalone Red Hat Quay</a></span></li><li><span class="section"><a href="#red_hat_quay_operator">12.1.2. Red Hat Quay Operator</a></span></li><li><span class="section"><a href="#setting-up-prometheus-to-consume-metrics">12.1.3. Setting up Prometheus to consume metrics</a></span></li><li><span class="section"><a href="#dns-configuration-under-kubernetes">12.1.4. DNS configuration under Kubernetes</a></span></li><li><span class="section"><a href="#dns-configuration-for-a-manual-cluster">12.1.5. DNS configuration for a manual cluster</a></span></li></ul></li><li><span class="section"><a href="#metrics-intro">12.2. Introduction to metrics</a></span><ul><li><span class="section"><a href="#metrics-general-registry-stats">12.2.1. General registry statistics</a></span></li><li><span class="section"><a href="#metrics-queue-items">12.2.2. Queue items</a></span></li><li><span class="section"><a href="#metrics-garbage-collection">12.2.3. Garbage collection metrics</a></span></li><li><span class="section"><a href="#metrics-image-push-pull">12.2.4. Image push / pull metrics</a></span></li><li><span class="section"><a href="#metrics-authentication">12.2.5. Authentication metrics</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#red-hat-quay-quota-management-and-enforcement">13. Red Hat Quay quota management and enforcement</a></span><ul><li><span class="section"><a href="#config-fields-quota">13.1. Quota management configuration</a></span><ul><li><span class="section"><a href="#default_quota">13.1.1. Default quota</a></span></li></ul></li><li><span class="section"><a href="#quota-management-arch">13.2. Quota management architecture</a></span></li><li><span class="section"><a href="#quota-establishment-ui">13.3. Establishing quota in Red Hat Quay UI</a></span></li><li><span class="section"><a href="#quota-establishment-api">13.4. Establishing quota with the Red Hat Quay API</a></span><ul><li><span class="section"><a href="#setting_the_quota">13.4.1. Setting the quota</a></span></li><li><span class="section"><a href="#viewing_the_quota">13.4.2. Viewing the quota</a></span></li><li><span class="section"><a href="#modifying_the_quota">13.4.3. Modifying the quota</a></span></li><li><span class="section"><a href="#pushing_images">13.4.4. Pushing images</a></span></li><li><span class="section"><a href="#rejecting_pushes_using_quota_limits">13.4.5. Rejecting pushes using quota limits</a></span></li></ul></li><li><span class="section"><a href="#quota-management-limitations">13.5. Quota management limitations</a></span></li></ul></li><li><span class="chapter"><a href="#georepl-intro">14. Geo-replication</a></span><ul><li><span class="section"><a href="#geo_replication_features">14.1. Geo-replication features</a></span></li><li><span class="section"><a href="#georepl-prereqs">14.2. Geo-replication requirements and constraints</a></span></li><li><span class="section"><a href="#georepl-arch-standalone">14.3. Geo-replication - standalone Quay</a></span><ul><li><span class="section"><a href="#geo_replication_architecture_standalone_quay">14.3.1. Geo-replication architecture - standalone Quay</a></span></li><li><span class="section"><a href="#config-ui-storage-georepl">14.3.2. Enable storage replication - standalone Quay</a></span></li><li><span class="section"><a href="#georepl-deploy-standalone">14.3.3. Run Red Hat Quay with storage preferences</a></span></li></ul></li><li><span class="section"><a href="#georepl-arch-operator">14.4. Geo-replication - Quay Operator</a></span><ul><li><span class="section"><a href="#geo_replication_architecture_quay_operator">14.4.1. Geo-replication architecture - Quay Operator</a></span></li><li><span class="section"><a href="#georepl-deploy-operator">14.4.2. Setting up geo-replication on Openshift</a></span></li><li><span class="section"><a href="#georepl-mixed-storage">14.4.3. Mixed storage for geo-replication</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#quay-troubleshooting-guides">15. Red Hat Quay Troubleshooting</a></span></li><li><span class="chapter"><a href="#quay-schema">16. Schema for Red Hat Quay configuration</a></span></li></ul></div><section class="preface" id="idm45642557062592"><div class="titlepage"><div><div><h1 class="title">Preface</h1></div></div></div><p>
			Once you have deployed a Red Hat Quay registry, there are many ways you can further configure and manage that deployment. Topics covered here include:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Advanced Red Hat Quay configuration
				</li><li class="listitem">
					Setting notifications to alert you of a new Red Hat Quay release
				</li><li class="listitem">
					Securing connections with SSL and TLS certificates
				</li><li class="listitem">
					Directing action logs storage to Elasticsearch
				</li><li class="listitem">
					Configuring image security scanning with Clair
				</li><li class="listitem">
					Scan pod images with the Container Security Operator
				</li><li class="listitem">
					Integrate Red Hat Quay into OpenShift with the Quay Bridge Operator
				</li><li class="listitem">
					Mirroring images with repository mirroring
				</li><li class="listitem">
					Sharing Quay images with a BitTorrent service
				</li><li class="listitem">
					Authenticating users with LDAP
				</li><li class="listitem">
					Enabling Quay for Prometheus and Grafana metrics
				</li><li class="listitem">
					Setting up geo-replication
				</li><li class="listitem">
					Troubleshooting Quay
				</li></ul></div></section><section class="chapter" id="advanced-quay-configuration"><div class="titlepage"><div><div><h1 class="title">Chapter 1. Advanced Red Hat Quay configuration</h1></div></div></div><p>
			You can configure your Red Hat Quay after initial deployment using several different interfaces:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					The Red Hat Quay Config Tool: Running the <code class="literal">Quay</code> container in <code class="literal">config</code> mode presents a Web-based interface for configuring the Red Hat Quay cluster. This is the recommended method for most configuration of the Red Hat Quay service itself.
				</li><li class="listitem">
					Editing the <code class="literal">config.yaml</code>: The <code class="literal">config.yaml</code> file holds most of the configuration information for the Red Hat Quay cluster. Editing that file directly is possible, but it is only recommended for advanced tuning and performance features that are not available through the Config Tool.
				</li><li class="listitem">
					Red Hat Quay API: Some Red Hat Quay configuration can be done through the API.
				</li></ul></div><p>
			While configuration for specific features is covered in separate sections, this section describes how to use each of those interfaces and perform some more advanced configuration.
		</p><section class="section" id="using-the-config-tool"><div class="titlepage"><div><div><h2 class="title">1.1. Using Red Hat Quay Config Tool to modify Red Hat Quay</h2></div></div></div><p>
				The Red Hat Quay Config Tool is made available by running a <code class="literal">Quay</code> container in <code class="literal">config</code> mode alongside the regular Red Hat Quay service. Running the Config Tool is different for Red Hat Quay clusters running on OpenShift than it is for those running directly on host systems.
			</p><section class="section" id="running_the_config_tool_from_the_red_hat_quay_operator"><div class="titlepage"><div><div><h3 class="title">1.1.1. Running the Config Tool from the Red Hat Quay Operator</h3></div></div></div><p>
					If you are running the Red Hat Quay Operator from OpenShift, the Config Tool is probably already available for you to use. To access the Config Tool, do the following:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							From the OpenShift console, select the project in which Red Hat Quay is running. For example, quay-enterprise.
						</li><li class="listitem"><p class="simpara">
							From the left column, select Networking → Routes. You should see routes to both the Red Hat Quay application and Config Tool, as shown in the following image:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/configtoolroute.png" alt="View the route to the Red Hat Quay Config Tool"/></span>
						</p></li><li class="listitem">
							Select the route to the Config Tool (for example, example-quayecosystem-quay-config) and select it. The Config tool Web UI should open in your browser.
						</li><li class="listitem"><p class="simpara">
							Select <code class="literal">Modify configuration for this cluster</code>. You should see the Config Tool, ready for you to change features of your Red Hat Quay cluster, as shown in the following image:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/configtoolsetup.png" alt="Modify Red Hat Quay cluster settings from the Config Tool"/></span>
						</p></li><li class="listitem">
							When you have made the changes you want, select <code class="literal">Save Configuration Changes</code>. The Config Tool will validate your changes.
						</li><li class="listitem">
							Make any corrections as needed by selecting <code class="literal">Continue Editing</code> or select <code class="literal">Next</code> to continue on.
						</li><li class="listitem">
							When prompted, it is recommended that you select <code class="literal">Download Configuration</code>. That will download a tarball of your new <code class="literal">config.yaml</code>, as well as any certificates and keys used with your Red Hat Quay setup.
						</li><li class="listitem">
							Select <code class="literal">Go to deployment rollout</code>, then <code class="literal">Populate the configuration to deployments</code>. The Red Hat Quay pods will be restarted and the changes will take effect.
						</li></ol></div><p>
					The <code class="literal">config.yaml</code> file you saved can be used to make advanced changes to your configuration or just kept for future reference.
				</p></section><section class="section" id="running_the_config_tool_from_the_command_line"><div class="titlepage"><div><div><h3 class="title">1.1.2. Running the Config Tool from the command line</h3></div></div></div><p>
					If you are running Red Hat Quay directly from a host system, using tools such as the <code class="literal">podman</code> or <code class="literal">docker</code> commands, after the initial Red Hat Quay deployment, you can restart the Config Tool to modify your Red Hat Quay cluster. Here’s how:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							<span class="strong strong"><strong>Start quay in config mode</strong></span>: On the first <code class="literal">quay</code> node run the following, replacing <code class="literal">my-secret-password</code> with your password. If you would like to modify an existing config bundle, you can simply mount your configuration directory into the <code class="literal">Quay</code> container as you would in registry mode.
						</p><pre class="literallayout"># podman run --rm -it --name quay_config -p 8080:8080 \
    -v path/to/config-bundle:/conf/stack \
    registry.redhat.io/quay/quay-rhel8:v3.7.0 config my-secret-password</pre></li><li class="listitem">
							<span class="strong strong"><strong>Open browser</strong></span>: When the quay configuration tool starts up, open a browser to the URL and port 8080 of the system you are running the configuration tool on (for example <a class="link" href="https://myquay.example.com:8080">https://myquay.example.com:8080</a>). You are prompted for a username and password.
						</li></ol></div><p>
					At this point, you can begin modifying your Red Hat Quay cluster as described earlier.
				</p></section></section><section class="section" id="overview-advanced-config"><div class="titlepage"><div><div><h2 class="title">1.2. Using the API to modify Red Hat Quay</h2></div></div></div><p>
				See the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html-single/red_hat_quay_api_guide/index">Red Hat Quay API Guide</a> for information on how to access Red Hat Quay API.
			</p></section><section class="section" id="editing_the_literal_config_yaml_literal_file_to_modify_red_hat_quay"><div class="titlepage"><div><div><h2 class="title">1.3. Editing the <code class="literal">config.yaml</code> file to modify Red Hat Quay</h2></div></div></div><p>
				Some advanced Red Hat Quay configuration that is not available through the Config Tool can be achieved by editing the <code class="literal">config.yaml</code> file directly. Available settings are described in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/manage_red_hat_quay/quay-schema">Schema for Red Hat Quay configuration</a> The following are examples of settings you can change directly in the <code class="literal">config.yaml</code> file.
			</p><section class="section" id="add_name_and_company_to_red_hat_quay_sign_in"><div class="titlepage"><div><div><h3 class="title">1.3.1. Add name and company to Red Hat Quay sign-in</h3></div></div></div><p>
					Setting the following will cause users to be prompted for their name and company when they first sign in. Although this is optional, it can provide you with extra data about your Red Hat Quay users:
				</p><p>
					+ <code class="literal">FEATURE_USER_METADATA: true</code>
				</p></section><section class="section" id="disable_tls_protocols"><div class="titlepage"><div><div><h3 class="title">1.3.2. Disable TLS Protocols</h3></div></div></div><p>
					You can change the SSL_PROTOCOLS setting to remove SSL protocols that you do not want to support in your Red Hat Quay instance. For example, to remove TLS v1 support from the default SSL_PROTOCOLS : ['TLSv1','TLSv1.1','TLSv1.2'], change it as follows:
				</p><p>
					+ SSL_PROTOCOLS : ['TLSv1.1','TLSv1.2']
				</p></section><section class="section" id="rate_limit_api_calls"><div class="titlepage"><div><div><h3 class="title">1.3.3. Rate limit API calls</h3></div></div></div><p>
					Adding the FEATURE_RATE_LIMITS parameter to the <code class="literal">config.yaml</code> causes <code class="literal">nginx</code> to limit certain API calls to 30 per second. If that feature is not set, API calls are limied to 300 per second (effectively unlimited). Rate limiting can be an important feature, if you need to make sure the resources available are not overwhelmed with traffic.
				</p><p>
					Some namespace may require unlimited access (perhaps they are important to CI/CD and take priority, for example). In this case, those namespace may be placed in a list in <code class="literal">config.yaml</code> for NON_RATE_LIMITED_NAMESPACES.
				</p></section><section class="section" id="adjust_database_connection_pooling"><div class="titlepage"><div><div><h3 class="title">1.3.4. Adjust database connection pooling</h3></div></div></div><p>
					Red Hat Quay is composed of many different processes which all run within the same container. Many of these processes interact with the database.
				</p><p>
					If enabled, each process that interacts with the database will contain a connection pool. These per-process connection pools are configured to maintain a maximum of 20 connections. Under heavy load, it is possible to fill the connection pool for every process within a Red Hat Quay container. Under certain deployments and loads, this may require analysis to ensure Red Hat Quay does not exceed the database’s configured maximum connection count.
				</p><p>
					Overtime, the connection pools will release idle connections. To release all connections immediately, Red Hat Quay requires a restart.
				</p><p>
					Database connection pooling may be toggled by setting the environment variable <code class="literal">DB_CONNECTION_POOLING={true|false}</code>
				</p><p>
					If database connection pooling is enabled, it is possible to change the maximum size of the connection pool. This can be done through the following <code class="literal">config.yaml</code> option:
				</p><pre class="literallayout">DB_CONNECTION_ARGS:
  max_connections: 10</pre><section class="section" id="database_connection_arguments"><div class="titlepage"><div><div><h4 class="title">1.3.4.1. Database connection arguments</h4></div></div></div><p>
						You can customize Red Hat Quay database connection settings within the <code class="literal">config.yaml</code> file. These are entirely dependent upon the underlying database driver, such as <code class="literal">psycopg2</code> for Postgres and <code class="literal">pymysql</code> for MySQL. It is also possible to pass in arguments used by Peewee’s Connection Pooling mechanism as seen below.
					</p><pre class="literallayout">DB_CONNECTION_ARGS:
  max_connections: n  # Max Connection Pool size. (Connection Pooling only)
  timeout: n  # Time to hold on to connections. (Connection Pooling only)
  stale_timeout: n  # Number of seconds to block when the pool is full. (Connection Pooling only)</pre></section><section class="section" id="database-ssl-configuration"><div class="titlepage"><div><div><h4 class="title">1.3.4.2. Database SSL configuration</h4></div></div></div><p>
						Some key-value pairs defined under DB_CONNECTION_ARGS are generic while others are database-specific. In particular, SSL configuration depends on the database you are deploying.
					</p><section class="section" id="postgresql_ssl_connection_arguments"><div class="titlepage"><div><div><h5 class="title">1.3.4.2.1. PostgreSQL SSL connection arguments</h5></div></div></div><p>
							A sample PostgreSQL SSL configuration is given below:
						</p><pre class="screen">DB_CONNECTION_ARGS:
  sslmode: verify-ca
  sslrootcert: /path/to/cacert</pre><p>
							The <code class="literal">sslmode</code> option determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the server. There are six modes:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<span class="strong strong"><strong>disable:</strong></span> only try a non-SSL connection
								</li><li class="listitem">
									<span class="strong strong"><strong>allow:</strong></span> first try a non-SSL connection; if that fails, try an SSL connection
								</li><li class="listitem">
									<span class="strong strong"><strong>prefer:</strong></span> (default) first try an SSL connection; if that fails, try a non-SSL connection
								</li><li class="listitem">
									<span class="strong strong"><strong>require:</strong></span> only try an SSL connection. If a root CA file is present, verify the certificate in the same way as if verify-ca was specified
								</li><li class="listitem">
									<span class="strong strong"><strong>verify-ca:</strong></span> only try an SSL connection, and verify that the server certificate is issued by a trusted certificate authority (CA)
								</li><li class="listitem">
									<span class="strong strong"><strong>verify-full:</strong></span> only try an SSL connection, verify that the server certificate is issued by a trusted CA and that the requested server host name matches that in the certificate
								</li></ul></div><p>
							More information on the valid arguments for PostgreSQL is available at <a class="link" href="https://www.postgresql.org/docs/current/libpq-connect.html">https://www.postgresql.org/docs/current/libpq-connect.html</a>.
						</p></section><section class="section" id="mysql_ssl_connection_arguments"><div class="titlepage"><div><div><h5 class="title">1.3.4.2.2. MySQL SSL connection arguments</h5></div></div></div><p>
							A sample MySQL SSL configuration follows:
						</p><pre class="screen">DB_CONNECTION_ARGS:
  ssl:
    ca: /path/to/cacert</pre><p>
							Information on the valid connection arguments for MySQL is available at <a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/connecting-using-uri-or-key-value-pairs.html">https://dev.mysql.com/doc/refman/8.0/en/connecting-using-uri-or-key-value-pairs.html</a>.
						</p></section></section><section class="section" id="http_connection_counts"><div class="titlepage"><div><div><h4 class="title">1.3.4.3. HTTP connection counts</h4></div></div></div><p>
						It is possible to specify the quantity of simultaneous HTTP connections using environment variables. These can be specified as a whole, or for a specific component. The default for each is 50 parallel connections per process.
					</p><p>
						Environment variables:
					</p><pre class="screen">WORKER_CONNECTION_COUNT_REGISTRY=n
WORKER_CONNECTION_COUNT_WEB=n
WORKER_CONNECTION_COUNT_SECSCAN=n
WORKER_CONNECTION_COUNT=n</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							Specifying a count for a specific component will override any value set in WORKER_CONNECTION_COUNT.
						</p></div></div></section><section class="section" id="dynamic_process_counts"><div class="titlepage"><div><div><h4 class="title">1.3.4.4. Dynamic process counts</h4></div></div></div><p>
						To estimate the quantity of dynamically sized processes, the following calculation is used by default.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							Red Hat Quay queries the available CPU count from the entire machine. Any limits applied using kubernetes or other non-virtualized mechanisms will not affect this behavior; Red Hat Quay will makes its calculation based on the total number of processors on the Node. The default values listed are simply targets, but shall not exceed the maximum or be lower than the minimum.
						</p></div></div><p>
						Each of the following process quantities can be overridden using the environment variable specified below.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								registry - Provides HTTP endpoints to handle registry action
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										minimum: 8
									</li><li class="listitem">
										maximum: 64
									</li><li class="listitem">
										default: $CPU_COUNT x 4
									</li><li class="listitem">
										environment variable: WORKER_COUNT_REGISTRY
									</li></ul></div></li><li class="listitem"><p class="simpara">
								web - Provides HTTP endpoints for the web-based interface
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										minimum: 2
									</li><li class="listitem">
										maximum: 32
									</li><li class="listitem">
										default: $CPU_COUNT x 2
									</li><li class="listitem">
										environment_variable: WORKER_COUNT_WEB
									</li></ul></div></li><li class="listitem"><p class="simpara">
								secscan - Interacts with Clair
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										minimum: 2
									</li><li class="listitem">
										maximum: 4
									</li><li class="listitem">
										default: $CPU_COUNT x 2
									</li><li class="listitem">
										environment variable: WORKER_COUNT_SECSCAN
									</li></ul></div></li></ul></div></section><section class="section" id="environment_variables"><div class="titlepage"><div><div><h4 class="title">1.3.4.5. Environment variables</h4></div></div></div><p>
						Red Hat Quay allows overriding default behavior using environment variables. This table lists and describes each variable and the values they can expect.
					</p><div class="table" id="idm45642558032480"><p class="title"><strong>Table 1.1. Worker count environment variables</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"/><col style="width: 33%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642558026608" scope="col">Variable</th><th align="left" valign="top" id="idm45642556384176" scope="col">Description</th><th align="left" valign="top" id="idm45642556383088" scope="col">Values</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642558026608">
									<p>
										WORKER_COUNT_REGISTRY
									</p>
									</td><td align="left" valign="top" headers="idm45642556384176">
									<p>
										Specifies the number of processes to handle Registry requests within the <code class="literal">Quay</code> container.
									</p>
									</td><td align="left" valign="top" headers="idm45642556383088">
									<p>
										Integer between 8 and 64
									</p>
									</td></tr><tr><td align="left" valign="top" headers="idm45642558026608">
									<p>
										WORKER_COUNT_WEB
									</p>
									</td><td align="left" valign="top" headers="idm45642556384176">
									<p>
										Specifies the number of processes to handle UI/Web requests within the container.
									</p>
									</td><td align="left" valign="top" headers="idm45642556383088">
									<p>
										Integer between 2 and 32
									</p>
									</td></tr><tr><td align="left" valign="top" headers="idm45642558026608">
									<p>
										WORKER_COUNT_SECSCAN
									</p>
									</td><td align="left" valign="top" headers="idm45642556384176">
									<p>
										Specifies the number of processes to handle Security Scanning (e.g. Clair) integration within the container.
									</p>
									</td><td align="left" valign="top" headers="idm45642556383088">
									<p>
										Integer between 2 and 4
									</p>
									</td></tr><tr><td align="left" valign="top" headers="idm45642558026608">
									<p>
										DB_CONNECTION_POOLING
									</p>
									</td><td align="left" valign="top" headers="idm45642556384176">
									<p>
										Toggle database connection pooling. In 3.4, it is disabled by default.
									</p>
									</td><td align="left" valign="top" headers="idm45642556383088">
									<p>
										"true" or "false"
									</p>
									</td></tr></tbody></table></div></div></section><section class="section" id="turning_off_connection_pooling"><div class="titlepage"><div><div><h4 class="title">1.3.4.6. Turning off connection pooling</h4></div></div></div><p>
						Red Hat Quay deployments with a large amount of user activity can regularly hit the 2k maximum database connection limit. In these cases, connection pooling, which is enabled by default for Red Hat Quay, can cause database connection count to rise exponentially and require you to turn off connection pooling.
					</p><p>
						If turning off connection pooling is not enough to prevent hitting that 2k database connection limit, you need to take additional steps to deal with the problem. In this case you might need to increase the maximum database connections to better suit your workload.
					</p></section></section></section></section><section class="chapter" id="using_the_configuration_api"><div class="titlepage"><div><div><h1 class="title">Chapter 2. Using the configuration API</h1></div></div></div><p>
			The configuration tool exposes 4 endpoints that can be used to build, validate, bundle and deploy a configuration. The config-tool API is documented at <a class="link" href="https://github.com/quay/config-tool/blob/master/pkg/lib/editor/API.md">https://github.com/quay/config-tool/blob/master/pkg/lib/editor/API.md</a>. In this section, you will see how to use the API to retrieve the current configuration and how to validate any changes you make.
		</p><section class="section" id="retrieving_the_default_configuration"><div class="titlepage"><div><div><h2 class="title">2.1. Retrieving the default configuration</h2></div></div></div><p>
				If you are running the configuration tool for the first time, and do not have an existing configuration, you can retrieve the default configuration. Start the container in config mode:
			</p><pre class="literallayout">$ sudo podman run --rm -it --name quay_config \
  -p 8080:8080 \
  registry.redhat.io/quay/quay-rhel8:v3.7.0 config secret</pre><p>
				Use the <code class="literal">config</code> endpoint of the configuration API to get the default:
			</p><pre class="literallayout">$ curl -X GET -u quayconfig:secret http://quay-server:8080/api/v1/config  | jq</pre><p>
				The value returned is the default configuration in JSON format:
			</p><pre class="programlisting language-json">{
  "config.yaml": {
    "AUTHENTICATION_TYPE": "Database",
    "AVATAR_KIND": "local",
    "DB_CONNECTION_ARGS": {
      "autorollback": true,
      "threadlocals": true
    },
    "DEFAULT_TAG_EXPIRATION": "2w",
    "EXTERNAL_TLS_TERMINATION": false,
    "FEATURE_ACTION_LOG_ROTATION": false,
    "FEATURE_ANONYMOUS_ACCESS": true,
    "FEATURE_APP_SPECIFIC_TOKENS": true,
    ....
  }

}</pre></section><section class="section" id="retrieving_the_current_configuration"><div class="titlepage"><div><div><h2 class="title">2.2. Retrieving the current configuration</h2></div></div></div><p>
				If you have already configured and deployed the Quay registry, stop the container and restart it in configuration mode, loading the existing configuration as a volume:
			</p><pre class="literallayout">$ sudo podman run --rm -it --name quay_config \
  -p 8080:8080 \
  -v $QUAY/config:/conf/stack:Z \
  registry.redhat.io/quay/quay-rhel8:v3.7.0 config secret</pre><p>
				Use the <code class="literal">config</code> endpoint of the API to get the current configuration:
			</p><pre class="literallayout">$ curl -X GET -u quayconfig:secret http://quay-server:8080/api/v1/config  | jq</pre><p>
				The value returned is the current configuration in JSON format, including database and Redis configuration data:
			</p><pre class="programlisting language-json">{
  "config.yaml": {
    ....
    "BROWSER_API_CALLS_XHR_ONLY": false,
    "BUILDLOGS_REDIS": {
      "host": "quay-server",
      "password": "strongpassword",
      "port": 6379
    },
    "DATABASE_SECRET_KEY": "4b1c5663-88c6-47ac-b4a8-bb594660f08b",
    "DB_CONNECTION_ARGS": {
      "autorollback": true,
      "threadlocals": true
    },
    "DB_URI": "postgresql://quayuser:quaypass@quay-server:5432/quay",
    "DEFAULT_TAG_EXPIRATION": "2w",
    ....


  }

}</pre></section><section class="section" id="validating_configuration_using_the_api"><div class="titlepage"><div><div><h2 class="title">2.3. Validating configuration using the API</h2></div></div></div><p>
				You can validate a configuration by posting it to the <code class="literal">config/validate</code> endpoint:
			</p><pre class="literallayout">curl -u quayconfig:secret --header 'Content-Type: application/json' --request POST --data '
{
  "config.yaml": {
    ....
    "BROWSER_API_CALLS_XHR_ONLY": false,
    "BUILDLOGS_REDIS": {
      "host": "quay-server",
      "password": "strongpassword",
      "port": 6379
    },
    "DATABASE_SECRET_KEY": "4b1c5663-88c6-47ac-b4a8-bb594660f08b",
    "DB_CONNECTION_ARGS": {
      "autorollback": true,
      "threadlocals": true
    },
    "DB_URI": "postgresql://quayuser:quaypass@quay-server:5432/quay",
    "DEFAULT_TAG_EXPIRATION": "2w",
    ....

  }

} http://quay-server:8080/api/v1/config/validate | jq</pre><p>
				The returned value is an array containing the errors found in the configuration. If the configuration is valid, an empty array <code class="literal">[]</code> is returned.
			</p></section><section class="section" id="determining_the_required_fields"><div class="titlepage"><div><div><h2 class="title">2.4. Determining the required fields</h2></div></div></div><p>
				You can determine the required fields by posting an empty configuration structure to the <code class="literal">config/validate</code> endpoint:
			</p><pre class="literallayout">curl -u quayconfig:secret --header 'Content-Type: application/json' --request POST --data '
{
  "config.yaml": {
  }

} http://quay-server:8080/api/v1/config/validate | jq</pre><p>
				The value returned is an array indicating which fields are required:
			</p><pre class="programlisting language-yaml">[
  {
    "FieldGroup": "Database",
    "Tags": [
      "DB_URI"
    ],
    "Message": "DB_URI is required."
  },
  {
    "FieldGroup": "DistributedStorage",
    "Tags": [
      "DISTRIBUTED_STORAGE_CONFIG"
    ],
    "Message": "DISTRIBUTED_STORAGE_CONFIG must contain at least one storage location."
  },
  {
    "FieldGroup": "HostSettings",
    "Tags": [
      "SERVER_HOSTNAME"
    ],
    "Message": "SERVER_HOSTNAME is required"
  },
  {
    "FieldGroup": "HostSettings",
    "Tags": [
      "SERVER_HOSTNAME"
    ],
    "Message": "SERVER_HOSTNAME must be of type Hostname"
  },
  {
    "FieldGroup": "Redis",
    "Tags": [
      "BUILDLOGS_REDIS"
    ],
    "Message": "BUILDLOGS_REDIS is required"
  }
]</pre></section></section><section class="chapter" id="release-notifications"><div class="titlepage"><div><div><h1 class="title">Chapter 3. Getting Red Hat Quay release notifications</h1></div></div></div><p>
			To keep up with the latest Red Hat Quay releases and other changes related to Red Hat Quay, you can sign up for update notifications on the <a class="link" href="https://access.redhat.com">Red Hat Customer Portal</a>. After signing up for notifications, you will receive notifications letting you know when there is new a Red Hat Quay version, updated documentation, or other Red Hat Quay news.
		</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
					Log into the <a class="link" href="https://access.redhat.com">Red Hat Customer Portal</a> with your Red Hat customer account credentials.
				</li><li class="listitem">
					Select your user name (upper-right corner) to see Red Hat Account and Customer Portal selections: 
					<span class="inlinemediaobject"><img src="images/notification-profile.png" alt="View account and portal selections"/></span>
				</li><li class="listitem">
					Select Notifications. Your profile activity page appears.
				</li><li class="listitem">
					Select the Notifications tab.
				</li><li class="listitem">
					Select Manage Notifications.
				</li><li class="listitem">
					Select Follow, then choose Products from the drop-down box.
				</li><li class="listitem">
					From the drop-down box next to the Products, search for and select Red Hat Quay: 
					<span class="inlinemediaobject"><img src="images/notification-follow.png" alt="Select Products from notifications box"/></span>
				</li><li class="listitem">
					Select the SAVE NOTIFICATION button. Going forward, you will receive notifications when there are changes to the Red Hat Quay product, such as a new release.
				</li></ol></div></section><section class="chapter" id="using-ssl-to-protect-quay"><div class="titlepage"><div><div><h1 class="title">Chapter 4. Using SSL to protect connections to Red Hat Quay</h1></div></div></div><section class="section" id="introduction_to_using_ssl"><div class="titlepage"><div><div><h2 class="title">4.1. Introduction to using SSL</h2></div></div></div><p>
				To configure Red Hat Quay with a <a class="link" href="https://en.wikipedia.org/wiki/Self-signed_certificate">self-signed certificate</a>, you need to create a Certificate Authority (CA) and then generate the required key and certificate files.
			</p><p>
				The following examples assume you have configured the server hostname <code class="literal">quay-server.example.com</code> using DNS or another naming mechanism, such as adding an entry in your <code class="literal">/etc/hosts</code> file:
			</p><pre class="literallayout">$ cat /etc/hosts
...
192.168.1.112   quay-server.example.com</pre></section><section class="section" id="create-a-ca-and-sign-a-certificate"><div class="titlepage"><div><div><h2 class="title">4.2. Create a Certificate Authority and sign a certificate</h2></div></div></div><p>
				At the end of this procedure, you will have a certificate file and a primary key file named <code class="literal">ssl.cert</code> and <code class="literal">ssl.key</code>, respectively.
			</p><section class="section" id="create_a_certificate_authority"><div class="titlepage"><div><div><h3 class="title">4.2.1. Create a Certificate Authority</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Generate the root CA key:
						</p><pre class="screen">$ openssl genrsa -out rootCA.key 2048</pre></li><li class="listitem"><p class="simpara">
							Generate the root CA cert:
						</p><pre class="screen">$ openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.pem</pre></li><li class="listitem"><p class="simpara">
							Enter the information that will be incorporated into your certificate request, including the server hostname, for example:
						</p><pre class="screen">Country Name (2 letter code) [XX]:IE
State or Province Name (full name) []:GALWAY
Locality Name (eg, city) [Default City]:GALWAY
Organization Name (eg, company) [Default Company Ltd]:QUAY
Organizational Unit Name (eg, section) []:DOCS
Common Name (eg, your name or your server's hostname) []:quay-server.example.com</pre></li></ol></div></section><section class="section" id="sign_a_certificate"><div class="titlepage"><div><div><h3 class="title">4.2.2. Sign a certificate</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Generate the server key:
						</p><pre class="screen">$ openssl genrsa -out ssl.key 2048</pre></li><li class="listitem"><p class="simpara">
							Generate a signing request:
						</p><pre class="screen">$ openssl req -new -key ssl.key -out ssl.csr</pre></li><li class="listitem"><p class="simpara">
							Enter the information that will be incorporated into your certificate request, including the server hostname, for example:
						</p><pre class="screen">Country Name (2 letter code) [XX]:IE
State or Province Name (full name) []:GALWAY
Locality Name (eg, city) [Default City]:GALWAY
Organization Name (eg, company) [Default Company Ltd]:QUAY
Organizational Unit Name (eg, section) []:DOCS
Common Name (eg, your name or your server's hostname) []:quay-server.example.com</pre></li><li class="listitem"><p class="simpara">
							Create a configuration file <code class="literal">openssl.cnf</code>, specifying the server hostname, for example:
						</p><div class="formalpara"><p class="title"><strong>openssl.cnf</strong></p><p>
								
<pre class="screen">[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
subjectAltName = @alt_names
[alt_names]
DNS.1 = quay-server.example.com
IP.1 = 192.168.1.112</pre>
							</p></div></li><li class="listitem"><p class="simpara">
							Use the configuration file to generate the certificate <code class="literal">ssl.cert</code>:
						</p><pre class="screen">$ openssl x509 -req -in ssl.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out ssl.cert -days 356 -extensions v3_req -extfile openssl.cnf</pre></li></ol></div></section></section><section class="section" id="configuring_ssl_using_the_command_line"><div class="titlepage"><div><div><h2 class="title">4.3. Configuring SSL using the command line</h2></div></div></div><p>
				Another option when configuring SSL is to use the command line interface.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Copy the certificate file and primary key file to your configuration directory, ensuring they are named <code class="literal">ssl.cert</code> and <code class="literal">ssl.key</code> respectively:
					</p><pre class="screen">$ cp ~/ssl.cert $QUAY/config
$ cp ~/ssl.key $QUAY/config
$ cd $QUAY/config</pre></li><li class="listitem"><p class="simpara">
						Edit the <code class="literal">config.yaml</code> file and specify that you want Quay to handle TLS:
					</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
							
<pre class="programlisting language-yaml">...
SERVER_HOSTNAME: quay-server.example.com
...
PREFERRED_URL_SCHEME: https
...</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						Stop the <code class="literal">Quay</code> container and restart the registry:
					</p><pre class="screen">$ sudo podman rm -f quay
$ sudo podman run -d --rm -p 80:8080 -p 443:8443 \
  --name=quay \
  -v $QUAY/config:/conf/stack:Z \
  -v $QUAY/storage:/datastorage:Z \
  registry.redhat.io/quay/quay-rhel8:v3.7.0</pre></li></ol></div></section><section class="section" id="configuring_ssl_using_the_ui"><div class="titlepage"><div><div><h2 class="title">4.4. Configuring SSL using the UI</h2></div></div></div><p>
				This section configures SSL using the Quay UI. To configure SSL using the command line interface, see the following section.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">Quay</code> container in configuration mode:
					</p><pre class="screen">$ sudo podman run --rm -it --name quay_config -p 80:8080 -p 443:8443 registry.redhat.io/quay/quay-rhel8:v3.7.0 config secret</pre></li><li class="listitem">
						In the Server Configuration section, select <code class="literal">Red Hat Quay handles TLS</code> for TLS. Upload the certificate file and private key file created earlier, ensuring that the Server Hostname matches the value used when creating the certs. Validate and download the updated configuration.
					</li><li class="listitem"><p class="simpara">
						Stop the <code class="literal">Quay</code> container and then restart the registry:
					</p><pre class="screen">$ sudo podman rm -f quay
$ sudo podman run -d --rm -p 80:8080 -p 443:8443 \
--name=quay \
-v $QUAY/config:/conf/stack:Z \
-v $QUAY/storage:/datastorage:Z \
registry.redhat.io/quay/quay-rhel8:v3.7.0</pre></li></ol></div></section><section class="section" id="testing_ssl_configuration_using_the_command_line"><div class="titlepage"><div><div><h2 class="title">4.5. Testing SSL configuration using the command line</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the <code class="literal">podman login</code> command to attempt to log in to the Quay registry with SSL enabled:
					</p><pre class="screen">$ sudo podman login quay-server.example.com
Username: quayadmin
Password:

Error: error authenticating creds for "quay-server.example.com": error pinging docker registry quay-server.example.com: Get "https://quay-server.example.com/v2/": x509: certificate signed by unknown authority</pre></li><li class="listitem"><p class="simpara">
						Podman does not trust self-signed certificates. As a workaround, use the <code class="literal">--tls-verify</code> option:
					</p><pre class="screen">$ sudo podman login --tls-verify=false quay-server.example.com
Username: quayadmin
Password:

Login Succeeded!</pre></li></ul></div><p>
				Configuring Podman to trust the root Certificate Authority (CA) is covered in a subsequent section.
			</p></section><section class="section" id="testing_ssl_configuration_using_the_browser"><div class="titlepage"><div><div><h2 class="title">4.6. Testing SSL configuration using the browser</h2></div></div></div><p>
				When you attempt to access the Quay registry, in this case, <code class="literal"><a class="link" href="https://quay-server.example.com">https://quay-server.example.com</a></code>, the browser warns of the potential risk:
			</p><p>
				<span class="inlinemediaobject"><img src="images/ssl-connection-not-private.png" alt="Potential risk"/></span>
			</p><p>
				Proceed to the log in screen, and the browser will notify you that the connection is not secure:
			</p><p>
				<span class="inlinemediaobject"><img src="images/ssl-connection-not-secure.png" alt="Connection not secure"/></span>
			</p><p>
				Configuring the system to trust the root Certificate Authority (CA) is covered in the subsequent section.
			</p></section><section class="section" id="configuring_podman_to_trust_the_certificate_authority"><div class="titlepage"><div><div><h2 class="title">4.7. Configuring podman to trust the Certificate Authority</h2></div></div></div><p>
				Podman uses two paths to locate the CA file, namely, <code class="literal">/etc/containers/certs.d/</code> and <code class="literal">/etc/docker/certs.d/</code>.
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Copy the root CA file to one of these locations, with the exact path determined by the server hostname, and naming the file <code class="literal">ca.crt</code>:
					</p><pre class="screen">$ sudo cp rootCA.pem /etc/containers/certs.d/quay-server.example.com/ca.crt</pre></li><li class="listitem"><p class="simpara">
						Alternatively, if you are using Docker, you can copy the root CA file to the equivalent Docker directory:
					</p><pre class="screen">$ sudo cp rootCA.pem /etc/docker/certs.d/quay-server.example.com/ca.crt</pre></li></ul></div><p>
				You should no longer need to use the <code class="literal">--tls-verify=false</code> option when logging in to the registry:
			</p><pre class="screen">$ sudo podman login quay-server.example.com

Username: quayadmin
Password:
Login Succeeded!</pre></section><section class="section" id="configuring_the_system_to_trust_the_certificate_authority"><div class="titlepage"><div><div><h2 class="title">4.8. Configuring the system to trust the certificate authority</h2></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Copy the root CA file to the consolidated system-wide trust store:
					</p><pre class="screen">$ sudo cp rootCA.pem /etc/pki/ca-trust/source/anchors/</pre></li><li class="listitem"><p class="simpara">
						Update the system-wide trust store configuration:
					</p><pre class="screen">$ sudo update-ca-trust extract</pre></li><li class="listitem"><p class="simpara">
						You can use the <code class="literal">trust list</code> command to ensure that the Quay server has been configured:
					</p><pre class="screen">$ trust list | grep quay
    label: quay-server.example.com</pre><p class="simpara">
						Now, when you browse to the registry at <code class="literal"><a class="link" href="https://quay-server.example.com">https://quay-server.example.com</a></code>, the lock icon shows that the connection is secure:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/ssl-connection-secure.png" alt="Connection not secure"/></span>
					</p></li><li class="listitem"><p class="simpara">
						To remove the root CA from system-wide trust, delete the file and update the configuration:
					</p><pre class="screen">$ sudo rm /etc/pki/ca-trust/source/anchors/rootCA.pem
$ sudo update-ca-trust extract
$ trust list | grep quay
$</pre></li></ol></div><p>
				More information can be found in the RHEL 8 documentation in the chapter <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/security_hardening/using-shared-system-certificates_security-hardening">Using shared system certificates</a>.
			</p></section></section><section class="chapter" id="config-custom-ssl-certs-manual"><div class="titlepage"><div><div><h1 class="title">Chapter 5. Adding TLS Certificates to the Red Hat Quay Container</h1></div></div></div><p>
			To add custom TLS certificates to Red Hat Quay, create a new directory named <code class="literal">extra_ca_certs/</code> beneath the Red Hat Quay config directory. Copy any required site-specific TLS certificates to this new directory.
		</p><section class="section" id="add-certificates-to-quay-container"><div class="titlepage"><div><div><h2 class="title">5.1. Add TLS certificates to Red Hat Quay</h2></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View certificate to be added to the container
					</p><pre class="screen">$ cat storage.crt
-----BEGIN CERTIFICATE-----
MIIDTTCCAjWgAwIBAgIJAMVr9ngjJhzbMA0GCSqGSIb3DQEBCwUAMD0xCzAJBgNV
[...]
-----END CERTIFICATE-----</pre></li><li class="listitem"><p class="simpara">
						Create certs directory and copy certificate there
					</p><pre class="screen">$ mkdir -p quay/config/extra_ca_certs
$ cp storage.crt quay/config/extra_ca_certs/
$ tree quay/config/
├── config.yaml
├── extra_ca_certs
│   ├── storage.crt</pre></li><li class="listitem"><p class="simpara">
						Obtain the <code class="literal">Quay</code> container’s <code class="literal">CONTAINER ID</code> with <code class="literal">podman ps</code>:
					</p><pre class="screen">$ sudo podman ps
CONTAINER ID        IMAGE                                COMMAND                  CREATED             STATUS              PORTS
5a3e82c4a75f        &lt;registry&gt;/&lt;repo&gt;/quay:v3.7.0 "/sbin/my_init"          24 hours ago        Up 18 hours         0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 443/tcp   grave_keller</pre></li><li class="listitem"><p class="simpara">
						Restart the container with that ID:
					</p><pre class="screen">$ sudo podman restart 5a3e82c4a75f</pre></li><li class="listitem"><p class="simpara">
						Examine the certificate copied into the container namespace:
					</p><pre class="screen">$ sudo podman exec -it 5a3e82c4a75f cat /etc/ssl/certs/storage.pem
-----BEGIN CERTIFICATE-----
MIIDTTCCAjWgAwIBAgIJAMVr9ngjJhzbMA0GCSqGSIb3DQEBCwUAMD0xCzAJBgNV</pre></li></ol></div></section><section class="section" id="config-custom-ssl-cert-kubernetes"><div class="titlepage"><div><div><h2 class="title">5.2. Add certs when deployed on Kubernetes</h2></div></div></div><p>
				When deployed on Kubernetes, Red Hat Quay mounts in a secret as a volume to store config assets. Unfortunately, this currently breaks the upload certificate function of the superuser panel.
			</p><p>
				To get around this error, a base64 encoded certificate can be added to the secret <span class="emphasis"><em>after</em></span> Red Hat Quay has been deployed. Here’s how:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Begin by base64 encoding the contents of the certificate:
					</p><pre class="screen">$ cat ca.crt
-----BEGIN CERTIFICATE-----
MIIDljCCAn6gAwIBAgIBATANBgkqhkiG9w0BAQsFADA5MRcwFQYDVQQKDA5MQUIu
TElCQ09SRS5TTzEeMBwGA1UEAwwVQ2VydGlmaWNhdGUgQXV0aG9yaXR5MB4XDTE2
MDExMjA2NTkxMFoXDTM2MDExMjA2NTkxMFowOTEXMBUGA1UECgwOTEFCLkxJQkNP
UkUuU08xHjAcBgNVBAMMFUNlcnRpZmljYXRlIEF1dGhvcml0eTCCASIwDQYJKoZI
[...]
-----END CERTIFICATE-----

$ cat ca.crt | base64 -w 0
[...]
c1psWGpqeGlPQmNEWkJPMjJ5d0pDemVnR2QNCnRsbW9JdEF4YnFSdVd3PT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</pre></li><li class="listitem"><p class="simpara">
						Use the <code class="literal">kubectl</code> tool to edit the quay-enterprise-config-secret.
					</p><pre class="screen">$ kubectl --namespace quay-enterprise edit secret/quay-enterprise-config-secret</pre></li><li class="listitem"><p class="simpara">
						Add an entry for the cert and paste the full base64 encoded string under the entry:
					</p><pre class="screen">  custom-cert.crt:
c1psWGpqeGlPQmNEWkJPMjJ5d0pDemVnR2QNCnRsbW9JdEF4YnFSdVd3PT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</pre></li><li class="listitem">
						Finally, recycle all Red Hat Quay pods. Use <code class="literal">kubectl delete</code> to remove all Red Hat Quay pods. The Red Hat Quay Deployment will automatically schedule replacement pods with the new certificate data.
					</li></ol></div></section></section><section class="chapter" id="proc_manage-log-storage"><div class="titlepage"><div><div><h1 class="title">Chapter 6. Configuring action log storage for Elasticsearch</h1></div></div></div><p>
			By default, the past three months of usage logs are stored in the Red Hat Quay database and exposed via the web UI on organization and repository levels. Appropriate administrative privileges are required to see log entries. For deployments with a large amount of logged operations, you can now store the usage logs in Elasticsearch instead of the Red Hat Quay database backend. To do this, you need to provide your own Elasticsearch stack, as it is not included with Red Hat Quay as a customizable component.
		</p><p>
			Enabling Elasticsearch logging can be done during Red Hat Quay deployment or post-deployment using the Red Hat Quay Config Tool. The resulting configuration is stored in the <code class="literal">config.yaml</code> file. Once configured, usage log access continues to be provided the same way, via the web UI for repositories and organizations.
		</p><p>
			Here’s how to configure action log storage to change it from the default Red Hat Quay database to use Elasticsearch:
		</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
					Obtain an Elasticsearch account.
				</li><li class="listitem">
					Open the Red Hat Quay Config Tool (either during or after Red Hat Quay deployment).
				</li><li class="listitem"><p class="simpara">
					Scroll to the <span class="emphasis"><em>Action Log Storage Configuration</em></span> setting and select <span class="emphasis"><em>Elasticsearch</em></span> instead of <span class="emphasis"><em>Database</em></span>. The following figure shows the Elasticsearch settings that appear:
				</p><p class="simpara">
					<span class="inlinemediaobject"><img src="images/elasticsearch_action_logs.png" alt="Choose Elasticsearch to view settings to store logs"/></span>
				</p></li><li class="listitem"><p class="simpara">
					Fill in the following information for your Elasticsearch instance:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Elasticsearch hostname</strong></span>: The hostname or IP address of the system providing the Elasticsearch service.
						</li><li class="listitem">
							<span class="strong strong"><strong>Elasticsearch port</strong></span>: The port number providing the Elasticsearch service on the host you just entered. Note that the port must be accessible from all systems running the Red Hat Quay registry. The default is TCP port 9200.
						</li><li class="listitem">
							<span class="strong strong"><strong>Elasticsearch access key</strong></span>: The access key needed to gain access to the Elastic search service, if required.
						</li><li class="listitem">
							<span class="strong strong"><strong>Elasticsearch secret key</strong></span>: The secret key needed to gain access to the Elastic search service, if required.
						</li><li class="listitem">
							<span class="strong strong"><strong>AWS region</strong></span>: If you are running on AWS, set the AWS region (otherwise, leave it blank).
						</li><li class="listitem">
							<span class="strong strong"><strong>Index prefix</strong></span>: Choose a prefix to attach to log entries.
						</li><li class="listitem"><p class="simpara">
							<span class="strong strong"><strong>Logs Producer</strong></span>: Choose either Elasticsearch (default) or Kinesis to direct logs to an intermediate Kinesis stream on AWS. You need to set up your own pipeline to send logs from Kinesis to Elasticsearch (for example, Logstash). The following figure shows additional fields you would need to fill in for Kinesis:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/kinesis_producer.png" alt="On AWS optionally set up an intermediate Kinesis stream"/></span>
						</p></li></ul></div></li><li class="listitem"><p class="simpara">
					If you chose Elasticsearch as the Logs Producer, no further configuration is needed. If you chose Kinesis, fill in the following:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Stream name</strong></span>: The name of the Kinesis stream.
						</li><li class="listitem">
							<span class="strong strong"><strong>AWS access key</strong></span>: The name of the AWS access key needed to gain access to the Kinesis stream, if required.
						</li><li class="listitem">
							<span class="strong strong"><strong>AWS secret key</strong></span>: The name of the AWS secret key needed to gain access to the Kinesis stream, if required.
						</li><li class="listitem">
							<span class="strong strong"><strong>AWS region</strong></span>: The AWS region.
						</li></ul></div></li><li class="listitem">
					When you are done, save the configuration. The Config Tool checks your settings. If there is a problem connecting to the Elasticsearch or Kinesis services, you will see an error and have the opportunity to continue editing. Otherwise, logging will begin to be directed to your Elasticsearch configuration after the cluster restarts with the new configuration.
				</li></ol></div></section><section class="chapter" id="clair-intro2"><div class="titlepage"><div><div><h1 class="title">Chapter 7. Clair Security Scanning</h1></div></div></div><p>
			Clair is a set of micro services that can be used with Red Hat Quay to perform vulnerability scanning of container images associated with a set of Linux operating systems. The micro services design of Clair makes it appropriate to run in a highly scalable configuration, where components can be scaled separately as appropriate for enterprise environments.
		</p><p>
			Clair uses the following vulnerability databases to scan for issues in your images:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Alpine SecDB database
				</li><li class="listitem">
					AWS UpdateInfo
				</li><li class="listitem">
					Debian Oval database
				</li><li class="listitem">
					Oracle Oval database
				</li><li class="listitem">
					RHEL Oval database
				</li><li class="listitem">
					SUSE Oval database
				</li><li class="listitem">
					Ubuntu Oval database
				</li><li class="listitem">
					Pyup.io (python) database
				</li></ul></div><p>
			For information on how Clair does security mapping with the different databases, see <a class="link" href="https://quay.github.io/claircore/concepts/severity_mapping.html">ClairCore Severity Mapping</a>.
		</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				With the release of Red Hat Quay 3.4, the new Clair V4 (image registry.redhat.io/quay/clair-rhel8 fully replaces the prior Clair V2 (image quay.io/redhat/clair-jwt). See below for how to run V2 in read-only mode while V4 is updating.
			</p></div></div><section class="section" id="clair-openshift"><div class="titlepage"><div><div><h2 class="title">7.1. Setting Up Clair on a Red Hat Quay OpenShift deployment</h2></div></div></div><section class="section" id="deploying_via_the_quay_operator"><div class="titlepage"><div><div><h3 class="title">7.1.1. Deploying Via the Quay Operator</h3></div></div></div><p>
					To set up Clair V4 on a new Red Hat Quay deployment on OpenShift, it is highly recommended to use the Quay Operator. By default, the Quay Operator will install or upgrade a Clair deployment along with your Red Hat Quay deployment and configure Clair security scanning automatically.
				</p></section><section class="section" id="clair-openshift-manual"><div class="titlepage"><div><div><h3 class="title">7.1.2. Manually Deploying Clair</h3></div></div></div><p>
					To configure Clair V4 on an existing Red Hat Quay OpenShift deployment running Clair V2, first ensure Red Hat Quay has been upgraded to at least version 3.4.0. Then use the following steps to manually set up Clair V4 alongside Clair V2.
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Set your current project to the name of the project in which Red Hat Quay is running. For example:
						</p><pre class="screen">$ oc project quay-enterprise</pre></li><li class="listitem"><p class="simpara">
							Create a Postgres deployment file for Clair v4 (for example, <code class="literal">clairv4-postgres.yaml</code>) as follows.
						</p><div class="formalpara"><p class="title"><strong>clairv4-postgres.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: clairv4-postgres
  namespace: quay-enterprise
  labels:
    quay-component: clairv4-postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      quay-component: clairv4-postgres
  template:
    metadata:
      labels:
        quay-component: clairv4-postgres
    spec:
      volumes:
        - name: postgres-data
          persistentVolumeClaim:
            claimName: clairv4-postgres
      containers:
        - name: postgres
          image: postgres:11.5
          imagePullPolicy: "IfNotPresent"
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_DB
              value: "clair"
            - name: POSTGRES_PASSWORD
              value: "postgres"
            - name: PGDATA
              value: "/etc/postgres/data"
          volumeMounts:
            - name: postgres-data
              mountPath: "/etc/postgres"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clairv4-postgres
  labels:
    quay-component: clairv4-postgres
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "5Gi"
    volumeName: "clairv4-postgres"
---
apiVersion: v1
kind: Service
metadata:
  name: clairv4-postgres
  labels:
    quay-component: clairv4-postgres
spec:
  type: ClusterIP
  ports:
    - port: 5432
      protocol: TCP
      name: postgres
      targetPort: 5432
  selector:
    quay-component: clairv4-postgres</pre>
							</p></div></li><li class="listitem"><p class="simpara">
							Deploy the postgres database as follows:
						</p><pre class="screen">$ oc create -f ./clairv4-postgres.yaml</pre></li><li class="listitem"><p class="simpara">
							Create a Clair <code class="literal">config.yaml</code> file to use for Clair v4. For example:
						</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">introspection_addr: :8089
http_listen_addr: :8080
log_level: debug
indexer:
  connstring: host=clairv4-postgres port=5432 dbname=clair user=postgres password=postgres sslmode=disable
  scanlock_retry: 10
  layer_scan_concurrency: 5
  migrations: true
matcher:
  connstring: host=clairv4-postgres port=5432 dbname=clair user=postgres password=postgres sslmode=disable
  max_conn_pool: 100
  run: ""
  migrations: true
  indexer_addr: clair-indexer
notifier:
  connstring: host=clairv4-postgres port=5432 dbname=clair user=postgres password=postgres sslmode=disable
  delivery: 1m
  poll_interval: 5m
  migrations: true
auth:
  psk:
    key: MTU5YzA4Y2ZkNzJoMQ== <span id="CO1-1"/><span class="callout">1</span>
    iss: ["quay"]
# tracing and metrics
trace:
  name: "jaeger"
  probability: 1
  jaeger:
    agent_endpoint: "localhost:6831"
    service_name: "clair"
metrics:
  name: "prometheus"</pre>
							</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO1-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									To generate a Clair pre-shared key (PSK), enable <code class="literal">scanning</code> in the Security Scanner section of the User Interface and click <code class="literal">Generate PSK</code>.
								</div></dd></dl></div></li></ol></div><p>
					More information about Clair’s configuration format can be found in <a class="link" href="https://quay.github.io/clair/reference/config.html">upstream Clair documentation</a>.
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a secret from the Clair <code class="literal">config.yaml</code>:
						</p><pre class="screen">$ oc create secret generic clairv4-config-secret --from-file=./config.yaml</pre></li><li class="listitem"><p class="simpara">
							Create the Clair v4 deployment file (for example, <code class="literal">clair-combo.yaml</code>) and modify it as necessary:
						</p><div class="formalpara"><p class="title"><strong>clair-combo.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    quay-component: clair-combo
  name: clair-combo
spec:
  replicas: 1
  selector:
    matchLabels:
      quay-component: clair-combo
  template:
    metadata:
      labels:
        quay-component: clair-combo
    spec:
      containers:
        - image: registry.redhat.io/quay/clair-rhel8:v3.7.0  <span id="CO2-1"/><span class="callout">1</span>
          imagePullPolicy: IfNotPresent
          name: clair-combo
          env:
            - name: CLAIR_CONF
              value: /clair/config.yaml
            - name: CLAIR_MODE
              value: combo
          ports:
            - containerPort: 8080
              name: clair-http
              protocol: TCP
            - containerPort: 8089
              name: clair-intro
              protocol: TCP
          volumeMounts:
            - mountPath: /clair/
              name: config
      imagePullSecrets:
        - name: redhat-pull-secret
      restartPolicy: Always
      volumes:
        - name: config
          secret:
            secretName: clairv4-config-secret
---
apiVersion: v1
kind: Service
metadata:
  name: clairv4 <span id="CO2-2"/><span class="callout">2</span>
  labels:
    quay-component: clair-combo
spec:
  ports:
    - name: clair-http
      port: 80
      protocol: TCP
      targetPort: 8080
    - name: clair-introspection
      port: 8089
      protocol: TCP
      targetPort: 8089
  selector:
    quay-component: clair-combo
  type: ClusterIP</pre>
							</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO2-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Change image to latest clair image name and version.
								</div></dd><dt><a href="#CO2-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									With the Service set to clairv4, the scanner endpoint for Clair v4 is entered later into the Red Hat Quay config.yaml in the <code class="literal">SECURITY_SCANNER_V4_ENDPOINT</code> as <code class="literal">http://clairv4</code>.
								</div></dd></dl></div></li><li class="listitem"><p class="simpara">
							Create the Clair v4 deployment as follows:
						</p><pre class="screen">$ oc create -f ./clair-combo.yaml</pre></li><li class="listitem"><p class="simpara">
							Modify the <code class="literal">config.yaml</code> file for your Red Hat Quay deployment to add the following entries at the end:
						</p><pre class="programlisting language-yaml">FEATURE_SECURITY_NOTIFICATIONS: true
FEATURE_SECURITY_SCANNER: true
SECURITY_SCANNER_V4_ENDPOINT: http://clairv4 <span id="CO3-1"/><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO3-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Identify the Clair v4 service endpoint
								</div></dd></dl></div></li><li class="listitem"><p class="simpara">
							Redeploy the modified <code class="literal">config.yaml</code> to the secret containing that file (for example, <code class="literal">quay-enterprise-config-secret</code>:
						</p><pre class="screen">$ oc delete secret quay-enterprise-config-secret
$ oc create secret generic quay-enterprise-config-secret --from-file=./config.yaml</pre></li><li class="listitem">
							For the new <code class="literal">config.yaml</code> to take effect, you need to restart the Red Hat Quay pods. Simply deleting the <code class="literal">quay-app</code> pods causes pods with the updated configuration to be deployed.
						</li></ol></div><p>
					At this point, images in any of the organizations identified in the namespace whitelist will be scanned by Clair v4.
				</p></section></section><section class="section" id="clair-standalone"><div class="titlepage"><div><div><h2 class="title">7.2. Setting up Clair on a non-OpenShift Red Hat Quay deployment</h2></div></div></div><p>
				For Red Hat Quay deployments not running on OpenShift, it is possible to configure Clair security scanning manually. Red Hat Quay deployments already running Clair V2 can use the instructions below to add Clair V4 to their deployment.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Deploy a (preferably fault-tolerant) Postgres database server. Note that Clair requires the <code class="literal">uuid-ossp</code> extension to be added to its Postgres database. If the user supplied in Clair’s <code class="literal">config.yaml</code> has the necessary privileges to create the extension then it will be added automatically by Clair itself. If not, then the extension must be added before starting Clair. If the extension is not present, the following error will be displayed when Clair attempts to start.
					</p><pre class="screen">ERROR: Please load the "uuid-ossp" extension. (SQLSTATE 42501)</pre></li><li class="listitem"><p class="simpara">
						Create a Clair config file in a specific folder, for example, <code class="literal">/etc/clairv4/config/config.yaml</code>).
					</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
							
<pre class="programlisting language-yaml">introspection_addr: :8089
http_listen_addr: :8080
log_level: debug
indexer:
  connstring: host=clairv4-postgres port=5432 dbname=clair user=postgres password=postgres sslmode=disable
  scanlock_retry: 10
  layer_scan_concurrency: 5
  migrations: true
matcher:
  connstring: host=clairv4-postgres port=5432 dbname=clair user=postgres password=postgres sslmode=disable
  max_conn_pool: 100
  run: ""
  migrations: true
  indexer_addr: clair-indexer
notifier:
  connstring: host=clairv4-postgres port=5432 dbname=clair user=postgres password=postgres sslmode=disable
  delivery_interval: 1m
  poll_interval: 5m
  migrations: true

# tracing and metrics
trace:
  name: "jaeger"
  probability: 1
  jaeger:
    agent_endpoint: "localhost:6831"
    service_name: "clair"
metrics:
  name: "prometheus"</pre>
						</p></div></li></ol></div><p>
				More information about Clair’s configuration format can be found in <a class="link" href="https://quay.github.io/clair/reference/config.html">upstream Clair documentation</a>.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Run Clair via the container image, mounting in the configuration from the file you created.
					</p><pre class="screen">$ podman run -p 8080:8080 -p 8089:8089 -e CLAIR_CONF=/clair/config.yaml -e CLAIR_MODE=combo -v /etc/clair4/config:/clair -d registry.redhat.io/quay/clair-rhel8:v3.7.0</pre></li><li class="listitem">
						Follow the remaining instructions from the previous section for configuring Red Hat Quay to use the new Clair V4 endpoint.
					</li></ol></div><p>
				Running multiple Clair containers in this fashion is also possible, but for deployment scenarios beyond a single container the use of a container orchestrator like Kubernetes or OpenShift is strongly recommended.
			</p></section><section class="section" id="clair-unmanaged"><div class="titlepage"><div><div><h2 class="title">7.3. Advanced Clair configuration</h2></div></div></div><section class="section" id="unmanaged_clair_configuration"><div class="titlepage"><div><div><h3 class="title">7.3.1. Unmanaged Clair configuration</h3></div></div></div><p>
					With Red Hat Quay 3.7, users can run an unmanaged Clair configuration on the Red Hat Quay OpenShift Container Platform Operator. This feature allows users to create an unmanaged Clair database, or run their custom Clair configuration without an unmanaged database.
				</p><section class="section" id="unnmanaging_a_clair_database"><div class="titlepage"><div><div><h4 class="title">7.3.1.1. Unnmanaging a Clair database</h4></div></div></div><p>
						An unmanaged Clair database allows the Red Hat Quay Operator to work in a geo-replicated environment, where multiple instances of the Operator must communicate with the same database. An unmanaged Clair database can also be used when a user requires a highly-available (HA) Clair database that exists outside of a cluster.
					</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								In the Quay Operator, set the <code class="literal">clairpostgres</code> component of the QuayRegistry custom resource to <code class="literal">unmanaged</code>:
							</p><pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: quay370
spec:
  configBundleSecret: config-bundle-secret
  components:
    - kind: objectstorage
      managed: false
    - kind: route
      managed: true
    - kind: tls
      managed: false
    - kind: clairpostgres
      managed: false</pre></li></ul></div></section><section class="section" id="configuring_a_custom_clair_database"><div class="titlepage"><div><div><h4 class="title">7.3.1.2. Configuring a custom Clair database</h4></div></div></div><p>
						The Red Hat Quay Operator for OpenShift Container Platform allows users to provide their own Clair configuration by editing the <code class="literal">configBundleSecret</code> parameter.
					</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Create a <code class="literal">clair-config.yaml</code> bundle secret:
							</p><pre class="programlisting language-terminal">$ oc create secret generic --from-file config.yaml=./config.yaml --from-file extra_ca_cert_rds-ca-2019-root.pem=./rds-ca-2019-root.pem --from-file clair-config.yaml=./clair-config-aws-rds-postgres_ca_cert.yaml --from-file ssl.cert=./ssl.cert --from-file ssl.key=./ssl.key config-bundle-secret</pre><p class="simpara">
								Example <code class="literal">clair-config.yaml</code> configuration:
							</p><pre class="programlisting language-yaml">auth:
    psk:
       iss:
          - quay
          - clairctl
       key: &lt;example_key&gt;
http_listen_addr: :8080
indexer:
    connstring: host=quay-server.example.com port=5432 dbname=quay user=clairuser password=clairpass sslrootcert=/run/certs/rds-ca-2019-root.pem sslmode=verify-ca
    migrations: true
log_level: debug
matcher:
    connstring: host=quay-server.example.com port=5432 dbname=quay user=clairuser password=clairpass sslrootcert=/run/certs/rds-ca-2019-root.pem sslmode=verify-ca
    migrations: true
metrics:
    name: prometheus
notifier:
    connstring: host=quay-server.example.com port=5432 dbname=quay user=clairuser password=clairpass sslrootcert=/run/certs/rds-ca-2019-root.pem sslmode=verify-ca
    migrations: true</pre><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
											The database certificate is mounted under <code class="literal">/run/certs/rds-ca-2019-root.pem</code> on the Clair application pod in the <code class="literal">clair-config.yaml</code>. It must be specified when configuring your <code class="literal">clair-config.yaml</code>.
										</li><li class="listitem">
											An example <code class="literal">clair-config.yaml</code> can be found at <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/deploy_red_hat_quay_on_openshift_with_the_quay_operator/quay_operator_features#clair-openshift-config">Clair on OpenShift config</a>.
										</li></ul></div></div></div></li><li class="listitem"><p class="simpara">
								Add the <code class="literal">clair-config.yaml</code> bundle secret to your <code class="literal">configBundleSecret</code>. For example:
							</p><pre class="programlisting language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: config-bundle-secret
  namespace: quay-enterprise
data:
  config.yaml: &lt;base64 encoded Quay config&gt;
  clair-config.yaml: &lt;base64 encoded Clair config&gt;
  extra_ca_cert_&lt;name&gt;: &lt;base64 encoded ca cert&gt;
  clair-ssl.crt: &gt;-
  clair-ssl.key: &gt;-</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									When updated, the provided <code class="literal">clair-config.yaml</code> is mounted into the Clair pod. Any fields not provided are automatically populated with defaults using the Clair configuration module.
								</p></div></div></li></ol></div><p>
						After proper configuration, the Clair application pod should return to a <code class="literal">Ready</code> state.
					</p></section></section><section class="section" id="running_a_custom_clair_configuration_with_a_literal_managed_literal_database"><div class="titlepage"><div><div><h3 class="title">7.3.2. Running a custom Clair configuration with a <code class="literal">managed</code> database</h3></div></div></div><p>
					In some cases, users might want to run a custom Clair configuration with a <code class="literal">managed</code> database. This is useful in the following scenarios:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							When a user wants to disable an updater.
						</li><li class="listitem"><p class="simpara">
							When a user is running in an air-gapped environment.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										If you are running Quay in an air-gapped environment, the <code class="literal">airgap</code> parameter of your <code class="literal">clair-config.yaml</code> must be set to <code class="literal">true</code>.
									</li><li class="listitem">
										If you are running Quay in an air-gapped environment, you should disable all updaters.
									</li></ul></div></div></div></li></ul></div><p>
					Use the steps in "Configuring a custom Clair database" to configure your database when <code class="literal">clairpostgres</code> is set to <code class="literal">managed</code>.
				</p><p>
					For more information about running Clair in an air-gapped environment, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html-single/deploy_red_hat_quay_on_openshift_with_the_quay_operator/index#clair-openshift-airgap-database">Configuring access to the Clair database in the air-gapped OpenShift cluster</a>.
				</p></section></section><section class="section" id="clair-using"><div class="titlepage"><div><div><h2 class="title">7.4. Using Clair</h2></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Log in to your Red Hat Quay cluster and select an organization for which you have configured Clair scanning.
					</li><li class="listitem"><p class="simpara">
						Select a repository from that organization that holds some images and select Tags from the left navigation. The following figure shows an example of a repository with two images that have been scanned:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/clair-reposcan.png" alt="Security scan information appears for scanned repository images"/></span>
					</p></li><li class="listitem"><p class="simpara">
						If vulnerabilities are found, select to under the Security Scan column for the image to see either all vulnerabilities or those that are fixable. The following figure shows information on all vulnerabilities found:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/clair-vulnerabilities.png" alt="See all vulnerabilities or only those that are fixable"/></span>
					</p></li></ol></div></section><section class="section" id="clair-cve"><div class="titlepage"><div><div><h2 class="title">7.5. CVE ratings from the National Vulnerability Database</h2></div></div></div><p>
				With Clair v4.2, enrichment data is now viewable in the Quay UI. Additionally, Clair v4.2 adds CVSS scores from the National Vulnerability Database for detected vulnerabilities.
			</p><p>
				With this change, if the vulnerability has a CVSS score that is within 2 levels of the distro’s score, the Quay UI present’s the distro’s score by default. For example:
			</p><p>
				<span class="inlinemediaobject"><img src="images/clair-4-2-enrichment-data.png" alt="Clair v4.2 data display"/></span>
			</p><p>
				This differs from the previous interface, which would only display the following information:
			</p><p>
				<span class="inlinemediaobject"><img src="images/clair-4-0-cve-report.png" alt="Clair v4 data display"/></span>
			</p></section><section class="section" id="clair-disconnected"><div class="titlepage"><div><div><h2 class="title">7.6. Configuring Clair for Disconnected Environments</h2></div></div></div><p>
				Clair utilizes a set of components called Updaters to handle the fetching and parsing of data from various vulnerability databases. These Updaters are set up by default to pull vulnerability data directly from the internet and work out of the box. For customers in disconnected environments without direct access to the internet this poses a problem. Clair supports these environments through the ability to work with different types of update workflows that take into account network isolation. Using the <code class="literal">clairctl</code> command line utility, any process can easily fetch Updater data from the internet via an open host, securely transfer the data to an isolated host, and then import the Updater data on the isolated host into Clair itself.
			</p><p>
				The steps are as follows.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						First ensure that your Clair configuration has disabled automated Updaters from running.
					</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
							
<pre class="programlisting language-yaml">matcher:
  disable_updaters: true</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						Export out the latest Updater data to a local archive. This requires the <code class="literal">clairctl</code> tool which can be run directly as a binary, or via the Clair container image. Assuming your Clair configuration is in <code class="literal">/etc/clairv4/config/config.yaml</code>, to run via the container image:
					</p><pre class="screen">$ podman run -it --rm -v /etc/clairv4/config:/cfg:Z -v /path/to/output/directory:/updaters:Z --entrypoint /bin/clairctl registry.redhat.io/quay/clair-rhel8:v3.7.0 --config /cfg/config.yaml export-updaters  /updaters/updaters.gz</pre><p class="simpara">
						Note that you need to explicitly reference the Clair configuration. This will create the Updater archive in <code class="literal">/etc/clairv4/updaters/updaters.gz</code>. If you want to ensure the archive was created without any errors from the source databases, you can supply the <code class="literal">--strict</code> flag to <code class="literal">clairctl</code>. The archive file should be copied over to a volume that is accessible from the disconnected host running Clair. From the disconnected host, use the same procedure now to import the archive into Clair.
					</p><pre class="screen">$ podman run -it --rm -v /etc/clairv4/config:/cfg:Z -v /path/to/output/directory:/updaters:Z --entrypoint /bin/clairctl registry.redhat.io/quay/clair-rhel8:v3.7.0 --config /cfg/config.yaml import-updaters /updaters/updaters.gz</pre></li></ol></div></section><section class="section" id="clair-updater-urls"><div class="titlepage"><div><div><h2 class="title">7.7. Clair updater URLs</h2></div></div></div><p>
				The following are the HTTP hosts and paths that Clair will attempt to talk to in a default configuration. This list is non-exhaustive, as some servers will issue redirects and some request URLs are constructed dynamically.
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						https://secdb.alpinelinux.org/
					</li><li class="listitem">
						http://repo.us-west-2.amazonaws.com/2018.03/updates/x86_64/mirror.list
					</li><li class="listitem">
						https://cdn.amazonlinux.com/2/core/latest/x86_64/mirror.list
					</li><li class="listitem">
						https://www.debian.org/security/oval/
					</li><li class="listitem">
						https://linux.oracle.com/security/oval/
					</li><li class="listitem">
						https://packages.vmware.com/photon/photon_oval_definitions/
					</li><li class="listitem">
						https://github.com/pyupio/safety-db/archive/
					</li><li class="listitem">
						https://catalog.redhat.com/api/containers/
					</li><li class="listitem">
						https://www.redhat.com/security/data/
					</li><li class="listitem">
						https://support.novell.com/security/oval/
					</li><li class="listitem">
						https://people.canonical.com/~ubuntu-security/oval/
					</li></ul></div></section><section class="section" id="clair-add-info"><div class="titlepage"><div><div><h2 class="title">7.8. Additional Information</h2></div></div></div><p>
				For detailed documentation on the internals of Clair, including how the microservices are structured, please see the <a class="link" href="https://quay.github.io/clair">Upstream Clair</a> and <a class="link" href="https://quay.github.io/claircore">ClairCore</a> documentation.
			</p></section></section><section class="chapter" id="container-security-operator-setup"><div class="titlepage"><div><div><h1 class="title">Chapter 8. Scan pod images with the Container Security Operator</h1></div></div></div><p>
			Using the <a class="link" href="https://operatorhub.io/operator/container-security-operator">Container Security Operator</a>, (CSO) you can scan container images associated with active pods, running on OpenShift (4.2 or later) and other Kubernetes platforms, for known vulnerabilities. The CSO:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Watches containers associated with pods on all or specified namespaces
				</li><li class="listitem">
					Queries the container registry where the containers came from for vulnerability information provided an image’s registry supports image scanning (such as a Quay registry with Clair scanning)
				</li><li class="listitem">
					Exposes vulnerabilities via the ImageManifestVuln object in the Kubernetes API
				</li></ul></div><p>
			Using the instructions here, the CSO is installed in the <code class="literal">marketplace-operators</code> namespace, so it is available to all namespaces on your OpenShift cluster.
		</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				To see instructions on installing the CSO on Kubernetes, select the Install button from the <a class="link" href="https://operatorhub.io/operator/container-security-operator">Container Security OperatorHub.io</a> page.
			</p></div></div><section class="section" id="run_the_cso_in_openshift"><div class="titlepage"><div><div><h2 class="title">8.1. Run the CSO in OpenShift</h2></div></div></div><p>
				To start using the CSO in OpenShift, do the following:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Go to Operators → OperatorHub (select Security) to see the available <code class="literal">Container Security</code> Operator.
					</li><li class="listitem">
						Select the <code class="literal">Container Security</code> Operator, then select <code class="literal">Install</code> to go to the Create Operator Subscription page.
					</li><li class="listitem">
						Check the settings (all namespaces and automatic approval strategy, by default), and select <code class="literal">Subscribe</code>. The <code class="literal">Container Security</code> appears after a few moments on the <code class="literal">Installed Operators</code> screen.
					</li><li class="listitem"><p class="simpara">
						Optionally, you can add custom certificates to the CSO. In this example, create a certificate named quay.crt in the current directory. Then run the following command to add the cert to the CSO (restart the Operator pod for the new certs to take effect):
					</p><pre class="screen">$ oc create secret generic container-security-operator-extra-certs --from-file=quay.crt -n openshift-operators</pre></li><li class="listitem"><p class="simpara">
						Open the OpenShift Dashboard (Home → Dashboards). A link to Image Security appears under the status section, with a listing of the number of vulnerabilities found so far. Select the link to see a Security breakdown, as shown in the following figure:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/cso-dashboard.png" alt="Access SCO scanning data from OpenShift dashboard"/></span>
					</p></li><li class="listitem"><p class="simpara">
						You can do one of two things at this point to follow up on any detected vulnerabilities:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Select the link to the vulnerability. You are taken to the container registry, Red Hat Quay or other registry where the container came from, where you can see information about the vulnerability. The following figure shows an example of detected vulnerabilities from a Quay.io registry:
							</p><p class="simpara">
								<span class="inlinemediaobject"><img src="images/cso-registry-vulnerable.png" alt="The CSO points you to a registry containing the vulnerable image"/></span>
							</p></li><li class="listitem"><p class="simpara">
								Select the namespaces link to go to the ImageManifestVuln screen, where you can see the name of the selected image and all namespaces where that image is running. The following figure indicates that a particular vulnerable image is running in two namespaces:
							</p><p class="simpara">
								<span class="inlinemediaobject"><img src="images/cso-namespace-vulnerable.png" alt="View namespaces a vulnerable image is running in"/></span>
							</p></li></ul></div></li></ol></div><p>
				At this point, you know what images are vulnerable, what you need to do to fix those vulnerabilities, and every namespace that the image was run in. So you can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Alert anyone running the image that they need to correct the vulnerability
					</li><li class="listitem">
						Stop the images from running (by deleting the deployment or other object that started the pod the image is in)
					</li></ul></div><p>
				Note that if you do delete the pod, it may take a few minutes for the vulnerability to reset on the dashboard.
			</p></section><section class="section" id="query_image_vulnerabilities_from_the_cli"><div class="titlepage"><div><div><h2 class="title">8.2. Query image vulnerabilities from the CLI</h2></div></div></div><p>
				You can query information on security from the command line. To query for detected vulnerabilities, type:
			</p><pre class="screen">$ oc get vuln --all-namespaces
NAMESPACE     NAME              AGE
default       sha256.ca90...    6m56s
skynet        sha256.ca90...    9m37s</pre><p>
				To display details for a particular vulnerability, identify one of the vulnerabilities, along with its namespace and the <code class="literal">describe</code> option. This example shows an active container whose image includes an RPM package with a vulnerability:
			</p><pre class="screen">$ oc describe vuln --namespace mynamespace sha256.ac50e3752...
Name:         sha256.ac50e3752...
Namespace:    quay-enterprise
...
Spec:
  Features:
    Name:            nss-util
    Namespace Name:  centos:7
    Version:         3.44.0-3.el7
    Versionformat:   rpm
    Vulnerabilities:
      Description: Network Security Services (NSS) is a set of libraries...</pre></section></section><section class="chapter" id="quay-bridge-operator"><div class="titlepage"><div><div><h1 class="title">Chapter 9. Integrate Red Hat Quay into OpenShift with the Bridge Operator</h1></div></div></div><p>
			Using the Quay Bridge Operator, you can replace the integrated container registry in OpenShift with a Red Hat Quay registry. By doing this, your integrated OpenShift registry becomes a highly available, enterprise-grade Red Hat Quay registry with enhanced role based access control (RBAC) features.
		</p><p>
			The primary goals of the Bridge Operator is to duplicate the features of the integrated OpenShift registry in the new Red Hat Quay registry. The features enabled with this Operator include:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
					Synchronizing OpenShift namespaces as Red Hat Quay organizations.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
							Creating Robot accounts for each default namespace service account
						</li><li class="listitem">
							Creating Secrets for each created Robot Account (associating each Robot Secret to a Service Account as Mountable and Image Pull Secret)
						</li><li class="listitem">
							Synchronizing OpenShift ImageStreams as Quay Repositories
						</li></ul></div></li><li class="listitem">
					Automatically rewriting new Builds making use of ImageStreams to output to Red Hat Quay
				</li><li class="listitem">
					Automatically importing an ImageStream tag once a build completes
				</li></ul></div><p>
			Using this procedure with the Quay Bridge Operator, you enable bi-directional communication between your Red Hat Quay and OpenShift clusters.
		</p><section class="section" id="running_the_quay_bridge_operator"><div class="titlepage"><div><div><h2 class="title">9.1. Running the Quay Bridge Operator</h2></div></div></div><section class="section" id="prerequisites"><div class="titlepage"><div><div><h3 class="title">9.1.1. Prerequisites</h3></div></div></div><p>
					Before setting up the Bridge Operator, have the following in place:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							An existing Red Hat Quay environment for which you have superuser permissions
						</li><li class="listitem">
							A Red Hat OpenShift Container Platform environment (4.2 or later is recommended) for which you have cluster administrator permissions
						</li><li class="listitem">
							An OpenShift command line tool (<code class="literal">oc</code> command)
						</li></ul></div></section><section class="section" id="setting_up_and_configuring_openshift_and_red_hat_quay"><div class="titlepage"><div><div><h3 class="title">9.1.2. Setting up and configuring OpenShift and Red Hat Quay</h3></div></div></div><p>
					Both Red Hat Quay and OpenShift configuration is required:
				</p></section><section class="section" id="red_hat_quay_setup"><div class="titlepage"><div><div><h3 class="title">9.1.3. Red Hat Quay setup</h3></div></div></div><p>
					Create a dedicated Red Hat Quay organization, and from a new application you create within that organization, generate an OAuth token to be used with the Quay Bridge Operator in OpenShift
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Log in to Red Hat Quay as a user with superuser access and select the organization for which the external application will be configured.
						</li><li class="listitem">
							In the left navigation, select Applications.
						</li><li class="listitem">
							Select <code class="literal">Create New Application</code> and entering a name for the new application (for example, <code class="literal">openshift</code>).
						</li><li class="listitem">
							With the new application displayed, select it.
						</li><li class="listitem">
							In the left navigation, select <code class="literal">Generate Token</code> to create a new OAuth2 token.
						</li><li class="listitem">
							Select all checkboxes to grant the access needed for the integration.
						</li><li class="listitem">
							Review the assigned permissions and then select <code class="literal">Authorize Application</code>, then confirm it.
						</li><li class="listitem">
							Copy and save the generated Access Token that appears to use in the next section.
						</li></ol></div></section><section class="section" id="openshift_setup"><div class="titlepage"><div><div><h3 class="title">9.1.4. OpenShift Setup</h3></div></div></div><p>
					Setting up OpenShift for the Quay Bridge Operator requires several steps, including:
				</p><section class="section" id="deploying_the_operator"><div class="titlepage"><div><div><h4 class="title">9.1.4.1. Deploying the Operator</h4></div></div></div><p>
						The fastest method for deploying the operator is to deploy from OperatorHub. From the Administrator perspective in the OpenShift Web Console, navigate to the Operators tab, and then select OperatorHub.
					</p><p>
						Search for Quay Bridge Operator and then select Install.
					</p><p>
						Select an Approval Strategy and then select Install which will deploy the operator to the cluster.
					</p></section><section class="section" id="creating_an_openshift_secret_for_the_oauth_token"><div class="titlepage"><div><div><h4 class="title">9.1.4.2. Creating an OpenShift secret for the OAuth token</h4></div></div></div><p>
						The Operator will use the previously obtained Access Token to communicate with Quay. Store this token within OpenShift as a secret.
					</p><p>
						Execute the following command to create a secret called <code class="literal">quay-integration</code> in the <code class="literal">openshift-operators</code> namespace with a key called <code class="literal">token</code> containing the access token:
					</p><pre class="programlisting language-bash">$ oc create secret -n openshift-operators generic quay-integration --from-literal=token=&lt;access_token&gt;</pre></section><section class="section" id="create_the_quayintegration_custom_resource"><div class="titlepage"><div><div><h4 class="title">9.1.4.3. Create the QuayIntegration Custom Resource</h4></div></div></div><p>
						Finally, to complete the integration between OpenShift and Quay, a <code class="literal">QuayIntegration</code> custom resource needs to be created. This can be completed in the Web Console or from the command line.
					</p><div class="formalpara"><p class="title"><strong>quay-integration.yaml</strong></p><p>
							
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayIntegration
metadata:
  name: example-quayintegration
spec:
  clusterID: openshift  <span id="CO4-1"/><span class="callout">1</span>
  credentialsSecret:
    namespace: openshift-operators
    name: quay-integration<span id="CO4-2"/><span class="callout">2</span>
  quayHostname: https://&lt;QUAY_URL&gt;   <span id="CO4-3"/><span class="callout">3</span>
  insecureRegistry: false <span id="CO4-4"/><span class="callout">4</span></pre>
						</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO4-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								The clusterID value should be unique across the entire ecosystem. This value is optional and defaults to <code class="literal">openshift</code>.
							</div></dd><dt><a href="#CO4-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								The <code class="literal">credentialsSecret</code> property refers to the namespace and name of the secret containing the token that was previously created.
							</div></dd><dt><a href="#CO4-3"><span class="callout">3</span></a> </dt><dd><div class="para">
								Replace QUAY_URL with the hostname of your Red Hat Quay instance.
							</div></dd><dt><a href="#CO4-4"><span class="callout">4</span></a> </dt><dd><div class="para">
								If Quay is using self signed certificates, set the property <code class="literal">insecureRegistry: true</code>.
							</div></dd></dl></div><p>
						Create the <code class="literal">QuayIntegration</code> Custom Resource:
					</p><pre class="programlisting language-bash">$ oc create -f quay-integration.yaml</pre><p>
						At this point a Quay integration resource is created, linking the OpenShift cluster to the Red Hat Quay instance. Organizations within Quay should be created for the related namespaces from the OpenShift environment
					</p></section></section></section></section><section class="chapter" id="repo-mirroring-in-red-hat-quay"><div class="titlepage"><div><div><h1 class="title">Chapter 10. Repository mirroring</h1></div></div></div><section class="section" id="mirroring-intro"><div class="titlepage"><div><div><h2 class="title">10.1. Repository mirroring</h2></div></div></div><p>
				Red Hat Quay repository mirroring lets you mirror images from external container registries (or another local registry) into your Red Hat Quay cluster. Using repository mirroring, you can synchronize images to Red Hat Quay based on repository names and tags.
			</p><p>
				From your Red Hat Quay cluster with repository mirroring enabled, you can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Choose a repository from an external registry to mirror
					</li><li class="listitem">
						Add credentials to access the external registry
					</li><li class="listitem">
						Identify specific container image repository names and tags to sync
					</li><li class="listitem">
						Set intervals at which a repository is synced
					</li><li class="listitem">
						Check the current state of synchronization
					</li></ul></div><p>
				To use the mirroring functionality, you need to:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Enable Repository Mirroring in the Red Hat Quay configuration
					</li><li class="listitem">
						Run a repository mirroring worker
					</li><li class="listitem">
						Create mirrored repositories
					</li></ul></div><p>
				All repository mirroring configuration can be performed using the configuration tool UI or via the Quay API
			</p></section><section class="section" id="mirroring-versus-georepl"><div class="titlepage"><div><div><h2 class="title">10.2. Repository mirroring versus geo-replication</h2></div></div></div><p>
				Quay geo-replication mirrors the entire image storage backend data between 2 or more different storage backends while the database is shared (one Quay registry with two different blob storage endpoints). The primary use cases for geo-replication are:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Speeding up access to the binary blobs for geographically dispersed setups
					</li><li class="listitem">
						Guaranteeing that the image content is the same across regions
					</li></ul></div><p>
				Repository mirroring synchronizes selected repositories (or subsets of repositories) from one registry to another. The registries are distinct, with registry is separate database and image storage. The primary use cases for mirroring are:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Independent registry deployments in different datacenters or regions, where a certain subset of the overall content is supposed to be shared across the datacenters / regions
					</li><li class="listitem">
						Automatic synchronization or mirroring of selected (whitelisted) upstream repositories from external registries into a local Quay deployment
					</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					Repository mirroring and geo-replication can be used simultaneously.
				</p></div></div><div class="table" id="idm45642555243648"><p class="title"><strong>Table 10.1. Red Hat Quay Repository mirroring versus geo-replication</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"/><col style="width: 33%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642555237056" scope="col">Feature / Capability</th><th align="left" valign="top" id="idm45642551766880" scope="col">Geo-replication</th><th align="left" valign="top" id="idm45642551765824" scope="col">Repository mirroring</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								What is the feature designed to do?
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								A shared, global registry
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								Distinct, different registries
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								What happens if replication or mirroring hasn’t been completed yet?
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								The remote copy is used (slower)
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								No image is served
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								Is access to all storage backends in both regions required?
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								Yes (all Red Hat Quay nodes)
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								No (distinct storage)
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								Can users push images from both sites to the same repository?
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								Yes
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								No
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								Is all registry content and configuration identical across all regions (shared database)
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								Yes
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								No
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								Can users select individual namespaces or repositories to be mirrored?
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								No,by default
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								Yes
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642555237056">
							<p>
								Can users apply filters to synchronization rules?
							</p>
							</td><td align="left" valign="top" headers="idm45642551766880">
							<p>
								No
							</p>
							</td><td align="left" valign="top" headers="idm45642551765824">
							<p>
								Yes
							</p>
							</td></tr></tbody></table></div></div></section><section class="section" id="mirroring-using"><div class="titlepage"><div><div><h2 class="title">10.3. Using repository mirroring</h2></div></div></div><p>
				Here are some features and limitations of Red Hat Quay repository mirroring:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						With repository mirroring, you can mirror an entire repository or selectively limit which images are synced. Filters can be based on a comma-separated list of tags, a range of tags, or other means of identifying tags through regular expressions.
					</li><li class="listitem">
						Once a repository is set as mirrored, you cannot manually add other images to that repository.
					</li><li class="listitem">
						Because the mirrored repository is based on the repository and tags you set, it will hold only the content represented by the repo/tag pair. In other words, if you change the tag so that some images in the repository no longer match, those images will be deleted.
					</li><li class="listitem">
						Only the designated robot can push images to a mirrored repository, superseding any role-based access control permissions set on the repository.
					</li><li class="listitem">
						With a mirrored repository, a user can pull images (given read permission) from the repository but not push images to the repository.
					</li><li class="listitem">
						Changing settings on your mirrored repository is done from the Mirrors tab on the Repositories page for the mirrored repository you create.
					</li><li class="listitem">
						Images are synced at set intervals, but can also be synced on demand.
					</li></ul></div></section><section class="section" id="mirroring_configuration_ui"><div class="titlepage"><div><div><h2 class="title">10.4. Mirroring configuration UI</h2></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">Quay</code> container in configuration mode and select the Enable Repository Mirroring check box. If you want to require HTTPS communications and verify certificates during mirroring, select the HTTPS and cert verification check box.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/repo_mirror_config.png" alt="Enable mirroring and require HTTPS and verified certificates"/></span>
					</p></li><li class="listitem">
						Validate and download the <code class="literal">configuration</code> file, and then restart Quay in registry mode using the updated config file.
					</li></ol></div></section><section class="section" id="config-fields-mirroring"><div class="titlepage"><div><div><h2 class="title">10.5. Mirroring configuration fields</h2></div></div></div><div class="table" id="idm45642553693776"><p class="title"><strong>Table 10.2. Mirroring configuration</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 17%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642553406544" scope="col">Field</th><th align="left" valign="top" id="idm45642553405456" scope="col">Type</th><th align="left" valign="top" id="idm45642553404368" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642553406544">
							<p>
								<span class="strong strong"><strong>FEATURE_REPO_MIRROR</strong></span>
							</p>
							</td><td align="left" valign="top" headers="idm45642553405456">
							<p>
								Boolean
							</p>
							</td><td align="left" valign="top" headers="idm45642553404368">
							<p>
								Enable or disable repository mirroring<br/><br/> <span class="strong strong"><strong>Default:</strong></span> <code class="literal">false</code>
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642553406544">
							<p>
								 
							</p>
							</td><td align="left" valign="top" headers="idm45642553405456">
							<p>
								 
							</p>
							</td><td align="left" valign="top" headers="idm45642553404368">
							<p>
								 
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642553406544">
							<p>
								<span class="strong strong"><strong>REPO_MIRROR_INTERVAL</strong></span>
							</p>
							</td><td align="left" valign="top" headers="idm45642553405456">
							<p>
								Number
							</p>
							</td><td align="left" valign="top" headers="idm45642553404368">
							<p>
								The number of seconds between checking for repository mirror candidates<br/><br/><span class="strong strong"><strong>Default:</strong></span> 30
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642553406544">
							<p>
								<span class="strong strong"><strong>REPO_MIRROR_SERVER_HOSTNAME</strong></span>
							</p>
							</td><td align="left" valign="top" headers="idm45642553405456">
							<p>
								String
							</p>
							</td><td align="left" valign="top" headers="idm45642553404368">
							<p>
								Replaces the <code class="literal">SERVER_HOSTNAME</code> as the destination for mirroring. <br/><br/><span class="strong strong"><strong>Default:</strong></span> None<br/><br/><span class="strong strong"><strong>Example</strong></span>:<br/><code class="literal">openshift-quay-service</code>
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642553406544">
							<p>
								<span class="strong strong"><strong>REPO_MIRROR_TLS_VERIFY</strong></span>
							</p>
							</td><td align="left" valign="top" headers="idm45642553405456">
							<p>
								Boolean
							</p>
							</td><td align="left" valign="top" headers="idm45642553404368">
							<p>
								Require HTTPS and verify certificates of Quay registry during mirror.<br/><br/> <span class="strong strong"><strong>Default:</strong></span> <code class="literal">false</code>
							</p>
							</td></tr></tbody></table></div></div></section><section class="section" id="mirroring-worker"><div class="titlepage"><div><div><h2 class="title">10.6. Mirroring worker</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To run the repository mirroring worker, start by running a <code class="literal">Quay</code> pod with the <code class="literal">repomirror</code> option:
					</p><pre class="screen">$ sudo podman run -d --name mirroring-worker \
  -v $QUAY/config:/conf/stack:Z \
  registry.redhat.io/quay/quay-rhel8:v3.7.0 repomirror</pre></li><li class="listitem"><p class="simpara">
						If you have configured TLS communications using a certificate <code class="literal">/root/ca.crt</code>, then the following example shows how to start the mirroring worker:
					</p><pre class="screen">$ sudo podman run -d --name mirroring-worker \
  -v $QUAY/config:/conf/stack:Z \
  -v /root/ca.crt:/etc/pki/ca-trust/source/anchors/ca.crt \
  registry.redhat.io/quay/quay-rhel8:v3.7.0 repomirror</pre></li></ul></div></section><section class="section" id="mirroring-creating-repo"><div class="titlepage"><div><div><h2 class="title">10.7. Creating a mirrored repository</h2></div></div></div><p>
				The steps shown in this section assume you already have enabled repository mirroring in the configuration for your Red Hat Quay cluster and that you have a deployed a mirroring worker.
			</p><p>
				When mirroring a repository from an external container registry, create a new private repository. Typically the same name is used as the target repository, for example, <code class="literal">quay-rhel8</code>:
			</p><p>
				<span class="inlinemediaobject"><img src="images/repo_quay_rhel8.png" alt="Create new Red Hat Quay repo"/></span>
			</p><section class="section" id="repository_mirroring_settings"><div class="titlepage"><div><div><h3 class="title">10.7.1. Repository mirroring settings</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							In the Settings tab, set the Repository State to <code class="literal">Mirror</code>:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/repo_mirror_create.png" alt="Create a new Red Hat Quay repo mirror"/></span>
						</p></li><li class="listitem"><p class="simpara">
							In the Mirror tab, enter the details for connecting to the external registry, along with the tags, scheduling and access information:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/repo-mirror-details-start.png" alt="Repository mirroring"/></span>
						</p></li><li class="listitem"><p class="simpara">
							Enter the details as required in the following fields:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<span class="strong strong"><strong>Registry Location:</strong></span> The external repository you want to mirror, for example, <code class="literal">registry.redhat.io/quay/quay-rhel8</code>
								</li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Tags:</strong></span> This field is required. You may enter a comma-separated list of individual tags or tag patterns. (See <span class="emphasis"><em>Tag Patterns</em></span> section for details.)
								</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
										In order for Quay to get the list of tags in the remote repository, one of the following requirements must be met:
									</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
												An image with the "latest" tag must exist in the remote repository <span class="emphasis"><em>OR</em></span>
											</li><li class="listitem">
												At least one explicit tag, without pattern matching, must exist in the list of tags that you specify
											</li></ul></div></div></div></li><li class="listitem">
									<span class="strong strong"><strong>Start Date:</strong></span> The date on which mirroring begins. The current date and time is used by default.
								</li><li class="listitem">
									<span class="strong strong"><strong>Sync Interval:</strong></span> Defaults to syncing every 24 hours. You can change that based on hours or days.
								</li><li class="listitem">
									<span class="strong strong"><strong>Robot User:</strong></span> Create a new robot account or choose an existing robot account to do the mirroring.
								</li><li class="listitem">
									<span class="strong strong"><strong>Username:</strong></span> The username for accessing the external registry holding the repository you are mirroring.
								</li><li class="listitem">
									<span class="strong strong"><strong>Password:</strong></span> The password associated with the Username. Note that the password cannot include characters that require an escape character (\).
								</li></ul></div></li></ol></div></section><section class="section" id="advanced_settings"><div class="titlepage"><div><div><h3 class="title">10.7.2. Advanced settings</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							In the Advanced Settings section, configure TLS and proxy, if required:
						</li><li class="listitem">
							<span class="strong strong"><strong>Verify TLS:</strong></span> Check this box if you want to require HTTPS and to verify certificates, when communicating with the target remote registry.
						</li><li class="listitem">
							<span class="strong strong"><strong>HTTP Proxy:</strong></span> Identify the HTTP proxy server needed to access the remote site, if one is required.
						</li><li class="listitem">
							<span class="strong strong"><strong>HTTPS Proxy:</strong></span> Identify the HTTPS proxy server needed to access the remote site, if one is required.
						</li><li class="listitem">
							<span class="strong strong"><strong>No Proxy:</strong></span> List of locations that do not require proxy
						</li></ul></div></section><section class="section" id="synchronize_now"><div class="titlepage"><div><div><h3 class="title">10.7.3. Synchronize now</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To perform an immediate mirroring operation, press the Sync Now button on the repository’s Mirroring tab. The logs are available on the Usage Logs tab:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/repo-mirror-usage-logs.png" alt="Usage logs"/></span>
						</p><p class="simpara">
							When the mirroring is complete, the images will appear in the Tags tab:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/repo-mirror-tags.png" alt="Repository mirroring tags"/></span>
						</p><p class="simpara">
							Below is an example of a completed Repository Mirroring screen:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/repo-mirror-details.png" alt="Repository mirroring details"/></span>
						</p></li></ul></div></section></section><section class="section" id="mirroring-events"><div class="titlepage"><div><div><h2 class="title">10.8. Event notifications for mirroring</h2></div></div></div><p>
				There are three notification events for repository mirroring:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Repository Mirror Started
					</li><li class="listitem">
						Repository Mirror Success
					</li><li class="listitem">
						Repository Mirror Unsuccessful
					</li></ul></div><p>
				The events can be configured inside the Settings tab for each repository, and all existing notification methods such as email, slack, Quay UI and webhooks are supported.
			</p></section><section class="section" id="mirroring-tag-patterns"><div class="titlepage"><div><div><h2 class="title">10.9. Mirroring tag patterns</h2></div></div></div><p>
				As noted above, at least one Tag must be explicitly entered (ie. not a tag pattern) <span class="emphasis"><em>or</em></span> the tag "latest" must exist in the report repository. (The tag "latest" will not be synced unless specified in the tag list.). This is required for Quay to get the list of tags in the remote repository to compare to the specified list to mirror.
			</p><section class="section" id="pattern_syntax"><div class="titlepage"><div><div><h3 class="title">10.9.1. Pattern syntax</h3></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><tbody><tr><td align="left" valign="top">
								<p>
									Pattern
								</p>
								</td><td align="left" valign="top">
								<p>
									Description
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									*
								</p>
								</td><td align="left" valign="top">
								<p>
									Matches all characters
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									?
								</p>
								</td><td align="left" valign="top">
								<p>
									Matches any single character
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									[seq]
								</p>
								</td><td align="left" valign="top">
								<p>
									Matches any character in <span class="emphasis"><em>seq</em></span>
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									[!seq]
								</p>
								</td><td align="left" valign="top">
								<p>
									Matches any character not in <span class="emphasis"><em>seq</em></span>
								</p>
								</td></tr></tbody></table></div></section><section class="section" id="example_tag_patterns"><div class="titlepage"><div><div><h3 class="title">10.9.2. Example tag patterns</h3></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><tbody><tr><td align="left" valign="top">
								<p>
									Example Pattern
								</p>
								</td><td align="left" valign="top">
								<p>
									Example Matches
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									v3*
								</p>
								</td><td align="left" valign="top">
								<p>
									v32, v3.1, v3.2, v3.2-4beta, v3.3
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									v3.*
								</p>
								</td><td align="left" valign="top">
								<p>
									v3.1, v3.2, v3.2-4beta
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									v3.?
								</p>
								</td><td align="left" valign="top">
								<p>
									v3.1, v3.2, v3.3
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									v3.[12]
								</p>
								</td><td align="left" valign="top">
								<p>
									v3.1, v3.2
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									v3.[12]*
								</p>
								</td><td align="left" valign="top">
								<p>
									v3.1, v3.2, v3.2-4beta
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									v3.[!1]*
								</p>
								</td><td align="left" valign="top">
								<p>
									v3.2, v3.2-4beta, v3.3
								</p>
								</td></tr></tbody></table></div></section></section><section class="section" id="mirroring-working-with"><div class="titlepage"><div><div><h2 class="title">10.10. Working with mirrored repositories</h2></div></div></div><p>
				Once you have created a mirrored repository, there are several ways you can work with that repository. Select your mirrored repository from the Repositories page and do any of the following:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="strong strong"><strong>Enable/disable the repository</strong></span>: Select the Mirroring button in the left column, then toggle the Enabled check box to enable or disable the repository temporarily.
					</li><li class="listitem"><p class="simpara">
						<span class="strong strong"><strong>Check mirror logs</strong></span>: To make sure the mirrored repository is working properly, you can check the mirror logs. To do that, select the Usage Logs button in the left column. Here’s an example:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/repo_mirror_logs.png" alt="View logs for your Red Hat Quay repo mirror"/></span>
					</p></li><li class="listitem">
						<span class="strong strong"><strong>Sync mirror now</strong></span>: To immediately sync the images in your repository, select the Sync Now button.
					</li><li class="listitem">
						<span class="strong strong"><strong>Change credentials</strong></span>: To change the username and password, select DELETE from the Credentials line. Then select None and add the username and password needed to log into the external registry when prompted.
					</li><li class="listitem">
						<span class="strong strong"><strong>Cancel mirroring</strong></span>: To stop mirroring, which keeps the current images available but stops new ones from being synced, select the CANCEL button.
					</li><li class="listitem"><p class="simpara">
						<span class="strong strong"><strong>Set robot permissions</strong></span>: Red Hat Quay robot accounts are named tokens that hold credentials for accessing external repositories. By assigning credentials to a robot, that robot can be used across multiple mirrored repositories that need to access the same external registry.
					</p><p class="simpara">
						You can assign an existing robot to a repository by going to Account Settings, then selecting the Robot Accounts icon in the left column. For the robot account, choose the link under the REPOSITORIES column. From the pop-up window, you can:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Check which repositories are assigned to that robot.
							</li><li class="listitem">
								Assign read, write or Admin privileges to that robot from the PERMISSION field shown in this figure: 
								<span class="inlinemediaobject"><img src="images/repo_mirror_robot_assign.png" alt="Assign a robot to mirrored repo"/></span>
							</li></ul></div></li><li class="listitem"><p class="simpara">
						<span class="strong strong"><strong>Change robot credentials</strong></span>: Robots can hold credentials such as Kubernetes secrets, Docker login information, and Mesos bundles. To change robot credentials, select the Options gear on the robot’s account line on the Robot Accounts window and choose View Credentials. Add the appropriate credentials for the external repository the robot needs to access.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/repo_mirror_robot_perm.png" alt="Assign permission to a robot"/></span>
					</p></li><li class="listitem">
						<span class="strong strong"><strong>Check and change general setting</strong></span>: Select the Settings button (gear icon) from the left column on the mirrored repository page. On the resulting page, you can change settings associated with the mirrored repository. In particular, you can change User and Robot Permissions, to specify exactly which users and robots can read from or write to the repo.
					</li></ul></div></section><section class="section" id="mirroring-recommend"><div class="titlepage"><div><div><h2 class="title">10.11. Repository mirroring recommendations</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Repository mirroring pods can run on any node including other nodes where Quay is already running
					</li><li class="listitem">
						Repository mirroring is scheduled in the database and run in batches. As a result, more workers could mean faster mirroring, since more batches will be processed.
					</li><li class="listitem"><p class="simpara">
						The optimal number of mirroring pods depends on:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								The total number of repositories to be mirrored
							</li><li class="listitem">
								The number of images and tags in the repositories and the frequency of changes
							</li><li class="listitem">
								Parallel batches
							</li></ul></div></li><li class="listitem">
						You should balance your mirroring schedule across all mirrored repositories, so that they do not all start up at the same time.
					</li><li class="listitem">
						For a mid-size deployment, with approximately 1000 users and 1000 repositories, and with roughly 100 mirrored repositories, it is expected that you would use 3-5 mirroring pods, scaling up to 10 if required.
					</li></ul></div></section></section><section class="chapter" id="ldap-authentication-setup-for-quay-enterprise"><div class="titlepage"><div><div><h1 class="title">Chapter 11. LDAP Authentication Setup for Red Hat Quay</h1></div></div></div><p>
			The Lightweight Directory Access Protocol (LDAP) is an open, vendor-neutral, industry standard application protocol for accessing and maintaining distributed directory information services over an Internet Protocol (IP) network. Red Hat Quay supports using LDAP as an identity provider.
		</p><section class="section" id="considerations_prior_to_enabling_ldap"><div class="titlepage"><div><div><h2 class="title">11.1. Considerations prior to enabling LDAP</h2></div></div></div><section class="section" id="considerations-for-existing-quay-deployments"><div class="titlepage"><div><div><h3 class="title">11.1.1. Existing Quay deployments</h3></div></div></div><p>
					Conflicts between user names can arise when you enable LDAP for an existing Quay deployment that already has users configured. Consider the scenario where a particular user, <code class="literal">alice</code>, was manually created in Quay prior to enabling LDAP. If the user name <code class="literal">alice</code> also exists in the LDAP directory, Quay will create a new user <code class="literal">alice-1</code> when <code class="literal">alice</code> logs in for the first time using LDAP, and will map the LDAP credentials to this account. This might not be want you want, for consistency reasons, and it is recommended that you remove any potentially conflicting local account names from Quay prior to enabling LDAP.
				</p></section><section class="section" id="considerations-for-manual-user-creation"><div class="titlepage"><div><div><h3 class="title">11.1.2. Manual User Creation and LDAP authentication</h3></div></div></div><p>
					When Quay is configured for LDAP, LDAP-authenticated users are automatically created in Quay’s database on first log in, if the configuration option <code class="literal">FEATURE_USER_CREATION</code> is set to <code class="literal">true</code>. If this option is set to <code class="literal">false</code>, the automatic user creation for LDAP users will fail and the user is not allowed to log in. In this scenario, the superuser needs to create the desired user account first. Conversely, if <code class="literal">FEATURE_USER_CREATION</code> is set to <code class="literal">true</code>, this also means that a user can still create an account from the Quay login screen, even if there is an equivalent user in LDAP.
				</p></section></section><section class="section" id="setup-ldap-configuration"><div class="titlepage"><div><div><h2 class="title">11.2. Set Up LDAP Configuration</h2></div></div></div><p>
				In the config tool, locate the Authentication section and select “LDAP” from the drop-down menu. Update LDAP configuration fields as required.
			</p><p>
				<span class="inlinemediaobject"><img src="images/authentication-ldap.png" alt="Fill in LDAP information"/></span>
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Here is an example of the resulting entry in the <span class="emphasis"><em>config.yaml</em></span> file:
					</li></ul></div><pre class="literallayout">AUTHENTICATION_TYPE: LDAP</pre><section class="section" id="full_ldap_uri"><div class="titlepage"><div><div><h3 class="title">11.2.1. Full LDAP URI</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-uri.png" alt="LDAP server URI"/></span>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-ssl.png" alt="LDAP server SSL"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The full LDAP URI, including the <span class="emphasis"><em>ldap://</em></span> or <span class="emphasis"><em>ldaps://</em></span> prefix.
						</li><li class="listitem">
							A URI beginning with <span class="emphasis"><em>ldaps://</em></span> will make use of the provided SSL certificate(s) for TLS setup.
						</li><li class="listitem">
							Here is an example of the resulting entry in the <span class="emphasis"><em>config.yaml</em></span> file:
						</li></ul></div><pre class="literallayout">LDAP_URI: ldaps://ldap.example.org</pre></section><section class="section" id="team_synchronization"><div class="titlepage"><div><div><h3 class="title">11.2.2. Team Synchronization</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-team-sync-1.png" alt="Team synchronization"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							If enabled, organization administrators who are also superusers can set teams to have their membership synchronized with a backing group in LDAP.
						</li></ul></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-team-sync-2.png" alt="Team synchronization"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The resynchronization duration is the period at which a team must be re-synchronized. Must be expressed in a duration string form: 30m, 1h, 1d.
						</li><li class="listitem">
							Optionally allow non-superusers to enable and manage team syncing under organizations in which they are administrators.
						</li><li class="listitem">
							Here is an example of the resulting entries in the <span class="emphasis"><em>config.yaml</em></span> file:
						</li></ul></div><pre class="literallayout">FEATURE_TEAM_SYNCING: true
TEAM_RESYNC_STALE_TIME: 60m
FEATURE_NONSUPERUSER_TEAM_SYNCING_SETUP: true</pre></section><section class="section" id="base_and_relative_distinguished_names"><div class="titlepage"><div><div><h3 class="title">11.2.3. Base and Relative Distinguished Names</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-basedn.png" alt="Distinguished Names"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							A Distinguished Name path which forms the base path for looking up all LDAP records. Example: <span class="emphasis"><em>dc=my,dc=domain,dc=com</em></span>
						</li><li class="listitem">
							Optional list of Distinguished Name path(s) which form the secondary base path(s) for looking up all user LDAP records, relative to the Base DN defined above. These path(s) will be tried if the user is not found via the primary relative DN.
						</li><li class="listitem">
							User Relative DN is relative to BaseDN. Example: <span class="emphasis"><em>ou=NYC</em></span> not <span class="emphasis"><em>ou=NYC,dc=example,dc=org</em></span>
						</li><li class="listitem">
							Multiple “Secondary User Relative DNs” may be entered if there are multiple Organizational Units where User objects are located at. Simply type in the Organizational Units and click on Add button to add multiple RDNs. Example: <span class="emphasis"><em>ou=Users,ou=NYC and ou=Users,ou=SFO</em></span>
						</li><li class="listitem">
							The "User Relative DN" searches with subtree scope. For example, if your Organization has Organizational Units NYC and SFO under the Users OU (<span class="emphasis"><em>ou=SFO,ou=Users</em></span> and <span class="emphasis"><em>ou=NYC,ou=Users</em></span>), Red Hat Quay can authenticate users from both the <span class="emphasis"><em>NYC</em></span> and <span class="emphasis"><em>SFO</em></span> Organizational Units if the User Relative DN is set to Users (<span class="emphasis"><em>ou=Users</em></span>).
						</li><li class="listitem">
							Here is an example of the resulting entries in the <span class="emphasis"><em>config.yaml</em></span> file:
						</li></ul></div><pre class="literallayout">LDAP_BASE_DN:
- dc=example
- dc=com
LDAP_USER_RDN:
- ou=users
LDAP_SECONDARY_USER_RDNS:
- ou=bots
- ou=external</pre></section><section class="section" id="additional_user_filters"><div class="titlepage"><div><div><h3 class="title">11.2.4. Additional User Filters</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-user-filter.png" alt="User filters"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							If specified, the additional filter used for all user lookup queries. Note that all Distinguished Names used in the filter must be <span class="strong strong"><strong>full</strong></span> paths; the Base DN is not added automatically here. <span class="strong strong"><strong>Must</strong></span> be wrapped in parens. Example: (&amp;(someFirstField=someValue)(someOtherField=someOtherValue))
						</li><li class="listitem">
							Here is an example of the resulting entry in the <span class="emphasis"><em>config.yaml</em></span> file:
						</li></ul></div><pre class="literallayout">LDAP_USER_FILTER: (memberof=cn=developers,ou=groups,dc=example,dc=com)</pre></section><section class="section" id="administrator_dn"><div class="titlepage"><div><div><h3 class="title">11.2.5. Administrator DN</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-admin-dn.png" alt="Administrator DN"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The Distinguished Name and password for the administrator account. This account must be able to login and view the records for all user accounts. Example: uid=admin,ou=employees,dc=my,dc=domain,dc=com
						</li><li class="listitem">
							The password will be stored in <span class="strong strong"><strong>plaintext</strong></span> inside the config.yaml, so setting up a dedicated account or using a password hash is highly recommended.
						</li><li class="listitem">
							Here is an example of the resulting entries in the <span class="emphasis"><em>config.yaml</em></span> file:
						</li></ul></div><pre class="literallayout">LDAP_ADMIN_DN: cn=admin,dc=example,dc=com
LDAP_ADMIN_PASSWD: changeme</pre></section><section class="section" id="uid_and_mail_attributes"><div class="titlepage"><div><div><h3 class="title">11.2.6. UID and Mail attributes</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-uid-mail.png" alt="UID and Mail"/></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The UID attribute is the name of the property field in LDAP user record to use as the <span class="strong strong"><strong>username</strong></span>. Typically "uid".
						</li><li class="listitem">
							The Mail attribute is the name of the property field in LDAP user record that stores user e-mail address(es). Typically "mail".
						</li><li class="listitem">
							Either of these may be used during login.
						</li><li class="listitem">
							The logged in username must exist in User Relative DN.
						</li><li class="listitem">
							<span class="emphasis"><em>sAMAccountName</em></span> is the UID attribute for against Microsoft Active Directory setups.
						</li><li class="listitem">
							Here is an example of the resulting entries in the <span class="emphasis"><em>config.yaml</em></span> file:
						</li></ul></div><pre class="literallayout">LDAP_UID_ATTR: uid
LDAP_EMAIL_ATTR: mail</pre></section><section class="section" id="validation"><div class="titlepage"><div><div><h3 class="title">11.2.7. Validation</h3></div></div></div><p>
					Once the configuration is completed, click on “Save Configuration Changes” button to validate the configuration.
				</p><p>
					<span class="inlinemediaobject"><img src="images/authentication-ldap-success.png" alt="Fill in LDAP information"/></span>
				</p><p>
					All validation must succeed before proceeding, or additional configuration may be performed by selecting the "Continue Editing" button.
				</p></section></section><section class="section" id="common-issues"><div class="titlepage"><div><div><h2 class="title">11.3. Common Issues</h2></div></div></div><p>
				<span class="strong strong"><strong><span class="emphasis"><em>Invalid credentials</em></span></strong></span>
			</p><p>
				Administrator DN or Administrator DN Password values are incorrect
			</p><p>
				<span class="strong strong"><strong><span class="emphasis"><em>Verification of superuser %USERNAME% failed: Username not found The user either does not exist in the remote authentication system OR LDAP auth is misconfigured.</em></span></strong></span>
			</p><p>
				Red Hat Quay can connect to the LDAP server via Username/Password specified in the Administrator DN fields however cannot find the current logged in user with the UID Attribute or Mail Attribute fields in the User Relative DN Path. Either current logged in user does not exist in User Relative DN Path, or Administrator DN user do not have rights to search/read this LDAP path.
			</p></section><section class="section" id="configure-ldap-superuser"><div class="titlepage"><div><div><h2 class="title">11.4. Configure an LDAP user as superuser</h2></div></div></div><p>
				Once LDAP is configured, you can log in to your Red Hat Quay instance with a valid LDAP username and password. You are prompted to confirm your Red Hat Quay username as shown in the following figure:
			</p><p>
				<span class="inlinemediaobject"><img src="images/confirm-ldap-username.png" alt="Confirm LDAP username for Red Hat Quay"/></span>
			</p><p>
				To attach superuser privilege to an LDAP user, modify the <span class="emphasis"><em>config.yaml</em></span> file with the username. For example:
			</p><pre class="literallayout">SUPER_USERS:
- testadmin</pre><p>
				Restart the Red Hat <code class="literal">Quay</code> container with the updated config.yaml file. The next time you log in, the user will have superuser privileges.
			</p></section></section><section class="chapter" id="prometheus-metrics-under-quay-enterprise"><div class="titlepage"><div><div><h1 class="title">Chapter 12. Prometheus and Grafana metrics under Red Hat Quay</h1></div></div></div><p>
			Red Hat Quay exports a <a class="link" href="https://prometheus.io/">Prometheus</a>- and Grafana-compatible endpoint on each instance to allow for easy monitoring and alerting.
		</p><section class="section" id="exposing-the-prometheus-endpoint"><div class="titlepage"><div><div><h2 class="title">12.1. Exposing the Prometheus endpoint</h2></div></div></div><section class="section" id="standalone_red_hat_quay"><div class="titlepage"><div><div><h3 class="title">12.1.1. Standalone Red Hat Quay</h3></div></div></div><p>
					When using <code class="literal">podman run</code> to start the <code class="literal">Quay</code> container, expose the metrics port <code class="literal">9091</code>:
				</p><pre class="literallayout">$ sudo podman run -d --rm -p 80:8080 -p 443:8443  -p 9091:9091\
   --name=quay \
   -v $QUAY/config:/conf/stack:Z \
   -v $QUAY/storage:/datastorage:Z \
   registry.redhat.io/quay/quay-rhel8:v3.7.0</pre><p>
					The metrics will now be available:
				</p><pre class="programlisting language-terminal">$ curl quay.example.com:9091/metrics</pre><p>
					See <a class="link" href="https://access.redhat.com/solutions/3750281">Monitoring Quay with Prometheus and Grafana</a> for details on configuring Prometheus and Grafana to monitor Quay repository counts.
				</p></section><section class="section" id="red_hat_quay_operator"><div class="titlepage"><div><div><h3 class="title">12.1.2. Red Hat Quay Operator</h3></div></div></div><p>
					Determine the cluster IP for the <code class="literal">quay-metrics</code> service:
				</p><pre class="programlisting language-terminal">$ oc get services -n quay-enterprise
NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                             AGE
example-registry-clair-app            ClusterIP   172.30.61.161    &lt;none&gt;        80/TCP,8089/TCP                     18h
example-registry-clair-postgres       ClusterIP   172.30.122.136   &lt;none&gt;        5432/TCP                            18h
example-registry-quay-app             ClusterIP   172.30.72.79     &lt;none&gt;        443/TCP,80/TCP,8081/TCP,55443/TCP   18h
example-registry-quay-config-editor   ClusterIP   172.30.185.61    &lt;none&gt;        80/TCP                              18h
example-registry-quay-database        ClusterIP   172.30.114.192   &lt;none&gt;        5432/TCP                            18h
example-registry-quay-metrics         ClusterIP   172.30.37.76     &lt;none&gt;        9091/TCP                            18h
example-registry-quay-redis           ClusterIP   172.30.157.248   &lt;none&gt;        6379/TCP                            18h</pre><p>
					Connect to your cluster and access the metrics using the cluster IP and port for the <code class="literal">quay-metrics</code> service:
				</p><pre class="programlisting language-terminal">$ oc debug node/master-0

sh-4.4# curl 172.30.37.76:9091/metrics

# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 4.0447e-05
go_gc_duration_seconds{quantile="0.25"} 6.2203e-05
...</pre></section><section class="section" id="setting-up-prometheus-to-consume-metrics"><div class="titlepage"><div><div><h3 class="title">12.1.3. Setting up Prometheus to consume metrics</h3></div></div></div><p>
					Prometheus needs a way to access all Red Hat Quay instances running in a cluster. In the typical setup, this is done by listing all the Red Hat Quay instances in a single named DNS entry, which is then given to Prometheus.
				</p></section><section class="section" id="dns-configuration-under-kubernetes"><div class="titlepage"><div><div><h3 class="title">12.1.4. DNS configuration under Kubernetes</h3></div></div></div><p>
					A simple <a class="link" href="http://kubernetes.io/docs/user-guide/services/">Kubernetes service</a> can be configured to provide the DNS entry for Prometheus.
				</p></section><section class="section" id="dns-configuration-for-a-manual-cluster"><div class="titlepage"><div><div><h3 class="title">12.1.5. DNS configuration for a manual cluster</h3></div></div></div><p>
					<a class="link" href="https://github.com/skynetservices/skydns">SkyDNS</a> is a simple solution for managing this DNS record when not using Kubernetes. SkyDNS can run on an <a class="link" href="https://github.com/coreos/etcd">etcd</a> cluster. Entries for each Red Hat Quay instance in the cluster can be added and removed in the etcd store. SkyDNS will regularly read them from there and update the list of Quay instances in the DNS record accordingly.
				</p></section></section><section class="section" id="metrics-intro"><div class="titlepage"><div><div><h2 class="title">12.2. Introduction to metrics</h2></div></div></div><p>
				Red Hat Quay provides metrics to help monitor the registry, including metrics for general registry usage, uploads, downloads, garbage collection, and authentication.
			</p><section class="section" id="metrics-general-registry-stats"><div class="titlepage"><div><div><h3 class="title">12.2.1. General registry statistics</h3></div></div></div><p>
					General registry statistics can indicate how large the registry has grown.
				</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642555055552" scope="col">Metric name</th><th align="left" valign="top" id="idm45642555054464" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642555055552">
								<p>
									quay_user_rows
								</p>
								</td><td align="left" valign="top" headers="idm45642555054464">
								<p>
									Number of users in the database
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642555055552">
								<p>
									quay_robot_rows
								</p>
								</td><td align="left" valign="top" headers="idm45642555054464">
								<p>
									Number of robot accounts in the database
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642555055552">
								<p>
									quay_org_rows
								</p>
								</td><td align="left" valign="top" headers="idm45642555054464">
								<p>
									Number of organizations in the database
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642555055552">
								<p>
									quay_repository_rows
								</p>
								</td><td align="left" valign="top" headers="idm45642555054464">
								<p>
									Number of repositories in the database
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642555055552">
								<p>
									quay_security_scanning_unscanned_images_remaining_total
								</p>
								</td><td align="left" valign="top" headers="idm45642555054464">
								<p>
									Number of images that are not scanned by the latest security scanner
								</p>
								</td></tr></tbody></table></div><div class="formalpara"><p class="title"><strong>Sample metrics output</strong></p><p>
						
<pre class="programlisting language-terminal"># HELP quay_user_rows number of users in the database
# TYPE quay_user_rows gauge
quay_user_rows{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="65",process_name="globalpromstats.py"} 3

# HELP quay_robot_rows number of robot accounts in the database
# TYPE quay_robot_rows gauge
quay_robot_rows{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="65",process_name="globalpromstats.py"} 2

# HELP quay_org_rows number of organizations in the database
# TYPE quay_org_rows gauge
quay_org_rows{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="65",process_name="globalpromstats.py"} 2

# HELP quay_repository_rows number of repositories in the database
# TYPE quay_repository_rows gauge
quay_repository_rows{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="65",process_name="globalpromstats.py"} 4

# HELP quay_security_scanning_unscanned_images_remaining number of images that are not scanned by the latest security scanner
# TYPE quay_security_scanning_unscanned_images_remaining gauge
quay_security_scanning_unscanned_images_remaining{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 5</pre>
					</p></div></section><section class="section" id="metrics-queue-items"><div class="titlepage"><div><div><h3 class="title">12.2.2. Queue items</h3></div></div></div><p>
					The <span class="emphasis"><em>queue items</em></span> metrics provide information on the multiple queues used by Quay for managing work.
				</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642551097376" scope="col">Metric name</th><th align="left" valign="top" id="idm45642551096288" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642551097376">
								<p>
									quay_queue_items_available
								</p>
								</td><td align="left" valign="top" headers="idm45642551096288">
								<p>
									Number of items in a specific queue
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642551097376">
								<p>
									quay_queue_items_locked
								</p>
								</td><td align="left" valign="top" headers="idm45642551096288">
								<p>
									Number of items that are running
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642551097376">
								<p>
									quay_queue_items_available_unlocked
								</p>
								</td><td align="left" valign="top" headers="idm45642551096288">
								<p>
									Number of items that are waiting to be processed
								</p>
								</td></tr></tbody></table></div><div class="itemizedlist"><p class="title"><strong>Metric labels</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							<span class="strong strong"><strong>queue_name:</strong></span> The name of the queue. One of:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									<span class="strong strong"><strong>exportactionlogs:</strong></span> Queued requests to export action logs. These logs are then processed and put in storage. A link is then sent to the requester via email.
								</li><li class="listitem">
									<span class="strong strong"><strong>namespacegc:</strong></span> Queued namespaces to be garbage collected
								</li><li class="listitem">
									<span class="strong strong"><strong>notification:</strong></span> Queue for repository notifications to be sent out
								</li><li class="listitem">
									<span class="strong strong"><strong>repositorygc:</strong></span> Queued repositories to be garbage collected
								</li><li class="listitem">
									<span class="strong strong"><strong>secscanv4:</strong></span> Notification queue specific for Clair V4
								</li><li class="listitem">
									<span class="strong strong"><strong>dockerfilebuild:</strong></span> Queue for Quay docker builds
								</li><li class="listitem">
									<span class="strong strong"><strong>imagestoragereplication:</strong></span> Queued blob to be replicated across multiple storages
								</li><li class="listitem">
									<span class="strong strong"><strong>chunk_cleanup:</strong></span> Queued blob segments that needs to be deleted. This is only used by some storage implementations, for example, Swift.
								</li></ul></div></li></ul></div><p>
					For example, the queue labelled <span class="strong strong"><strong>repositorygc</strong></span> contains the repositories marked for deletion by the repository garbage collection worker. For metrics with a <span class="strong strong"><strong>queue_name</strong></span> label of <span class="strong strong"><strong>repositorygc</strong></span>:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>quay_queue_items_locked</strong></span> is the number of repositories currently being deleted.
						</li><li class="listitem">
							<span class="strong strong"><strong>quay_queue_items_available_unlocked</strong></span> is the number of repositories waiting to get processed by the worker.
						</li></ul></div><div class="formalpara"><p class="title"><strong>Sample metrics output</strong></p><p>
						
<pre class="programlisting language-terminal"># HELP quay_queue_items_available number of queue items that have not expired
# TYPE quay_queue_items_available gauge
quay_queue_items_available{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="63",process_name="exportactionlogsworker.py",queue_name="exportactionlogs"} 0
...

# HELP quay_queue_items_available_unlocked number of queue items that have not expired and are not locked
# TYPE quay_queue_items_available_unlocked gauge
quay_queue_items_available_unlocked{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="63",process_name="exportactionlogsworker.py",queue_name="exportactionlogs"} 0
...

# HELP quay_queue_items_locked number of queue items that have been acquired
# TYPE quay_queue_items_locked gauge
quay_queue_items_locked{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="63",process_name="exportactionlogsworker.py",queue_name="exportactionlogs"} 0</pre>
					</p></div></section><section class="section" id="metrics-garbage-collection"><div class="titlepage"><div><div><h3 class="title">12.2.3. Garbage collection metrics</h3></div></div></div><p>
					These metrics show you how many resources have been removed from garbage collection (gc). They show many times the gc workers have run and how many namespaces, repositories, and blobs were removed.
				</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642553171040" scope="col">Metric name</th><th align="left" valign="top" id="idm45642553169952" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642553171040">
								<p>
									quay_gc_iterations_total
								</p>
								</td><td align="left" valign="top" headers="idm45642553169952">
								<p>
									Number of iterations by the GCWorker
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642553171040">
								<p>
									quay_gc_namespaces_purged_total
								</p>
								</td><td align="left" valign="top" headers="idm45642553169952">
								<p>
									Number of namespaces purged by the NamespaceGCWorker
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642553171040">
								<p>
									quay_gc_repos_purged_total
								</p>
								</td><td align="left" valign="top" headers="idm45642553169952">
								<p>
									Number of repositories purged by the RepositoryGCWorker or NamespaceGCWorker
								</p>
								</td></tr><tr><td align="left" valign="top" headers="idm45642553171040">
								<p>
									quay_gc_storage_blobs_deleted_total
								</p>
								</td><td align="left" valign="top" headers="idm45642553169952">
								<p>
									Number of storage blobs deleted
								</p>
								</td></tr></tbody></table></div><div class="formalpara"><p class="title"><strong>Sample metrics output</strong></p><p>
						
<pre class="programlisting language-terminal"># TYPE quay_gc_iterations_created gauge
quay_gc_iterations_created{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 1.6317823190189714e+09
...

# HELP quay_gc_iterations_total number of iterations by the GCWorker
# TYPE quay_gc_iterations_total counter
quay_gc_iterations_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 0
...

# TYPE quay_gc_namespaces_purged_created gauge
quay_gc_namespaces_purged_created{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 1.6317823190189433e+09
...

# HELP quay_gc_namespaces_purged_total number of namespaces purged by the NamespaceGCWorker
# TYPE quay_gc_namespaces_purged_total counter
quay_gc_namespaces_purged_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 0
....

# TYPE quay_gc_repos_purged_created gauge
quay_gc_repos_purged_created{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 1.631782319018925e+09
...

# HELP quay_gc_repos_purged_total number of repositories purged by the RepositoryGCWorker or NamespaceGCWorker
# TYPE quay_gc_repos_purged_total counter
quay_gc_repos_purged_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 0
...

# TYPE quay_gc_storage_blobs_deleted_created gauge
quay_gc_storage_blobs_deleted_created{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 1.6317823190189059e+09
...

# HELP quay_gc_storage_blobs_deleted_total number of storage blobs deleted
# TYPE quay_gc_storage_blobs_deleted_total counter
quay_gc_storage_blobs_deleted_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 0
...</pre>
					</p></div><section class="section" id="metrics-multipart-uploads"><div class="titlepage"><div><div><h4 class="title">12.2.3.1. Multipart uploads metrics</h4></div></div></div><p>
						The multipart uploads metrics show the number of blobs uploads to storage (S3, Rados, GoogleCloudStorage, RHOCS). These can help identify issues when Quay is unable to correctly upload blobs to storage.
					</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642559248048" scope="col">Metric name</th><th align="left" valign="top" id="idm45642559246960" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642559248048">
									<p>
										quay_multipart_uploads_started_total
									</p>
									</td><td align="left" valign="top" headers="idm45642559246960">
									<p>
										Number of multipart uploads to Quay storage that completed
									</p>
									</td></tr><tr><td align="left" valign="top" headers="idm45642559248048">
									<p>
										quay_multipart_uploads_completed_total
									</p>
									</td><td align="left" valign="top" headers="idm45642559246960">
									<p>
										Number of multipart uploads to Quay storage that started
									</p>
									</td></tr></tbody></table></div><div class="formalpara"><p class="title"><strong>Sample metrics output</strong></p><p>
							
<pre class="programlisting language-terminal"># TYPE quay_multipart_uploads_completed_created gauge
quay_multipart_uploads_completed_created{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 1.6317823308284895e+09
...

# HELP quay_multipart_uploads_completed_total number of multipart uploads to Quay storage that completed
# TYPE quay_multipart_uploads_completed_total counter
quay_multipart_uploads_completed_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 0

# TYPE quay_multipart_uploads_started_created gauge
quay_multipart_uploads_started_created{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 1.6317823308284352e+09
...

# HELP quay_multipart_uploads_started_total number of multipart uploads to Quay storage that started
# TYPE quay_multipart_uploads_started_total counter
quay_multipart_uploads_started_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="208",process_name="secscan:application"} 0
...</pre>
						</p></div></section></section><section class="section" id="metrics-image-push-pull"><div class="titlepage"><div><div><h3 class="title">12.2.4. Image push / pull metrics</h3></div></div></div><p>
					A number of metrics are available related to pushing and pulling images.
				</p><section class="section" id="image_pulls_total"><div class="titlepage"><div><div><h4 class="title">12.2.4.1. Image pulls total</h4></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642553670112" scope="col">Metric name</th><th align="left" valign="top" id="idm45642553669024" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642553670112">
									<p>
										quay_registry_image_pulls_total
									</p>
									</td><td align="left" valign="top" headers="idm45642553669024">
									<p>
										The number of images downloaded from the registry.
									</p>
									</td></tr></tbody></table></div><div class="itemizedlist"><p class="title"><strong>Metric labels</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								<span class="strong strong"><strong>protocol:</strong></span> the registry protocol used (should always be v2)
							</li><li class="listitem">
								<span class="strong strong"><strong>ref:</strong></span> ref used to pull - tag, manifest
							</li><li class="listitem">
								<span class="strong strong"><strong>status:</strong></span> http return code of the request
							</li></ul></div></section><section class="section" id="image_bytes_pulled"><div class="titlepage"><div><div><h4 class="title">12.2.4.2. Image bytes pulled</h4></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642551815408" scope="col">Metric name</th><th align="left" valign="top" id="idm45642551814320" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642551815408">
									<p>
										quay_registry_image_pulled_estimated_bytes_total
									</p>
									</td><td align="left" valign="top" headers="idm45642551814320">
									<p>
										The number of bytes downloaded from the registry
									</p>
									</td></tr></tbody></table></div><div class="itemizedlist"><p class="title"><strong>Metric labels</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								<span class="strong strong"><strong> protocol:</strong></span> the registry protocol used (should always be v2)
							</li></ul></div></section><section class="section" id="image_pushes_total"><div class="titlepage"><div><div><h4 class="title">12.2.4.3. Image pushes total</h4></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642553353376" scope="col">Metric name</th><th align="left" valign="top" id="idm45642553352288" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642553353376">
									<p>
										quay_registry_image_pushes_total
									</p>
									</td><td align="left" valign="top" headers="idm45642553352288">
									<p>
										The number of images uploaded from the registry.
									</p>
									</td></tr></tbody></table></div><div class="itemizedlist"><p class="title"><strong>Metric labels</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								<span class="strong strong"><strong>protocol:</strong></span> the registry protocol used (should always be v2)
							</li><li class="listitem">
								<span class="strong strong"><strong>pstatus:</strong></span> http return code of the request
							</li><li class="listitem">
								<span class="strong strong"><strong>pmedia_type:</strong></span> the uploaded manifest type
							</li></ul></div></section><section class="section" id="image_bytes_pushed"><div class="titlepage"><div><div><h4 class="title">12.2.4.4. Image bytes pushed</h4></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642553963328" scope="col">Metric name</th><th align="left" valign="top" id="idm45642553962240" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642553963328">
									<p>
										quay_registry_image_pushed_bytes_total
									</p>
									</td><td align="left" valign="top" headers="idm45642553962240">
									<p>
										The number of bytes uploaded to the registry
									</p>
									</td></tr></tbody></table></div><div class="formalpara"><p class="title"><strong>Sample metrics output</strong></p><p>
							
<pre class="programlisting language-terminal"># HELP quay_registry_image_pushed_bytes_total number of bytes pushed to the registry
# TYPE quay_registry_image_pushed_bytes_total counter
quay_registry_image_pushed_bytes_total{host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="221",process_name="registry:application"} 0
...</pre>
						</p></div></section></section><section class="section" id="metrics-authentication"><div class="titlepage"><div><div><h3 class="title">12.2.5. Authentication metrics</h3></div></div></div><p>
					The authentication metrics provide the number of authentication requests, labeled by type and whether it succeeded or not. For example, this metric could be used to monitor failed basic authentication requests.
				</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642553202224" scope="col">Metric name</th><th align="left" valign="top" id="idm45642553201136" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642553202224">
								<p>
									quay_authentication_attempts_total
								</p>
								</td><td align="left" valign="top" headers="idm45642553201136">
								<p>
									Number of authentication attempts across the registry and API
								</p>
								</td></tr></tbody></table></div><div class="itemizedlist"><p class="title"><strong>Metric labels</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							<span class="strong strong"><strong>auth_kind:</strong></span> The type of auth used, including:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									basic
								</li><li class="listitem">
									oauth
								</li><li class="listitem">
									credentials
								</li></ul></div></li><li class="listitem">
							<span class="strong strong"><strong>success:</strong></span> true or false
						</li></ul></div><div class="formalpara"><p class="title"><strong>Sample metrics output</strong></p><p>
						
<pre class="programlisting language-terminal"># TYPE quay_authentication_attempts_created gauge
quay_authentication_attempts_created{auth_kind="basic",host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="221",process_name="registry:application",success="True"} 1.6317843039374158e+09
...

# HELP quay_authentication_attempts_total number of authentication attempts across the registry and API
# TYPE quay_authentication_attempts_total counter
quay_authentication_attempts_total{auth_kind="basic",host="example-registry-quay-app-6df87f7b66-9tfn6",instance="",job="quay",pid="221",process_name="registry:application",success="True"} 2
...</pre>
					</p></div></section></section></section><section class="chapter" id="red-hat-quay-quota-management-and-enforcement"><div class="titlepage"><div><div><h1 class="title">Chapter 13. Red Hat Quay quota management and enforcement</h1></div></div></div><p>
			With Red Hat Quay 3.7, users have the ability to report storage consumption and to contain registry growth by establishing configured storage quota limits. On-premise Quay users are now equipped with the following capabilities to manage the capacity limits of their environment:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					<span class="strong strong"><strong>Quota reporting:</strong></span> With this feature, a superuser can track the storage consumption of all their organizations. Additionally, users can track the storage consumption of their assigned organization.
				</li><li class="listitem">
					<span class="strong strong"><strong>Quota management:</strong></span> With this feature, a superuser can define soft and hard checks for Red Hat Quay users. Soft checks tell users if the storage consumption of an organization reaches their configured threshold. Hard checks prevent users from pushing to the registry when storage consumption reaches the configured limit.
				</li></ul></div><p>
			Together, these features allow service owners of a Quay registry to define service level agreements and support a healthy resource budget.
		</p><section class="section" id="config-fields-quota"><div class="titlepage"><div><div><h2 class="title">13.1. Quota management configuration</h2></div></div></div><p>
				Quota management is now supported under the <code class="literal">FEATURE_QUOTA_MANAGEMENT</code> property and is turned off by default. To enable quota management, set the feature flag in your <code class="literal">config.yaml</code> to <code class="literal">true</code>:
			</p><pre class="programlisting language-yaml">FEATURE_QUOTA_MANAGEMENT: true</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					In Red Hat Quay 3.7, superuser privileges are required to create, update and delete quotas.
				</p></div></div><section class="section" id="default_quota"><div class="titlepage"><div><div><h3 class="title">13.1.1. Default quota</h3></div></div></div><p>
					To specify a system-wide default storage quota that is applied to every organization and user, use the <span class="strong strong"><strong>DEFAULT_SYSTEM_REJECT_QUOTA_BYTES</strong></span> configuration flag.
				</p><div class="table" id="idm45642553148816"><p class="title"><strong>Table 13.1. Default quota configuration</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 17%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642552930128" scope="col">Field</th><th align="left" valign="top" id="idm45642552929040" scope="col">Type</th><th align="left" valign="top" id="idm45642552927952" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642552930128">
								<p>
									<span class="strong strong"><strong>DEFAULT_SYSTEM_REJECT_QUOTA_BYTES</strong></span>
								</p>
								</td><td align="left" valign="top" headers="idm45642552929040">
								<p>
									String
								</p>
								</td><td align="left" valign="top" headers="idm45642552927952">
								<p>
									The quota size to apply to all organizations and users.<br/><br/> By default, no limit is set.
								</p>
								</td></tr></tbody></table></div></div><p>
					If you configure a specific quota for an organization or user, and then delete that quota, the system-wide default quota will apply if one has been set. Similarly, if you have configured a specific quota for an organization or user, and then modify the system-wide default quota, the updated system-wide default will override any specific settings.
				</p></section></section><section class="section" id="quota-management-arch"><div class="titlepage"><div><div><h2 class="title">13.2. Quota management architecture</h2></div></div></div><p>
				The <code class="literal">RepositorySize</code> database table holds the storage consumption, in bytes, of a Red Hat Quay repository within an organization. The sum of all repository sizes for an organization defines the current storage size of a Red Hat Quay organization. When an image push is initialized, the user’s organization storage is validated to check if it is beyond the configured quota limits. If an image push exceeds defined quota limitations, a soft or hard check occurs:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						For a soft check, users are notified.
					</li><li class="listitem">
						For a hard check, the push is stopped.
					</li></ul></div><p>
				If storage consumption is within configured quota limits, the push is allowed to proceed.
			</p><p>
				Image manifest deletion follows a similar flow, whereby the links between associated image tags and the manifest are deleted. Additionally, after the image manifest is deleted, the repository size is recalculated and updated in the <code class="literal">RepositorySize</code> table.
			</p></section><section class="section" id="quota-establishment-ui"><div class="titlepage"><div><div><h2 class="title">13.3. Establishing quota in Red Hat Quay UI</h2></div></div></div><p>
				The following procedure describes how you can report storage consumption and establish storage quota limits.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						A Red Hat Quay registry.
					</li><li class="listitem">
						A superuser account.
					</li><li class="listitem">
						Enough storage to meet the demands of quota limitations.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a new organization or choose an existing one. Initially, no quota is configured, as can be seen on the <span class="strong strong"><strong>Organization Settings</strong></span> tab:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-none-org-settings.png" alt="No Quota Configured"/></span>
					</p></li><li class="listitem"><p class="simpara">
						Log in to the registry as a superuser and navigate to the <span class="strong strong"><strong>Manage Organizations</strong></span> tab on the <span class="strong strong"><strong>Super User Admin Panel</strong></span>. Click the <span class="strong strong"><strong>Options</strong></span> icon of the organization for which you want to create storage quota limits:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-org-options.png" alt="Organization options"/></span>
					</p></li><li class="listitem"><p class="simpara">
						Click <span class="strong strong"><strong>Configure Quota</strong></span> and enter the initial quota, for example, <span class="strong strong"><strong>10 MB</strong></span>. Then click <span class="strong strong"><strong>Apply</strong></span> and <span class="strong strong"><strong>Close</strong></span>:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-init-10MB.png" alt="Initial quota"/></span>
					</p></li><li class="listitem"><p class="simpara">
						Check that the quota consumed shows <span class="strong strong"><strong>0 of 10 MB</strong></span> on the <span class="strong strong"><strong>Manage Organizations</strong></span> tab of the superuser panel:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-init-consumed.png" alt="Initial consumed quota"/></span>
					</p><p class="simpara">
						The consumed quota information is also available directly on the Organization page:
					</p><div class="formalpara"><p class="title"><strong>Initial consumed quota</strong></p><p>
							<span class="inlinemediaobject"><img src="images/quota-org-init-consumed.png" alt="Initial consumed quota"/></span>
						</p></div></li><li class="listitem"><p class="simpara">
						To increase the quota to 100MB, navigate to the <span class="strong strong"><strong>Manage Organizations</strong></span> tab on the superuser panel. Click the <span class="strong strong"><strong>Options</strong></span> icon and select <span class="strong strong"><strong>Configure Quota</strong></span>, setting the quota to 100 MB. Click <span class="strong strong"><strong>Apply</strong></span> and then <span class="strong strong"><strong>Close</strong></span>:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-increase-100MB.png" alt="Increase quota"/></span>
					</p></li><li class="listitem"><p class="simpara">
						Push a sample image to the organization from the command line:
					</p><div class="formalpara"><p class="title"><strong>Sample commands</strong></p><p>
							
<pre class="programlisting language-terminal">$ podman pull ubuntu:18.04

$ podman tag docker.io/library/ubuntu:18.04 example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:18.04

$ podman push --tls-verify=false example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:18.04</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						On the superuser panel, the quota consumed per organization is displayed:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-consumed-first.png" alt="Total Quota Consumed for first image"/></span>
					</p></li><li class="listitem"><p class="simpara">
						The Organization page shows the total proportion of the quota used by the image:
					</p><div class="formalpara"><p class="title"><strong>Total Quota Consumed for first image</strong></p><p>
							<span class="inlinemediaobject"><img src="images/quota-org-consumed-first.png" alt="Total Quota Consumed for first image"/></span>
						</p></div></li><li class="listitem"><p class="simpara">
						Pull, tag, and push a second image, for example, <code class="literal">nginx</code>:
					</p><div class="formalpara"><p class="title"><strong>Sample commands</strong></p><p>
							
<pre class="programlisting language-terminal">$ podman pull nginx

$ podman tag docker.io/library/nginx example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/nginx

$ podman push --tls-verify=false example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/nginx</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						The Organization page shows the total proportion of the quota used by each repository in that organization:
					</p><div class="formalpara"><p class="title"><strong>Total Quota Consumed for each repository</strong></p><p>
							<span class="inlinemediaobject"><img src="images/quota-org-consumed-second.png" alt="Total Quota Consumed for each repository"/></span>
						</p></div></li><li class="listitem"><p class="simpara">
						Create <span class="emphasis"><em>reject</em></span> and <span class="emphasis"><em>warning</em></span> limits:
					</p><p class="simpara">
						From the superuser panel, navigate to the <span class="strong strong"><strong>Manage Organizations</strong></span> tab. Click the <span class="strong strong"><strong>Options</strong></span> icon for the organization and select <span class="strong strong"><strong>Configure Quota</strong></span>. In the <span class="strong strong"><strong>Quota Policy</strong></span> section, with the <span class="strong strong"><strong>Action</strong></span> type set to <span class="strong strong"><strong>Reject</strong></span>, set the <span class="strong strong"><strong>Quota Threshold</strong></span> to <span class="strong strong"><strong>80</strong></span> and click <span class="strong strong"><strong>Add Limit</strong></span>:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-reject-80.png" alt="Reject limit"/></span>
					</p></li><li class="listitem"><p class="simpara">
						To create a <span class="emphasis"><em>warning</em></span> limit, select <span class="strong strong"><strong>Warning</strong></span> as the <span class="strong strong"><strong>Action</strong></span> type, set the <span class="strong strong"><strong>Quota Threshold</strong></span> to <span class="strong strong"><strong>70</strong></span> and click <span class="strong strong"><strong>Add Limit</strong></span>:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-su-warning-70.png" alt="Warning limit"/></span>
					</p></li><li class="listitem"><p class="simpara">
						Click <span class="strong strong"><strong>Close</strong></span> on the quota popup. The limits are viewable, but not editable, on the <span class="strong strong"><strong>Settings</strong></span> tab of the <span class="strong strong"><strong>Organization</strong></span> page:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="images/quota-org-quota-policy.png" alt="Quota policy in organization settings"/></span>
					</p></li><li class="listitem"><p class="simpara">
						Push an image where the reject limit is exceeded:
					</p><p class="simpara">
						Because the reject limit (80%) has been set to below the current repository size (~83%), the next push is rejected automatically.
					</p><div class="formalpara"><p class="title"><strong>Sample image push</strong></p><p>
							
<pre class="programlisting language-terminal">$ podman pull ubuntu:20.04

$ podman tag docker.io/library/ubuntu:20.04 example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:20.04

$ podman push --tls-verify=false example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:20.04</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Sample output when quota exceeded</strong></p><p>
							
<pre class="programlisting language-terminal">Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
WARN[0002] failed, retrying in 1s ... (1/3). Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace
Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
WARN[0005] failed, retrying in 1s ... (2/3). Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace
Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
WARN[0009] failed, retrying in 1s ... (3/3). Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace
Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						When limits are exceeded, notifications are displayed in the UI:
					</p><div class="formalpara"><p class="title"><strong>Quota notifications</strong></p><p>
							<span class="inlinemediaobject"><img src="images/quota-notifications.png" alt="Quota notifications"/></span>
						</p></div></li></ol></div></section><section class="section" id="quota-establishment-api"><div class="titlepage"><div><div><h2 class="title">13.4. Establishing quota with the Red Hat Quay API</h2></div></div></div><p>
				When an organization is first created, it does not have a quota applied. Use the <span class="strong strong"><strong>/api/v1/organization/{organization}/quota</strong></span> endpoint:
			</p><div class="formalpara"><p class="title"><strong>Sample command</strong></p><p>
					
<pre class="programlisting language-terminal">$ curl -k -X GET -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json'  https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg/quota  | jq</pre>
				</p></div><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
					
<pre class="programlisting language-terminal">[]</pre>
				</p></div><section class="section" id="setting_the_quota"><div class="titlepage"><div><div><h3 class="title">13.4.1. Setting the quota</h3></div></div></div><p>
					To set a quota for an organization, POST data to the <span class="strong strong"><strong>/api/v1/organization/{orgname}/quota</strong></span> endpoint: .Sample command
				</p><pre class="programlisting language-terminal">$ curl -k -X POST -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' -d '{"limit_bytes": 10485760}'  https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/namespacequota/testorg/quota | jq</pre><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
						
<pre class="programlisting language-terminal">"Created"</pre>
					</p></div></section><section class="section" id="viewing_the_quota"><div class="titlepage"><div><div><h3 class="title">13.4.2. Viewing the quota</h3></div></div></div><p>
					To see the applied quota, <code class="literal">GET</code> data from the <span class="strong strong"><strong>/api/v1/organization/{orgname}/quota</strong></span> endpoint:
				</p><div class="formalpara"><p class="title"><strong>Sample command</strong></p><p>
						
<pre class="programlisting language-terminal">$ curl -k -X GET -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json'  https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg/quota  | jq</pre>
					</p></div><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
						
<pre class="programlisting language-json">[
  {
    "id": 1,
    "limit_bytes": 10485760,
    "default_config": false,
    "limits": [],
    "default_config_exists": false
  }
]</pre>
					</p></div></section><section class="section" id="modifying_the_quota"><div class="titlepage"><div><div><h3 class="title">13.4.3. Modifying the quota</h3></div></div></div><p>
					To change the existing quota, in this instance from 10 MB to 100 MB, PUT data to the <span class="strong strong"><strong>/api/v1/organization/{orgname}/quota/{quota_id}</strong></span> endpoint:
				</p><div class="formalpara"><p class="title"><strong>Sample command</strong></p><p>
						
<pre class="programlisting language-terminal">$ curl -k -X PUT -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' -d '{"limit_bytes": 104857600}'  https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg/quota/1 | jq</pre>
					</p></div><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
						
<pre class="programlisting language-json">{
  "id": 1,
  "limit_bytes": 104857600,
  "default_config": false,
  "limits": [],
  "default_config_exists": false
}</pre>
					</p></div></section><section class="section" id="pushing_images"><div class="titlepage"><div><div><h3 class="title">13.4.4. Pushing images</h3></div></div></div><p>
					To see the storage consumed, push various images to the organization.
				</p><section class="section" id="pushing_ubuntu_18_04"><div class="titlepage"><div><div><h4 class="title">13.4.4.1. Pushing ubuntu:18.04</h4></div></div></div><p>
						Push ubuntu:18.04 to the organization from the command line:
					</p><div class="formalpara"><p class="title"><strong>Sample commands</strong></p><p>
							
<pre class="programlisting language-terminal">$ podman pull ubuntu:18.04

$ podman tag docker.io/library/ubuntu:18.04 example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:18.04

$ podman push --tls-verify=false example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:18.04</pre>
						</p></div></section><section class="section" id="using_the_api_to_view_quota_usage"><div class="titlepage"><div><div><h4 class="title">13.4.4.2. Using the API to view quota usage</h4></div></div></div><p>
						To view the storage consumed, <code class="literal">GET</code> data from the <span class="strong strong"><strong>/api/v1/repository</strong></span> endpoint:
					</p><div class="formalpara"><p class="title"><strong>Sample command</strong></p><p>
							
<pre class="programlisting language-terminal">$ curl -k -X GET -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' 'https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/repository?last_modified=true&amp;namespace=testorg&amp;popularity=true&amp;public=true&amp;quota=true' | jq</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
							
<pre class="programlisting language-json">{
  "repositories": [
    {
      "namespace": "testorg",
      "name": "ubuntu",
      "description": null,
      "is_public": false,
      "kind": "image",
      "state": "NORMAL",
      "quota_report": {
        "quota_bytes": 27959066,
        "configured_quota": 104857600
      },
      "last_modified": 1651225630,
      "popularity": 0,
      "is_starred": false
    }
  ]
}</pre>
						</p></div></section><section class="section" id="pushing_another_image"><div class="titlepage"><div><div><h4 class="title">13.4.4.3. Pushing another image</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Pull, tag, and push a second image, for example, <code class="literal">nginx</code>:
							</p><div class="formalpara"><p class="title"><strong>Sample commands</strong></p><p>
									
<pre class="programlisting language-terminal">$ podman pull nginx

$ podman tag docker.io/library/nginx example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/nginx

$ podman push --tls-verify=false example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/nginx</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								To view the quota report for the repositories in the organization, use the <span class="strong strong"><strong>/api/v1/repository</strong></span> endpoint:
							</p><div class="formalpara"><p class="title"><strong>Sample command</strong></p><p>
									
<pre class="programlisting language-terminal">$ curl -k -X GET -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' 'https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/repository?last_modified=true&amp;namespace=testorg&amp;popularity=true&amp;public=true&amp;quota=true'</pre>
								</p></div><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
									
<pre class="programlisting language-json">{
  "repositories": [
    {
      "namespace": "testorg",
      "name": "ubuntu",
      "description": null,
      "is_public": false,
      "kind": "image",
      "state": "NORMAL",
      "quota_report": {
        "quota_bytes": 27959066,
        "configured_quota": 104857600
      },
      "last_modified": 1651225630,
      "popularity": 0,
      "is_starred": false
    },
    {
      "namespace": "testorg",
      "name": "nginx",
      "description": null,
      "is_public": false,
      "kind": "image",
      "state": "NORMAL",
      "quota_report": {
        "quota_bytes": 59231659,
        "configured_quota": 104857600
      },
      "last_modified": 1651229507,
      "popularity": 0,
      "is_starred": false
    }
  ]
}</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								To view the quota information in the organization details, use the <span class="strong strong"><strong>/api/v1/organization/{orgname}</strong></span> endpoint:
							</p><div class="formalpara"><p class="title"><strong>Sample command</strong></p><p>
									
<pre class="programlisting language-terminal">$ curl -k -X GET -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' 'https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg' | jq</pre>
								</p></div><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
									
<pre class="programlisting language-json">{
  "name": "testorg",
  ...
  "quotas": [
    {
      "id": 1,
      "limit_bytes": 104857600,
      "limits": []
    }
  ],
  "quota_report": {
    "quota_bytes": 87190725,
    "configured_quota": 104857600
  }
}</pre>
								</p></div></li></ol></div></section></section><section class="section" id="rejecting_pushes_using_quota_limits"><div class="titlepage"><div><div><h3 class="title">13.4.5. Rejecting pushes using quota limits</h3></div></div></div><p>
					If an image push exceeds defined quota limitations, a soft or hard check occurs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							For a soft check, or <span class="emphasis"><em>warning</em></span>, users are notified.
						</li><li class="listitem">
							For a hard check, or <span class="emphasis"><em>reject</em></span>, the push is terminated.
						</li></ul></div><section class="section" id="setting_reject_and_warning_limits"><div class="titlepage"><div><div><h4 class="title">13.4.5.1. Setting reject and warning limits</h4></div></div></div><p>
						To set <span class="emphasis"><em>reject</em></span> and <span class="emphasis"><em>warning</em></span> limits, POST data to the <span class="strong strong"><strong>/api/v1/organization/{orgname}/quota/{quota_id}/limit</strong></span> endpoint:
					</p><div class="formalpara"><p class="title"><strong>Sample reject limit command</strong></p><p>
							
<pre class="programlisting language-terminal">$ curl -k -X POST -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' -d '{"type":"Reject","threshold_percent":80}'  https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg/quota/1/limit</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Sample warning limit command</strong></p><p>
							
<pre class="programlisting language-terminal">$ curl -k -X POST -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json' -d '{"type":"Warning","threshold_percent":50}'  https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg/quota/1/limit</pre>
						</p></div></section><section class="section" id="viewing_reject_and_warning_limits"><div class="titlepage"><div><div><h4 class="title">13.4.5.2. Viewing reject and warning limits</h4></div></div></div><p>
						To view the <span class="emphasis"><em>reject</em></span> and <span class="emphasis"><em>warning</em></span> limits, use the <span class="strong strong"><strong>/api/v1/organization/{orgname}/quota</strong></span> endpoint:
					</p><div class="formalpara"><p class="title"><strong>View quota limits</strong></p><p>
							
<pre class="programlisting language-terminal">$  curl -k -X GET -H "Authorization: Bearer &lt;token&gt;" -H 'Content-Type: application/json'  https://example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/api/v1/organization/testorg/quota | jq</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Sample output for quota limits</strong></p><p>
							
<pre class="programlisting language-json">[
  {
    "id": 1,
    "limit_bytes": 104857600,
    "default_config": false,
    "limits": [
      {
        "id": 2,
        "type": "Warning",
        "limit_percent": 50
      },
      {
        "id": 1,
        "type": "Reject",
        "limit_percent": 80
      }
    ],
    "default_config_exists": false
  }
]</pre>
						</p></div></section><section class="section" id="pushing_an_image_when_the_reject_limit_is_exceeded"><div class="titlepage"><div><div><h4 class="title">13.4.5.3. Pushing an image when the reject limit is exceeded</h4></div></div></div><p>
						In this example, the reject limit (80%) has been set to below the current repository size (~83%), so the next push should automatically be rejected.
					</p><p>
						Push a sample image to the organization from the command line:
					</p><div class="formalpara"><p class="title"><strong>Sample image push</strong></p><p>
							
<pre class="programlisting language-terminal">$ podman pull ubuntu:20.04

$ podman tag docker.io/library/ubuntu:20.04 example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:20.04

$ podman push --tls-verify=false example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org/testorg/ubuntu:20.04</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Sample output when quota exceeded</strong></p><p>
							
<pre class="programlisting language-terminal">Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
WARN[0002] failed, retrying in 1s ... (1/3). Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace
Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
WARN[0005] failed, retrying in 1s ... (2/3). Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace
Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
WARN[0009] failed, retrying in 1s ... (3/3). Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace
Getting image source signatures
Copying blob d4dfaa212623 [--------------------------------------] 8.0b / 3.5KiB
Copying blob cba97cc5811c [--------------------------------------] 8.0b / 15.0KiB
Copying blob 0c78fac124da [--------------------------------------] 8.0b / 71.8MiB
Error: Error writing blob: Error initiating layer upload to /v2/testorg/ubuntu/blobs/uploads/ in example-registry-quay-quay-enterprise.apps.docs.gcp.quaydev.org: denied: Quota has been exceeded on namespace</pre>
						</p></div></section><section class="section" id="notifications_for_limits_exceeded"><div class="titlepage"><div><div><h4 class="title">13.4.5.4. Notifications for limits exceeded</h4></div></div></div><p>
						When limits are exceeded, a notification appears:
					</p><div class="formalpara"><p class="title"><strong>Quota notifications</strong></p><p>
							<span class="inlinemediaobject"><img src="images/quota-notifications.png" alt="Quota notifications"/></span>
						</p></div></section></section></section><section class="section" id="quota-management-limitations"><div class="titlepage"><div><div><h2 class="title">13.5. Quota management limitations</h2></div></div></div><p>
				Quota management helps organizations to maintain resource consumption. One limitation of quota management is that calculating resource consumption on push results in the calculation becoming part of the push’s critical path. Without this, usage data might drift.
			</p><p>
				The maximum storage quota size is dependent on the selected database:
			</p><div class="table" id="idm45642554333008"><p class="title"><strong>Table 13.2. Worker count environment variables</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><thead><tr><th align="left" valign="top" id="idm45642554328160" scope="col">Variable</th><th align="left" valign="top" id="idm45642554327072" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45642554328160">
							<p>
								Postgres
							</p>
							</td><td align="left" valign="top" headers="idm45642554327072">
							<p>
								8388608 TB
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642554328160">
							<p>
								MySQL
							</p>
							</td><td align="left" valign="top" headers="idm45642554327072">
							<p>
								8388608 TB
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45642554328160">
							<p>
								SQL Server
							</p>
							</td><td align="left" valign="top" headers="idm45642554327072">
							<p>
								16777216 TB
							</p>
							</td></tr></tbody></table></div></div></section></section><section class="chapter" id="georepl-intro"><div class="titlepage"><div><div><h1 class="title">Chapter 14. Geo-replication</h1></div></div></div><p>
			Geo-replication allows multiple, geographically distributed Quay deployments to work as a single registry from the perspective of a client or user. It significantly improves push and pull performance in a globally-distributed Quay setup. Image data is asynchronously replicated in the background with transparent failover / redirect for clients.
		</p><p>
			With Red Hat Quay 3.7, deployments of Red Hat Quay with geo-replication is supported by standalone and Operator deployments.
		</p><section class="section" id="geo_replication_features"><div class="titlepage"><div><div><h2 class="title">14.1. Geo-replication features</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						When geo-replication is configured, container image pushes will be written to the preferred storage engine for that Red Hat Quay instance (typically the nearest storage backend within the region).
					</li><li class="listitem">
						After the initial push, image data will be replicated in the background to other storage engines.
					</li><li class="listitem">
						The list of replication locations is configurable and those can be different storage backends.
					</li><li class="listitem">
						An image pull will always use the closest available storage engine, to maximize pull performance.
					</li><li class="listitem">
						If replication hasn’t been completed yet, the pull will use the source storage backend instead.
					</li></ul></div></section><section class="section" id="georepl-prereqs"><div class="titlepage"><div><div><h2 class="title">14.2. Geo-replication requirements and constraints</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						A single database, and therefore all metadata and Quay configuration, is shared across all regions.
					</li><li class="listitem">
						A single Redis cache is shared across the entire Quay setup and needs to accessible by all Quay pods.
					</li><li class="listitem">
						The exact same configuration should be used across all regions, with exception of the storage backend, which can be configured explicitly using the <code class="literal">QUAY_DISTRIBUTED_STORAGE_PREFERENCE</code> environment variable.
					</li><li class="listitem">
						Geo-Replication requires object storage in each region. It does not work with local storage or NFS.
					</li><li class="listitem">
						Each region must be able to access every storage engine in each region (requires a network path).
					</li><li class="listitem">
						Alternatively, the storage proxy option can be used.
					</li><li class="listitem">
						The entire storage backend (all blobs) is replicated. This is in contrast to repository mirroring, which can be limited to an organization or repository or image.
					</li><li class="listitem">
						All Quay instances must share the same entrypoint, typically via load balancer.
					</li><li class="listitem">
						All Quay instances must have the same set of superusers, as they are defined inside the common configuration file.
					</li><li class="listitem">
						Geo-Replication requires SSL/TSL certificates and keys. For more information, see <a class="link" href="https://dxp-docs.ext.us-west.aws.prod.paas.redhat.com/documentation/en-us/red_hat_quay/3.6/html-single/deploy_red_hat_quay_for_proof-of-concept_non-production_purposes/index#using_ssl_to_protect_connections_to_red_hat_quay">Using SSL to protect connections to Red Hat Quay</a>.
					</li></ul></div><p>
				If the above requirements cannot be met, you should instead use two or more distinct Quay deployments and take advantage of repository mirroring functionality.
			</p></section><section class="section" id="georepl-arch-standalone"><div class="titlepage"><div><div><h2 class="title">14.3. Geo-replication - standalone Quay</h2></div></div></div><section class="section" id="geo_replication_architecture_standalone_quay"><div class="titlepage"><div><div><h3 class="title">14.3.1. Geo-replication architecture - standalone Quay</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/178_Quay_architecture_0821_georeplication.png" alt="Georeplication"/></span>
				</p><p>
					In the example shown above, Quay is running standalone in two separate regions, with a common database and a common Redis instance. Localized image storage is provided in each region and image pulls are served from the closest available storage engine. Container image pushes are written to the preferred storage engine for the Quay instance, and will then be replicated, in the background, to the other storage engines.
				</p></section><section class="section" id="config-ui-storage-georepl"><div class="titlepage"><div><div><h3 class="title">14.3.2. Enable storage replication - standalone Quay</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Scroll down to the section entitled <code class="literal">Registry Storage</code>.
						</li><li class="listitem">
							Click <code class="literal">Enable Storage Replication</code>.
						</li><li class="listitem">
							Add each of the storage engines to which data will be replicated. All storage engines to be used must be listed.
						</li><li class="listitem">
							If complete replication of all images to all storage engines is required, under each storage engine configuration click <code class="literal">Replicate to storage engine by default</code>. This will ensure that all images are replicated to that storage engine. To instead enable per-namespace replication, please contact support.
						</li><li class="listitem">
							When you are done, click <code class="literal">Save Configuration Changes</code>. Configuration changes will take effect the next time Red Hat Quay restarts.
						</li><li class="listitem"><p class="simpara">
							After adding storage and enabling “Replicate to storage engine by default” for Georeplications, you need to sync existing image data across all storage. To do this, you need to <code class="literal">oc exec</code> (or docker/kubectl exec) into the container and run:
						</p><pre class="screen"># scl enable python27 bash
# python -m util.backfillreplication</pre><p class="simpara">
							This is a one time operation to sync content after adding new storage.
						</p></li></ol></div></section><section class="section" id="georepl-deploy-standalone"><div class="titlepage"><div><div><h3 class="title">14.3.3. Run Red Hat Quay with storage preferences</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Copy the config.yaml to all machines running Red Hat Quay
						</li><li class="listitem"><p class="simpara">
							For each machine in each region, add a <code class="literal">QUAY_DISTRIBUTED_STORAGE_PREFERENCE</code> environment variable with the preferred storage engine for the region in which the machine is running.
						</p><p class="simpara">
							For example, for a machine running in Europe with the config directory on the host available from <code class="literal">$QUAY/config</code>:
						</p><pre class="literallayout">$ sudo podman run -d --rm -p 80:8080 -p 443:8443  \
   --name=quay \
   -v $QUAY/config:/conf/stack:Z \
   -e QUAY_DISTRIBUTED_STORAGE_PREFERENCE=europestorage \
   registry.redhat.io/quay/quay-rhel8:v3.7.0</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The value of the environment variable specified must match the name of a Location ID as defined in the config panel.
							</p></div></div></li><li class="listitem">
							Restart all Red Hat Quay containers
						</li></ol></div></section></section><section class="section" id="georepl-arch-operator"><div class="titlepage"><div><div><h2 class="title">14.4. Geo-replication - Quay Operator</h2></div></div></div><section class="section" id="geo_replication_architecture_quay_operator"><div class="titlepage"><div><div><h3 class="title">14.4.1. Geo-replication architecture - Quay Operator</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/178_Quay_architecture_0821_georeplication_openshift.png" alt="Georeplication architecture"/></span>
				</p><p>
					In the example shown above, Quay Operator is deployed in two separate regions, with a common database and a common Redis instance. Localized image storage is provided in each region and image pulls are served from the closest available storage engine. Container image pushes are written to the preferred storage engine for the Quay instance, and will then be replicated, in the background, to the other storage engines.
				</p></section><section class="section" id="georepl-deploy-operator"><div class="titlepage"><div><div><h3 class="title">14.4.2. Setting up geo-replication on Openshift</h3></div></div></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Deploy Quay postgres instance:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Login to the database
								</li><li class="listitem"><p class="simpara">
									Create a database for Quay
								</p><pre class="programlisting language-terminal">CREATE DATABASE quay;</pre></li><li class="listitem"><p class="simpara">
									Enable pg_trm extension inside the database
								</p><pre class="programlisting language-terminal">\c quay;
CREATE EXTENSION IF NOT EXISTS pg_trgm;</pre></li></ol></div></li><li class="listitem"><p class="simpara">
							Deploy a Redis instance:
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										Deploying a Redis instance might be unnecessary if your cloud provider has its own service.
									</li><li class="listitem">
										Deploying a Redis instance is required if you are leveraging Builders.
									</li></ul></div></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Deploy a VM for Redis
								</li><li class="listitem">
									Make sure that it is accessible from the clusters where Quay is running
								</li><li class="listitem">
									Port 6379/TCP must be open
								</li><li class="listitem"><p class="simpara">
									Run Redis inside the instance
								</p><pre class="programlisting language-terminal">sudo dnf install -y podman
podman run -d --name redis -p 6379:6379 redis</pre></li></ol></div></li><li class="listitem"><p class="simpara">
							Create two object storage backends, one for each cluster
						</p><p class="simpara">
							Ideally one object storage bucket will be close to the 1st cluster (primary) while the other will run closer to the 2nd cluster (secondary).
						</p></li><li class="listitem">
							Deploy the clusters with the same config bundle, using environment variable overrides to select the appropriate storage backend for an individual cluster
						</li><li class="listitem">
							Configure a load balancer, to provide a single entry point to the clusters
						</li></ol></div><section class="section" id="configuration"><div class="titlepage"><div><div><h4 class="title">14.4.2.1. Configuration</h4></div></div></div><p>
						The <code class="literal">config.yaml</code> file is shared between clusters, and will contain the details for the common PostgreSQL, Redis and storage backends:
					</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
							
<pre class="screen">DB_CONNECTION_ARGS:
  autorollback: true
  threadlocals: true
DB_URI: postgresql://postgres:password@10.19.0.1:5432/quay <span id="CO5-1"/><span class="callout">1</span>
BUILDLOGS_REDIS:
  host: 10.19.0.2
  port: 6379
USER_EVENTS_REDIS:
  host: 10.19.0.2
  port: 6379
DISTRIBUTED_STORAGE_CONFIG:
  usstorage:
    - GoogleCloudStorage
    - access_key: GOOGQGPGVMASAAMQABCDEFG
      bucket_name: georep-test-bucket-0
      secret_key: AYWfEaxX/u84XRA2vUX5C987654321
      storage_path: /quaygcp
  eustorage:
    - GoogleCloudStorage
    - access_key: GOOGQGPGVMASAAMQWERTYUIOP
      bucket_name: georep-test-bucket-1
      secret_key: AYWfEaxX/u84XRA2vUX5Cuj12345678
      storage_path: /quaygcp
DISTRIBUTED_STORAGE_DEFAULT_LOCATIONS:
  - usstorage
  - eustorage
DISTRIBUTED_STORAGE_PREFERENCE:
  - usstorage
  - eustorage</pre>
						</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO5-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								The PostgreSQL DB_URI must also be included in the Clair configuration file. For more information about retrieving the Clair configuration file on OpenShift, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/deploy_red_hat_quay_on_openshift_with_the_quay_operator/quay_operator_features#clair-openshift-config">Retrieving the Clair config</a>.
							</div></dd></dl></div><p>
						Create the <code class="literal">configBundleSecret</code>:
					</p><pre class="programlisting language-terminal">$ oc create secret generic --from-file config.yaml=./config.yaml georep-config-bundle</pre><p>
						In each of the clusters, set the <code class="literal">configBundleSecret</code> and use the <code class="literal">QUAY_DISTRIBUTED_STORAGE_PREFERENCE</code> environmental variable override to configure the appropriate storage for that cluster:
					</p><div class="formalpara"><p class="title"><strong>US cluster</strong></p><p>
							
<pre class="screen">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: georep-config-bundle
  components:
    - kind: postgres
      managed: false
    - kind: clairpostgres
      managed: false
    - kind: redis
      managed: false
    - kind: quay
      managed: true
      overrides:
        env:
          - name: QUAY_DISTRIBUTED_STORAGE_PREFERENCE
            value: usstorage</pre>
						</p></div><div class="formalpara"><p class="title"><strong>European cluster</strong></p><p>
							
<pre class="screen">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: georep-config-bundle
  components:
    - kind: postgres
      managed: false
    - kind: clairpostgres
      managed: false
    - kind: redis
      managed: false
    - kind: quay
      managed: true
      overrides:
        env:
          - name: QUAY_DISTRIBUTED_STORAGE_PREFERENCE
            value: eustorage</pre>
						</p></div></section></section><section class="section" id="georepl-mixed-storage"><div class="titlepage"><div><div><h3 class="title">14.4.3. Mixed storage for geo-replication</h3></div></div></div><p>
					Quay geo-replication supports the use of different, and multiple, replication targets for example, using AWS S3 storage on public cloud and using Ceph storage on-prem. This complicates the key requirement of granting access to all storage backends from all Quay pods and cluster nodes. As a result, it is recommended that you:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Use a VPN to prevent visibility of the internal storage <span class="emphasis"><em>or</em></span>
						</li><li class="listitem">
							Use a token pair that only allows access to the specified bucket used by Quay
						</li></ul></div><p>
					This will result in the public cloud instance of Quay having access to on-prem storage but the network will be encrypted, protected, and will use ACLs, thereby meeting security requirements.
				</p><p>
					If you cannot implement these security measures, it may be preferable to deploy two distinct Quay registries and to use repository mirroring as an alternative to geo-replication.
				</p></section></section></section><section class="chapter" id="quay-troubleshooting-guides"><div class="titlepage"><div><div><h1 class="title">Chapter 15. Red Hat Quay Troubleshooting</h1></div></div></div><p>
			Common failure modes and best practices for recovery.
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/429.html">I’m receiving HTTP Status Code 429</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/auth-failure.html">I’m authorized but I’m still getting 403s</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/base-pull-issue.html">Base image pull in Dockerfile fails with 403</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/cannot-add-trigger.html">Cannot add a build trigger</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/cannot-load-build-logs.html">Build logs are not loading</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/cannot-locate-dockerfile.html">I’m receiving "Cannot locate specified Dockerfile"</a> * <a class="link" href="http://docs.quay.io/issues/could-not-reach-any-registry-endpoint.html">Could not reach any registry endpoint</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/ecs-auth-failure.html">Cannot access private repositories using EC2 Container Service</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/iotimeout.html">Docker is returning an i/o timeout</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/odd-login-failure.html">Docker login is failing with an odd error</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/odd-pull-failure.html">Pulls are failing with an odd error</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/push-timestamp-wrong.html">I just pushed but the timestamp is wrong</a>
				</li><li class="listitem">
					<a class="link" href="http://docs.quay.io/issues/quay-mesos.html">Pulling Private Quay.io images with Marathon/Mesos fails</a>
				</li></ul></div></section><section class="chapter" id="quay-schema"><div class="titlepage"><div><div><h1 class="title">Chapter 16. Schema for Red Hat Quay configuration</h1></div></div></div><p>
			Most Red Hat Quay configuration information is stored in the <code class="literal">config.yaml</code> file that is created using the browser-based config tool when Red Hat Quay is first deployed.
		</p><p>
			The configuration options are described in the Red Hat Quay Configuration Guide.
		</p><h2 id="additional_resources">Additional resources</h2></section><div><div xml:lang="en-US" class="legalnotice" id="idm45642554420480"><h1 class="legalnotice">Legal Notice</h1><div class="para">
		Copyright <span class="trademark"/>© 2022 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></div></div></div><script type="text/javascript">
                        jQuery(document).ready(function() {
                            initSwitchery();
                            jQuery('pre[class*="language-"]').each(function(i, block){hljs.highlightBlock(block);});
                        });
                    </script></body></html>