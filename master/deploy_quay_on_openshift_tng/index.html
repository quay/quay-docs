<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" class="chrometwo"><head><title>Deploy Red Hat Quay on OpenShift with the Quay Operator</title><link rel="stylesheet" type="text/css" href="Common_Content/css/default.css"/><meta name="generator" content="publican v4.3.4"/><meta name="description" content="Deploy Red Hat Quay on an OpenShift Cluster with the Red Hat Quay Operator"/><link rel="next" href="#idm45308031179664" title="Preface"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><script type="text/javascript" src="Common_Content/scripts/jquery-1.7.1.min.js"> </script><script type="text/javascript" src="Common_Content/scripts/utils.js"> </script><script type="text/javascript" src="Common_Content/scripts/highlight.js/highlight.pack.js"> </script></head><body><div id="chrometwo"><div id="main"><div xml:lang="en-US" class="book" id="idm45308029616480"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Quay</span> <span class="productnumber">3.7</span></div><div><h1 class="title">Deploy Red Hat Quay on OpenShift with the Quay Operator</h1></div><div><h2 class="subtitle">Deploy Red Hat Quay on OpenShift with Quay Operator</h2></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat OpenShift Documentation Team</span></div></div><div><a href="#idm45308024452896">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				Deploy Red Hat Quay on an OpenShift Cluster with the Red Hat Quay Operator
			</div></div></div></div><hr/></div><div class="toc"><ul class="toc"><li><span class="preface"><a href="#idm45308031179664">Preface</a></span></li><li><span class="chapter"><a href="#operator-concepts">1. Introduction to the Red Hat Quay Operator</a></span><ul><li><span class="section"><a href="#operator-quayregistry-api">1.1. QuayRegistry API</a></span></li><li><span class="section"><a href="#operator-components-intro">1.2. Quay Operator components</a></span></li><li><span class="section"><a href="#operator-components-managed">1.3. Using managed components</a></span></li><li><span class="section"><a href="#operator-components-unmanaged">1.4. Using unmanaged components for dependencies</a></span></li><li><span class="section"><a href="#operator-config-bundle-secret">1.5. Config bundle secret</a></span></li><li><span class="section"><a href="#operator-prereq">1.6. Prerequisites for Red Hat Quay on OpenShift</a></span><ul><li><span class="section"><a href="#openshift_cluster">1.6.1. OpenShift cluster</a></span></li><li><span class="section"><a href="#resource_requirements">1.6.2. Resource Requirements</a></span></li><li><span class="section"><a href="#object_storage">1.6.3. Object Storage</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#installing_the_quay_operator_from_operatorhub">2. Installing the Quay Operator from OperatorHub</a></span></li><li><span class="chapter"><a href="#operator-preconfigure">3. Configuring Quay before deployment</a></span><ul><li><span class="section"><a href="#config-preconfigure-automation">3.1. Pre-configuring Quay for automation</a></span><ul><li><span class="section"><a href="#allowing_the_api_to_create_the_first_user">3.1.1. Allowing the API to create the first user</a></span></li><li><span class="section"><a href="#enabling_general_api_access">3.1.2. Enabling general API access</a></span></li><li><span class="section"><a href="#adding_a_super_user">3.1.3. Adding a super user</a></span></li><li><span class="section"><a href="#restricting_user_creation">3.1.4. Restricting user creation</a></span></li><li><span class="section"><a href="#suggested_configuration_for_automation">3.1.5. Suggested configuration for automation</a></span></li><li><span class="section"><a href="#deploying_the_operator_using_the_initial_configuration">3.1.6. Deploying the Operator using the initial configuration</a></span></li></ul></li><li><span class="section"><a href="#operator-storage-preconfig">3.2. Configuring object storage</a></span><ul><li><span class="section"><a href="#operator-unmanaged-storage">3.2.1. Unmanaged storage</a></span></li><li><span class="section"><a href="#operator-managed-storage">3.2.2. Managed storage</a></span></li></ul></li><li><span class="section"><a href="#configuring_the_database">3.3. Configuring the database</a></span><ul><li><span class="section"><a href="#operator-unmanaged-postgres">3.3.1. Using an existing Postgres database</a></span></li><li><span class="section"><a href="#config-fields-db">3.3.2. Database configuration</a></span></li><li><span class="section"><a href="#operator-managed-postgres">3.3.3. Using the managed PostgreSQL</a></span></li></ul></li><li><span class="section"><a href="#operator-preconfig-tls-routes">3.4. Configuring TLS and routes</a></span><ul><li><span class="section"><a href="#creating_the_config_bundle_secret_with_tls_cert_key_pair">3.4.1. Creating the config bundle secret with TLS cert, key pair:</a></span></li></ul></li><li><span class="section"><a href="#operator-components-unmanaged-other">3.5. Configuring other components</a></span><ul><li><span class="section"><a href="#operator-unmanaged-redis">3.5.1. Using external Redis</a></span></li><li><span class="section"><a href="#operator-unmanaged-hpa">3.5.2. Disabling the Horizontal Pod Autoscaler</a></span></li><li><span class="section"><a href="#operator-unmanaged-route">3.5.3. Disabling Route Component</a></span></li><li><span class="section"><a href="#operator-unmanaged-monitoring">3.5.4. Unmanaged monitoring</a></span></li><li><span class="section"><a href="#operator-unmanaged-mirroring">3.5.5. Unmanaged mirroring</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#operator-deploy">4. Deploying Quay using the Quay Operator</a></span><ul><li><span class="section"><a href="#operator-deploy-cli">4.1. Deploying Red Hat Quay from the command line</a></span><ul><li><span class="section"><a href="#operator-deploy-view-pods-cli">4.1.1. Viewing created components using the command line</a></span></li><li><span class="section"><a href="#operator-deploy-hpa">4.1.2. Horizontal Pod Autoscaling (HPA)</a></span></li><li><span class="section"><a href="#first-user-api">4.1.3. Using the API to create the first user</a></span></li><li><span class="section"><a href="#operator-monitor-deploy-cli">4.1.4. Monitoring and debugging the deployment process</a></span></li></ul></li><li><span class="section"><a href="#operator-deploy-ui">4.2. Deploying Red Hat Quay from the OpenShift console</a></span><ul><li><span class="section"><a href="#operator-first-user">4.2.1. Using the Quay UI to create the first user</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#operator-config-cli">5. Configuring Quay on OpenShift using the command line and API</a></span><ul><li><span class="section"><a href="#operator-config-cli-access">5.1. Determining QuayRegistry endpoints and secrets</a></span></li><li><span class="section"><a href="#operator-config-cli-download">5.2. Downloading the existing configuration</a></span></li><li><span class="section"><a href="#operator-custom-ssl-certs-config-bundle">5.3. Using the config bundle to configure custom SSL certs</a></span></li></ul></li><li><span class="chapter"><a href="#operator-config-ui">6. Using the config tool to reconfigure Quay on OpenShift</a></span><ul><li><span class="section"><a href="#operator-config-ui-access">6.1. Accessing the config editor</a></span><ul><li><span class="section"><a href="#retrieving_the_config_editor_credentials">6.1.1. Retrieving the config editor credentials</a></span></li><li><span class="section"><a href="#logging_in_to_the_config_editor">6.1.2. Logging in to the config editor</a></span></li><li><span class="section"><a href="#operator-config-ui-change">6.1.3. Changing configuration</a></span></li></ul></li><li><span class="section"><a href="#operator-config-ui-monitoring">6.2. Monitoring reconfiguration in the UI</a></span><ul><li><span class="section"><a href="#quayregistry_resource">6.2.1. QuayRegistry resource</a></span></li><li><span class="section"><a href="#events">6.2.2. Events</a></span></li></ul></li><li><span class="section"><a href="#operator-config-ui-updated">6.3. Accessing updated information after reconfiguration</a></span><ul><li><span class="section"><a href="#accessing_the_updated_config_tool_credentials_in_the_ui">6.3.1. Accessing the updated config tool credentials in the UI</a></span></li><li><span class="section"><a href="#accessing_the_updated_config_yaml_in_the_ui">6.3.2. Accessing the updated config.yaml in the UI</a></span></li></ul></li><li><span class="section"><a href="#config-ui-custom-ssl-certs">6.4. Custom SSL certificates UI</a></span></li><li><span class="section"><a href="#operator-external-access">6.5. External Access to the Registry</a></span></li></ul></li><li><span class="chapter"><a href="#quay_operator_features">7. Quay Operator features</a></span><ul><li><span class="section"><a href="#operator-console-monitoring-alerting">7.1. Console monitoring and alerting</a></span><ul><li><span class="section"><a href="#dashboard">7.1.1. Dashboard</a></span></li><li><span class="section"><a href="#metrics">7.1.2. Metrics</a></span></li><li><span class="section"><a href="#alerting">7.1.3. Alerting</a></span></li></ul></li><li><span class="section"><a href="#clair-openshift-airgap-update">7.2. Manually updating the vulnerability databases for Clair in an air-gapped OpenShift cluster</a></span><ul><li><span class="section"><a href="#clair-clairctl">7.2.1. Obtaining clairctl</a></span></li><li><span class="section"><a href="#retrieving_the_clair_config">7.2.2. Retrieving the Clair config</a></span></li><li><span class="section"><a href="#clair-export-bundle">7.2.3. Exporting the updaters bundle</a></span></li><li><span class="section"><a href="#clair-openshift-airgap-database">7.2.4. Configuring access to the Clair database in the air-gapped OpenShift cluster</a></span></li><li><span class="section"><a href="#clair-openshift-airgap-import-bundle">7.2.5. Importing the updaters bundle into the air-gapped environment</a></span></li></ul></li><li><span class="section"><a href="#fips-overview">7.3. FIPS readiness and compliance</a></span></li></ul></li><li><span class="chapter"><a href="#advanced_concepts">8. Advanced Concepts</a></span><ul><li><span class="section"><a href="#operator-deploy-infrastructure">8.1. Deploying Quay on infrastructure nodes</a></span><ul><li><span class="section"><a href="#label_and_taint_nodes_for_infrastructure_use">8.1.1. Label and taint nodes for infrastructure use</a></span></li><li><span class="section"><a href="#create_a_project_with_node_selector_and_toleration">8.1.2. Create a Project with node selector and toleration</a></span></li><li><span class="section"><a href="#install_the_quay_operator_in_the_namespace">8.1.3. Install the Quay Operator in the namespace</a></span></li><li><span class="section"><a href="#create_the_registry">8.1.4. Create the registry</a></span></li></ul></li><li><span class="section"><a href="#monitoring-single-namespace">8.2. Enabling monitoring when Operator is installed in a single namespace</a></span><ul><li><span class="section"><a href="#creating_a_cluster_monitoring_config_map">8.2.1. Creating a cluster monitoring config map</a></span></li><li><span class="section"><a href="#creating_a_user_defined_workload_monitoring_config_map">8.2.2. Creating a user-defined workload monitoring config map</a></span></li><li><span class="section"><a href="#enable_monitoring_for_user_defined_projects">8.2.3. Enable monitoring for user-defined projects</a></span></li><li><span class="section"><a href="#create_a_service_object_to_expose_quay_metrics">8.2.4. Create a Service object to expose Quay metrics</a></span></li><li><span class="section"><a href="#create_a_servicemonitor_object">8.2.5. Create a ServiceMonitor object</a></span></li><li><span class="section"><a href="#view_the_metrics_in_openshift">8.2.6. View the metrics in OpenShift</a></span></li></ul></li><li><span class="section"><a href="#operator-resize-storage">8.3. Resizing Managed Storage</a></span><ul><li><span class="section"><a href="#resize_noobaa_pvc">8.3.1. Resize Noobaa PVC</a></span></li><li><span class="section"><a href="#add_another_storage_pool">8.3.2. Add Another Storage Pool</a></span></li></ul></li><li><span class="section"><a href="#operator-customize-images">8.4. Customizing Default Operator Images</a></span><ul><li><span class="section"><a href="#environment_variables">8.4.1. Environment Variables</a></span></li><li><span class="section"><a href="#applying_overrides_to_a_running_operator">8.4.2. Applying Overrides to a Running Operator</a></span></li></ul></li><li><span class="section"><a href="#operator-cloudfront">8.5. AWS S3 CloudFront</a></span></li></ul></li><li><span class="chapter"><a href="#red-hat-quay-builders-enhancement">9. Red Hat Quay build enhancements</a></span><ul><li><span class="section"><a href="#red-hat-quay-builds-architecture">9.1. Red Hat Quay enhanced build architecture</a></span></li><li><span class="section"><a href="#red-hat-quay-build-limitations">9.2. Red Hat Quay build limitations</a></span></li><li><span class="section"><a href="#builders-virtual-environment">9.3. Creating a Red Hat Quay builders environment with OpenShift</a></span><ul><li><span class="section"><a href="#openshift_tls_component">9.3.1. OpenShift TLS component</a></span></li><li><span class="section"><a href="#red-hat-quay-quota-builders-establishment">9.3.2. Using OpenShift Container Platform for Red Hat Quay builders</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#georepl-intro">10. Geo-replication</a></span><ul><li><span class="section"><a href="#geo_replication_features">10.1. Geo-replication features</a></span></li><li><span class="section"><a href="#georepl-prereqs">10.2. Geo-replication requirements and constraints</a></span></li><li><span class="section"><a href="#georepl-arch-operator">10.3. Geo-replication - Quay Operator</a></span><ul><li><span class="section"><a href="#geo_replication_architecture_quay_operator">10.3.1. Geo-replication architecture - Quay Operator</a></span></li><li><span class="section"><a href="#georepl-deploy-operator">10.3.2. Setting up geo-replication on Openshift</a></span></li><li><span class="section"><a href="#georepl-mixed-storage">10.3.3. Mixed storage for geo-replication</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#operator-upgrade">11. Upgrading the Quay Operator Overview</a></span><ul><li><span class="section"><a href="#operator_lifecycle_manager">11.1. Operator Lifecycle Manager</a></span></li><li><span class="section"><a href="#upgrading_the_quay_operator">11.2. Upgrading the Quay Operator</a></span><ul><li><span class="section"><a href="#upgrading_quay">11.2.1. Upgrading Quay</a></span></li><li><span class="section"><a href="#upgrade-33-36">11.2.2. Notes on upgrading directly from 3.3.z or 3.4.z to 3.6</a></span></li><li><span class="section"><a href="#changing_the_update_channel_for_an_operator">11.2.3. Changing the update channel for an Operator</a></span></li><li><span class="section"><a href="#manually_approving_a_pending_operator_upgrade">11.2.4. Manually approving a pending Operator upgrade</a></span></li></ul></li><li><span class="section"><a href="#upgrading_a_quayregistry">11.3. Upgrading a QuayRegistry</a></span></li><li><span class="section"><a href="#enabling_features_in_quay_3_6">11.4. Enabling features in Quay 3.6</a></span><ul><li><span class="section"><a href="#console_monitoring_and_alerting">11.4.1. Console monitoring and alerting</a></span></li><li><span class="section"><a href="#oci_and_helm_support">11.4.2. OCI and Helm support</a></span></li></ul></li><li><span class="section"><a href="#upgrading_a_quayecosystem">11.5. Upgrading a QuayEcosystem</a></span><ul><li><span class="section"><a href="#reverting_quayecosystem_upgrade">11.5.1. Reverting QuayEcosystem Upgrade</a></span></li><li><span class="section"><a href="#supported_quayecosystem_configurations_for_upgrades">11.5.2. Supported QuayEcosystem Configurations for Upgrades</a></span></li></ul></li></ul></li></ul></div><section class="preface" id="idm45308031179664"><div class="titlepage"><div><div><h1 class="title">Preface</h1></div></div></div><p>
			Red Hat Quay is an enterprise-quality container registry. Use Red Hat Quay to build and store container images, then make them available to deploy across your enterprise.
		</p><p>
			The Red Hat Quay Operator provides a simple method to deploy and manage Red Hat Quay on an OpenShift cluster.
		</p><p id="operator-differences">
			As of Red Hat Quay 3.4.0, the Operator has been completely re-written to provide an improved out of the box experience as well as support for more Day 2 operations. As a result the new Operator is simpler to use and is more opinionated. The key differences from earlier versions of the Operator are:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					The <code class="literal">QuayEcosystem</code> custom resource has been replaced with the <code class="literal">QuayRegistry</code> custom resource
				</li><li class="listitem">
					The default installation options produces a fully supported Quay environment with all managed dependencies (database, caches, object storage, etc) supported for production use (some components may not be highly available)
				</li><li class="listitem">
					A new robust validation library for Quay’s configuration which is shared by the Quay application and config tool for consistency
				</li><li class="listitem">
					Object storage can now be managed by the Operator using the <code class="literal">ObjectBucketClaim</code> Kubernetes API (Red Hat OpenShift Data Foundation can be used to provide a supported implementation of this API on OpenShift)
				</li><li class="listitem">
					Customization of the container images used by deployed pods for testing and development scenarios
				</li></ul></div></section><section class="chapter" id="operator-concepts"><div class="titlepage"><div><div><h1 class="title">Chapter 1. Introduction to the Red Hat Quay Operator</h1></div></div></div><p>
			This document outlines the steps for configuring, deploying, managing and upgrading Red Hat Quay on OpenShift using the Red Hat Quay Operator.
		</p><p>
			It shows you how to:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Install the Red Hat Quay Operator
				</li><li class="listitem">
					Configure object storage, either managed or unmanaged
				</li><li class="listitem">
					Configure other unmanaged components, if required, including database, Redis, routes, TLS, etc.
				</li><li class="listitem">
					Deploy the Red Hat Quay registry on OpenShift using the Operator
				</li><li class="listitem">
					Use advanced features supported by the Operator
				</li><li class="listitem">
					Upgrade the registry by upgrading the Operator
				</li></ul></div><section class="section" id="operator-quayregistry-api"><div class="titlepage"><div><div><h2 class="title">1.1. QuayRegistry API</h2></div></div></div><p>
				The Quay Operator provides the <code class="literal">QuayRegistry</code> custom resource API to declaratively manage <code class="literal">Quay</code> container registries on the cluster. Use either the OpenShift UI or a command-line tool to interact with this API.
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Creating a <code class="literal">QuayRegistry</code> will result in the Operator deploying and configuring all necessary resources needed to run Quay on the cluster.
					</li><li class="listitem">
						Editing a <code class="literal">QuayRegistry</code> will result in the Operator reconciling the changes and creating/updating/deleting objects to match the desired configuration.
					</li><li class="listitem">
						Deleting a <code class="literal">QuayRegistry</code> will result in garbage collection of all previously created resources and the <code class="literal">Quay</code> container registry will no longer be available.
					</li></ul></div><p>
				The <code class="literal">QuayRegistry</code> API is fairly simple, and the fields are outlined in the following sections.
			</p></section><section class="section" id="operator-components-intro"><div class="titlepage"><div><div><h2 class="title">1.2. Quay Operator components</h2></div></div></div><p>
				Quay is a powerful container registry platform and as a result, has a significant number of dependencies. These include a database, object storage, Redis, and others. The Quay Operator manages an opinionated deployment of Quay and its dependencies on Kubernetes. These dependencies are treated as <span class="emphasis"><em>components</em></span> and are configured through the <code class="literal">QuayRegistry</code> API.
			</p><p>
				In the <code class="literal">QuayRegistry</code> custom resource, the <code class="literal">spec.components</code> field configures components. Each component contains two fields: <code class="literal">kind</code> - the name of the component, and <code class="literal">managed</code> - boolean whether the component lifecycle is handled by the Operator. By default (omitting this field), all components are managed and will be autofilled upon reconciliation for visibility:
			</p><pre class="programlisting language-yaml">spec:
  components:
    - managed: true
      kind: clair
    - managed: true
      kind: postgres
    - managed: true
      kind: objectstorage
    - managed: true
      kind: redis
    - managed: true
      kind: horizontalpodautoscaler
    - managed: true
      kind: route
    - managed: true
      kind: mirror
    - managed: true
      kind: monitoring
    - managed: true
      kind: tls</pre></section><section class="section" id="operator-components-managed"><div class="titlepage"><div><div><h2 class="title">1.3. Using managed components</h2></div></div></div><p>
				Unless your <code class="literal">QuayRegistry</code> custom resource specifies otherwise, the Operator will use defaults for the following managed components:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="strong strong"><strong>postgres:</strong></span> For storing the registry metadata, uses a version of Postgres 10 from the <a class="link" href="https://www.softwarecollections.org/en/">Software Collections</a>
					</li><li class="listitem">
						<span class="strong strong"><strong>redis:</strong></span> Handles Quay builder coordination and some internal logging
					</li><li class="listitem">
						<span class="strong strong"><strong>objectstorage:</strong></span> For storing image layer blobs, utilizes the <code class="literal">ObjectBucketClaim</code> Kubernetes API which is provided by Noobaa/RHOCS
					</li><li class="listitem">
						<span class="strong strong"><strong>clair:</strong></span> Provides image vulnerability scanning
					</li><li class="listitem">
						<span class="strong strong"><strong>horizontalpodautoscaler:</strong></span> Adjusts the number of Quay pods depending on memory/cpu consumption
					</li><li class="listitem">
						<span class="strong strong"><strong>mirror:</strong></span> Configures repository mirror workers (to support optional repository mirroring)
					</li><li class="listitem">
						<span class="strong strong"><strong>route:</strong></span> Provides an external entrypoint to the Quay registry from outside OpenShift
					</li><li class="listitem">
						<span class="strong strong"><strong>monitoring:</strong></span> Features include a Grafana dashboard, access to individual metrics, and alerting to notify for frequently restarting Quay pods
					</li><li class="listitem">
						<span class="strong strong"><strong>tls:</strong></span> Configures whether Red Hat Quay or OpenShift handles TLS
					</li></ul></div><p>
				The Operator will handle any required configuration and installation work needed for Red Hat Quay to use the managed components. If the opinionated deployment performed by the Quay Operator is unsuitable for your environment, you can provide the Operator with <code class="literal">unmanaged</code> resources (overrides) as described in the following sections.
			</p></section><section class="section" id="operator-components-unmanaged"><div class="titlepage"><div><div><h2 class="title">1.4. Using unmanaged components for dependencies</h2></div></div></div><p>
				If you have existing components such as Postgres, Redis or object storage that you would like to use with Quay, you first configure them within the Quay configuration bundle (<code class="literal">config.yaml</code>) and then reference the bundle in your <code class="literal">QuayRegistry</code> (as a Kubernetes <code class="literal">Secret</code>) while indicating which components are unmanaged.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					The Quay config editor can also be used to create or modify an existing config bundle and simplifies the process of updating the Kubernetes <code class="literal">Secret</code>, especially for multiple changes. When Quay’s configuration is changed via the config editor and sent to the Operator, the Quay deployment will be updated to reflect the new configuration.
				</p></div></div></section><section class="section" id="operator-config-bundle-secret"><div class="titlepage"><div><div><h2 class="title">1.5. Config bundle secret</h2></div></div></div><p>
				The <code class="literal">spec.configBundleSecret</code> field is a reference to the <code class="literal">metadata.name</code> of a <code class="literal">Secret</code> in the same namespace as the <code class="literal">QuayRegistry</code>. This <code class="literal">Secret</code> must contain a <code class="literal">config.yaml</code> key/value pair. This <code class="literal">config.yaml</code> file is a Quay config YAML file. This field is optional, and will be auto-filled by the Operator if not provided. If provided, it serves as the base set of config fields which are later merged with other fields from any managed components to form a final output <code class="literal">Secret</code>, which is then mounted into the Quay application pods.
			</p></section><section class="section" id="operator-prereq"><div class="titlepage"><div><div><h2 class="title">1.6. Prerequisites for Red Hat Quay on OpenShift</h2></div></div></div><p>
				Before you begin the deployment of Red Hat Quay Operator on OpenShift, you should consider the following.
			</p><section class="section" id="openshift_cluster"><div class="titlepage"><div><div><h3 class="title">1.6.1. OpenShift cluster</h3></div></div></div><p>
					You need a privileged account to an OpenShift 4.5 or later cluster on which to deploy the Red Hat Quay Operator. That account must have the ability to create namespaces at the cluster scope.
				</p></section><section class="section" id="resource_requirements"><div class="titlepage"><div><div><h3 class="title">1.6.2. Resource Requirements</h3></div></div></div><p>
					Each Red Hat Quay application pod has the following resource requirements:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							8Gi of memory
						</li><li class="listitem">
							2000 millicores of CPU.
						</li></ul></div><p>
					The Red Hat Quay Operator will create at least one application pod per Red Hat Quay deployment it manages. Ensure your OpenShift cluster has sufficient compute resources for these requirements.
				</p></section><section class="section" id="object_storage"><div class="titlepage"><div><div><h3 class="title">1.6.3. Object Storage</h3></div></div></div><p>
					By default, the Red Hat Quay Operator uses the <code class="literal">ObjectBucketClaim</code> Kubernetes API to provision object storage. Consuming this API decouples the Operator from any vendor-specific implementation. Red Hat OpenShift Data Foundation provides this API via its NooBaa component, which will be used in this example.
				</p><p>
					Red Hat Quay can be manually configured to use any of the following supported cloud storage options:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Amazon S3 (see <a class="link" href="https://access.redhat.com/solutions/3680151">S3 IAM Bucket Policy</a> for details on configuring an S3 bucket policy for Red Hat Quay)
						</li><li class="listitem">
							Azure Blob Storage
						</li><li class="listitem">
							Google Cloud Storage
						</li><li class="listitem">
							Ceph Object Gateway (RADOS)
						</li><li class="listitem">
							OpenStack Swift
						</li><li class="listitem">
							CloudFront + S3
						</li></ul></div></section></section></section><section class="chapter" id="installing_the_quay_operator_from_operatorhub"><div class="titlepage"><div><div><h1 class="title">Chapter 2. Installing the Quay Operator from OperatorHub</h1></div></div></div><div class="orderedlist" id="operator-install"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
					Using the OpenShift console, Select Operators → OperatorHub, then select the Red Hat Quay Operator. If there is more than one, be sure to use the Red Hat certified Operator and not the community version.
				</p><p class="simpara">
					<span class="inlinemediaobject"><img src="images/operatorhub-quay.png" alt="operatorhub quay"/></span>
				</p></li><li class="listitem"><p class="simpara">
					The Installation page outlines the features and prerequisites:
				</p><p class="simpara">
					<span class="inlinemediaobject"><img src="images/operator-install-page.png" alt="operator install page"/></span>
				</p></li><li class="listitem"><p class="simpara">
					Select Install. The Operator Installation page appears.
				</p><p class="simpara">
					<span class="inlinemediaobject"><img src="images/operator-subscription.png" alt="operator subscription"/></span>
				</p></li><li class="listitem"><p class="simpara">
					The following choices are available for customizing the installation:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Update Channel:</strong></span> Choose the update channel, for example, <code class="literal">stable-3.6</code> for the latest release.
						</li><li class="listitem">
							<span class="strong strong"><strong>Installation Mode:</strong></span> Choose <code class="literal">All namespaces on the cluster</code> if you want the Operator to be available cluster-wide. Choose <code class="literal">A specific namespace on the cluster</code> if you want it deployed only within a single namespace. It is recommended that you install the Operator cluster-wide. If you choose a single namespace, the monitoring component will not be available by default.
						</li><li class="listitem">
							<span class="strong strong"><strong>Approval Strategy:</strong></span> Choose to approve either automatic or manual updates. Automatic update strategy is recommended.
						</li></ul></div></li><li class="listitem">
					Select Install.
				</li><li class="listitem">
					After a short time, you will see the Operator installed successfully in the Installed Operators page.
				</li></ol></div></section><section class="chapter" id="operator-preconfigure"><div class="titlepage"><div><div><h1 class="title">Chapter 3. Configuring Quay before deployment</h1></div></div></div><p>
			The Operator can manage all the Red Hat Quay components when deploying on OpenShift, and this is the default configuration. Alternatively, you can manage one or more components externally yourself, where you want more control over the set up, and then allow the Operator to manage the remaining components.
		</p><p>
			The standard pattern for configuring unmanaged components is:
		</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
					Create a <code class="literal">config.yaml</code> configuration file with the appropriate settings
				</li><li class="listitem"><p class="simpara">
					Create a Secret using the configuration file
				</p><pre class="screen">$ oc create secret generic --from-file config.yaml=./config.yaml config-bundle-secret</pre></li><li class="listitem"><p class="simpara">
					Create a QuayRegistry YAML file <code class="literal">quayregistry.yaml</code>, identifying the unmanaged components and also referencing the created Secret, for example:
				</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml</strong></p><p>
						
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: config-bundle-secret
  components:
    - kind: objectstorage
      managed: false</pre>
					</p></div></li><li class="listitem"><p class="simpara">
					Deploy the registry using the YAML file:
				</p><pre class="screen">oc create -f quayregistry.yaml</pre></li></ol></div><section class="section" id="config-preconfigure-automation"><div class="titlepage"><div><div><h2 class="title">3.1. Pre-configuring Quay for automation</h2></div></div></div><p>
				Quay has a number of configuration options that support automation. These options can be set before deployment, to minimize the need to interact with the user interface.
			</p><section class="section" id="allowing_the_api_to_create_the_first_user"><div class="titlepage"><div><div><h3 class="title">3.1.1. Allowing the API to create the first user</h3></div></div></div><p>
					Set the config option <code class="literal">FEATURE_USER_INITIALIZE</code> to <code class="literal">true</code>, so that you can use the API <code class="literal">/api/v1/user/initialize</code> to create the first user. This API endpoint does not require authentication, unlike all other registry API calls which require an OAuth token which is generated by an OAuth application in an existing organization.
				</p><p>
					Once you have deployed Quay, you can use the API to create a user, for example, <code class="literal">quayadmin</code>, provided no other users have already been created. For more information, see the section on <a class="link" href="#first-user-api" title="4.1.3. Using the API to create the first user">Creating the first user using the API</a>.
				</p></section><section class="section" id="enabling_general_api_access"><div class="titlepage"><div><div><h3 class="title">3.1.2. Enabling general API access</h3></div></div></div><p>
					Set the config option <code class="literal">BROWSER_API_CALLS_XHR_ONLY</code> to <code class="literal">false</code>, to allow general access to the Quay registry API.
				</p></section><section class="section" id="adding_a_super_user"><div class="titlepage"><div><div><h3 class="title">3.1.3. Adding a super user</h3></div></div></div><p>
					While you cannot create a user until after deployment, it is convenient to ensure that first user is an administrator with full permissions. It is easier to configure this in advance, using the <code class="literal">SUPER_USER</code> configuration object.
				</p></section><section class="section" id="restricting_user_creation"><div class="titlepage"><div><div><h3 class="title">3.1.4. Restricting user creation</h3></div></div></div><p>
					Once you have configured a super user, you can restrict the ability to create new users to the super user group. Set the <code class="literal">FEATURE_USER_CREATION</code> to <code class="literal">false</code> to restrict user creation.
				</p></section><section class="section" id="suggested_configuration_for_automation"><div class="titlepage"><div><div><h3 class="title">3.1.5. Suggested configuration for automation</h3></div></div></div><p>
					Create a <code class="literal">config.yaml</code> configuration file that includes the appropriate settings:
				</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
						
<pre class="programlisting language-yaml">...
FEATURE_USER_INITIALIZE: true
BROWSER_API_CALLS_XHR_ONLY: false
SUPER_USERS:
- quayadmin
FEATURE_USER_CREATION: false
...</pre>
					</p></div></section><section class="section" id="deploying_the_operator_using_the_initial_configuration"><div class="titlepage"><div><div><h3 class="title">3.1.6. Deploying the Operator using the initial configuration</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a Secret using the configuration file
						</p><pre class="screen">$ oc create secret generic --from-file config.yaml=./config.yaml init-config-bundle-secret</pre></li><li class="listitem"><p class="simpara">
							Create a QuayRegistry YAML file <code class="literal">quayregistry.yaml</code>, identifying the unmanaged components and also referencing the created Secret, for example:
						</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: init-config-bundle-secret</pre>
							</p></div></li><li class="listitem"><p class="simpara">
							Deploy the registry:
						</p><pre class="screen">$ oc create -f quayregistry.yaml</pre></li><li class="listitem">
							Create the first user, <code class="literal">quayadmin</code>, using the API
						</li></ol></div></section></section><section class="section" id="operator-storage-preconfig"><div class="titlepage"><div><div><h2 class="title">3.2. Configuring object storage</h2></div></div></div><p>
				You need to configure object storage before installing Red Hat Quay, irrespective of whether you are allowing the Operator to manage the storage or managing it yourself.
			</p><p>
				If you want the Operator to be responsible for managing storage, see the section on <a class="link" href="#operator-managed-storage" title="3.2.2. Managed storage">Managed storage</a> for information on installing and configuring the NooBaa / RHOCS Operator.
			</p><p>
				If you are using a separate storage solution, set <code class="literal">objectstorage</code> as <code class="literal">unmanaged</code> when configuring the Operator. See the following section. <a class="link" href="#operator-unmanaged-storage" title="3.2.1. Unmanaged storage">Unmanaged storage</a>, for details of configuring existing storage.
			</p><section class="section" id="operator-unmanaged-storage"><div class="titlepage"><div><div><h3 class="title">3.2.1. Unmanaged storage</h3></div></div></div><p>
					Some configuration examples for unmanaged storage are provided in this section for convenience. See the Red Hat Quay configuration guide for full details for setting up object storage.
				</p><section class="section" id="config-fields-storage-aws"><div class="titlepage"><div><div><h4 class="title">3.2.1.1. AWS S3 storage</h4></div></div></div><pre class="programlisting language-yaml">DISTRIBUTED_STORAGE_CONFIG:
  s3Storage:
    - S3Storage
    - host: s3.us-east-2.amazonaws.com
      s3_access_key: ABCDEFGHIJKLMN
      s3_secret_key: OL3ABCDEFGHIJKLMN
      s3_bucket: quay_bucket
      storage_path: /datastorage/registry
DISTRIBUTED_STORAGE_DEFAULT_LOCATIONS: []
DISTRIBUTED_STORAGE_PREFERENCE:
    - s3Storage</pre></section><section class="section" id="config-fields-storage-gcp"><div class="titlepage"><div><div><h4 class="title">3.2.1.2. Google cloud storage</h4></div></div></div><pre class="programlisting language-yaml">DISTRIBUTED_STORAGE_CONFIG:
    googleCloudStorage:
        - GoogleCloudStorage
        - access_key: GOOGQIMFB3ABCDEFGHIJKLMN
          bucket_name: quay-bucket
          secret_key: FhDAYe2HeuAKfvZCAGyOioNaaRABCDEFGHIJKLMN
          storage_path: /datastorage/registry
DISTRIBUTED_STORAGE_DEFAULT_LOCATIONS: []
DISTRIBUTED_STORAGE_PREFERENCE:
    - googleCloudStorage</pre></section><section class="section" id="config-fields-storage-azure"><div class="titlepage"><div><div><h4 class="title">3.2.1.3. Azure storage</h4></div></div></div><pre class="programlisting language-yaml">DISTRIBUTED_STORAGE_CONFIG
  azureStorage:
    - AzureStorage
      azure_container: azure_container_here
      storage_path: /datastorage/registry
    - azure_account_name: azure_account_name_here
      azure_account_key: azure_account_key_here
      sas_token: some/path/
      endpoint_url: https://[account-name].blob.core.usgovcloudapi.net <span id="CO1-1"/><span class="callout">1</span>
DISTRIBUTED_STORAGE_DEFAULT_LOCATIONS: []
DISTRIBUTED_STORAGE_PREFERENCE:
    - azureStorage</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO1-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								The <code class="literal">endpoint_url</code> parameter for Azure storage is optional. If left blank, the <code class="literal">endpoint_url</code> will connect to the normal Azure region.
							</div></dd></dl></div></section><section class="section" id="operator-unmanaged-storage-noobaa"><div class="titlepage"><div><div><h4 class="title">3.2.1.4. NooBaa unmanaged storage</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Create a NooBaa Object Bucket Claim in the console at Storage → Object Bucket Claims.
							</li><li class="listitem">
								Retrieve the Object Bucket Claim Data details including the Access Key, Bucket Name, Endpoint (hostname) and Secret Key.
							</li><li class="listitem"><p class="simpara">
								Create a <code class="literal">config.yaml</code> configuration file, using the information for the Object Bucket Claim:
							</p><pre class="screen">DISTRIBUTED_STORAGE_CONFIG:
  default:
    - RHOCSStorage
    - access_key: WmrXtSGk8B3nABCDEFGH
      bucket_name: my-noobaa-bucket-claim-8b844191-dc6c-444e-9ea4-87ece0abcdef
      hostname: s3.openshift-storage.svc.cluster.local
      is_secure: true
      port: "443"
      secret_key: X9P5SDGJtmSuHFCMSLMbdNCMfUABCDEFGH+C5QD
      storage_path: /datastorage/registry
DISTRIBUTED_STORAGE_DEFAULT_LOCATIONS: []
DISTRIBUTED_STORAGE_PREFERENCE:
  - default</pre></li></ol></div></section></section><section class="section" id="operator-managed-storage"><div class="titlepage"><div><div><h3 class="title">3.2.2. Managed storage</h3></div></div></div><p>
					If you want the Operator to manage object storage for Quay, your cluster needs to be capable of providing object storage via the <code class="literal">ObjectBucketClaim</code> API. Using the Red Hat OpenShift Data Foundation (ODF) Operator, there are two supported options available:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							A standalone instance of the Multi-Cloud Object Gateway backed by a local Kubernetes <code class="literal">PersistentVolume</code> storage
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									Not highly available
								</li><li class="listitem">
									Included in the Quay subscription
								</li><li class="listitem">
									Does not require a separate subscription for ODF
								</li></ul></div></li><li class="listitem"><p class="simpara">
							A production deployment of ODF with scale-out Object Service and Ceph
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									Highly available
								</li><li class="listitem">
									Requires a separate subscription for ODF
								</li></ul></div></li></ul></div><p>
					To use the standalone instance option, continue reading below. For production deployment of ODF, please refer to the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_container_storage/">official documentation</a>.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Object storage disk space is allocated automatically by the Operator with 50 GiB. This number represents a usable amount of storage for most small to medium Red Hat Quay installations but may not be sufficient for your use cases. Resizing the RHOCS volume is currently not handled by the Operator. See the section below on resizing managed storage for more details.
					</p></div></div><section class="section" id="operator-standalone-object-gateway"><div class="titlepage"><div><div><h4 class="title">3.2.2.1. About The Standalone Object Gateway</h4></div></div></div><p>
						As part of a Red Hat Quay subscription, users are entitled to use the <span class="emphasis"><em>Multi-Cloud Object Gateway</em></span> (MCG) component of the Red Hat OpenShift Data Foundation Operator (formerly known as OpenShift Container Storage Operator). This gateway component allows you to provide an S3-compatible object storage interface to Quay backed by Kubernetes <code class="literal">PersistentVolume</code>-based block storage. The usage is limited to a Quay deployment managed by the Operator and to the exact specifications of the MCG instance as documented below.
					</p><p>
						Since Red Hat Quay does not support local filesystem storage, users can leverage the gateway in combination with Kubernetes <code class="literal">PersistentVolume</code> storage instead, to provide a supported deployment. A <code class="literal">PersistentVolume</code> is directly mounted on the gateway instance as a backing store for object storage and any block-based <code class="literal">StorageClass</code> is supported.
					</p><p>
						By the nature of <code class="literal">PersistentVolume</code>, this is not a scale-out, highly available solution and does not replace a scale-out storage system like Red Hat OpenShift Data Foundation (ODF). Only a single instance of the gateway is running. If the pod running the gateway becomes unavailable due to rescheduling, updates or unplanned downtime, this will cause temporary degradation of the connected Quay instances.
					</p><section class="section" id="create_a_standalone_object_gateway"><div class="titlepage"><div><div><h5 class="title">3.2.2.1.1. Create A Standalone Object Gateway</h5></div></div></div><p>
							To install the ODF (formerly known as OpenShift Container Storage) Operator and configure a single instance Multi-Cloud Gateway service, follow these steps:
						</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
									Open the OpenShift console and select Operators → OperatorHub, then select the OpenShift Data Foundation Operator.
								</li><li class="listitem">
									Select Install. Accept all default options and select Install again.
								</li><li class="listitem"><p class="simpara">
									Within a minute, the Operator will install and create a namespace <code class="literal">openshift-storage</code>. You can confirm it has completed when the <code class="literal">Status</code> column is marked <code class="literal">Succeeded</code>.
								</p><pre class="screen">When the installation of the ODF Operator is complete, you are prompted to create a storage system. Do not follow this instruction. Instead, create NooBaa object storage as outlined the following steps.</pre></li><li class="listitem"><p class="simpara">
									Create NooBaa object storage. Save the following YAML to a file called <code class="literal">noobaa.yaml</code>.
								</p><pre class="screen">apiVersion: noobaa.io/v1alpha1
kind: NooBaa
metadata:
  name: noobaa
  namespace: openshift-storage
spec:
 dbResources:
   requests:
     cpu: '0.1'
     memory: 1Gi
 dbType: postgres
 coreResources:
   requests:
     cpu: '0.1'
     memory: 1Gi</pre><p class="simpara">
									This will create a single instance deployment of the <span class="emphasis"><em>Multi-cloud Object Gateway</em></span>.
								</p></li><li class="listitem"><p class="simpara">
									Apply the configuration with the following command:
								</p><pre class="screen">$ oc create -n openshift-storage -f noobaa.yaml
noobaa.noobaa.io/noobaa created</pre></li><li class="listitem"><p class="simpara">
									After a couple of minutes, you should see that the MCG instance has finished provisioning (<code class="literal">PHASE</code> column will be set to <code class="literal">Ready</code>):
								</p><pre class="screen">$ oc get -n openshift-storage noobaas noobaa -w
NAME     MGMT-ENDPOINTS              S3-ENDPOINTS                IMAGE                                                                                                            PHASE   AGE
noobaa   [https://10.0.32.3:30318]   [https://10.0.32.3:31958]   registry.redhat.io/ocs4/mcg-core-rhel8@sha256:56624aa7dd4ca178c1887343c7445a9425a841600b1309f6deace37ce6b8678d   Ready   3d18h</pre></li><li class="listitem"><p class="simpara">
									Next, configure a backing store for the gateway. Save the following YAML to a file called <code class="literal">noobaa-pv-backing-store.yaml</code>.
								</p><div class="formalpara"><p class="title"><strong>noobaa-pv-backing-store.yaml</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: noobaa.io/v1alpha1
kind: BackingStore
metadata:
  finalizers:
  - noobaa.io/finalizer
  labels:
    app: noobaa
  name: noobaa-pv-backing-store
  namespace: openshift-storage
spec:
  pvPool:
    numVolumes: 1
    resources:
      requests:
        storage: 50Gi <span id="CO2-1"/><span class="callout">1</span>
    storageClass: STORAGE-CLASS-NAME <span id="CO2-2"/><span class="callout">2</span>
  type: pv-pool</pre>
									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO2-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											The overall capacity of the object storage service, adjust as needed
										</div></dd><dt><a href="#CO2-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">StorageClass</code> to use for the <code class="literal">PersistentVolumes</code> requested, delete this property to use the cluster default
										</div></dd></dl></div></li><li class="listitem"><p class="simpara">
									Apply the configuration with the following command:
								</p><pre class="screen">$ oc create -f noobaa-pv-backing-store.yaml
backingstore.noobaa.io/noobaa-pv-backing-store created</pre><p class="simpara">
									This creates the backing store configuration for the gateway. All images in Quay will be stored as objects through the gateway in a <code class="literal">PersistentVolume</code> created by the above configuration.
								</p></li><li class="listitem"><p class="simpara">
									Finally, run the following command to make the <code class="literal">PersistentVolume</code> backing store the default for all <code class="literal">ObjectBucketClaims</code> issued by the Operator.
								</p><pre class="screen">$ oc patch bucketclass noobaa-default-bucket-class --patch '{"spec":{"placementPolicy":{"tiers":[{"backingStores":["noobaa-pv-backing-store"]}]}}}' --type merge -n openshift-storage</pre></li></ol></div><p>
							This concludes the setup of the <span class="emphasis"><em>Multi-Cloud Object Gateway</em></span> instance for Red Hat Quay. Note that this configuration cannot be run in parallel on a cluster with Red Hat OpenShift Data Foundation installed.
						</p></section></section></section></section><section class="section" id="configuring_the_database"><div class="titlepage"><div><div><h2 class="title">3.3. Configuring the database</h2></div></div></div><section class="section" id="operator-unmanaged-postgres"><div class="titlepage"><div><div><h3 class="title">3.3.1. Using an existing Postgres database</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a configuration file <code class="literal">config.yaml</code> with the necessary database fields:
						</p><div class="formalpara"><p class="title"><strong>config.yaml:</strong></p><p>
								
<pre class="programlisting language-yaml">DB_URI: postgresql://test-quay-database:postgres@test-quay-database:5432/test-quay-database</pre>
							</p></div></li><li class="listitem"><p class="simpara">
							Create a Secret using the configuration file:
						</p><pre class="screen">$ kubectl create secret generic --from-file config.yaml=./config.yaml config-bundle-secret</pre></li><li class="listitem"><p class="simpara">
							Create a QuayRegistry YAML file <code class="literal">quayregistry.yaml</code> which marks the <code class="literal">postgres</code> component as unmanaged and references the created Secret:
						</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: config-bundle-secret
  components:
    - kind: postgres
      managed: false</pre>
							</p></div></li><li class="listitem">
							Deploy the registry as detailed in the following sections.
						</li></ol></div></section><section class="section" id="config-fields-db"><div class="titlepage"><div><div><h3 class="title">3.3.2. Database configuration</h3></div></div></div><p>
					You configure the connection to the database using the required DB_URI field and optional connection arguments in the DB_CONNECTION_ARGS structure. Some key-value pairs defined under DB_CONNECTION_ARGS are generic while others are database-specific. In particular, SSL configuration depends on the database you are deploying, and examples for PostgreSQL and MySQL are given below.
				</p><section class="section" id="database_uri"><div class="titlepage"><div><div><h4 class="title">3.3.2.1. Database URI</h4></div></div></div><div class="table" id="idm45308028608528"><p class="title"><strong>Table 3.1. Database URI</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 17%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45308031023968" scope="col">Field</th><th align="left" valign="top" id="idm45308031022880" scope="col">Type</th><th align="left" valign="top" id="idm45308031021792" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45308031023968">
									<p>
										<span class="strong strong"><strong>DB_URI</strong></span><br/> (Required)
									</p>
									</td><td align="left" valign="top" headers="idm45308031022880">
									<p>
										String
									</p>
									</td><td align="left" valign="top" headers="idm45308031021792">
									<p>
										The URI for accessing the database, including any credentials
									</p>
									</td></tr></tbody></table></div></div><p>
						<span class="strong strong"><strong>Example:</strong></span>
					</p><pre class="screen">postgresql://quayuser:quaypass@quay-server.example.com:5432/quay</pre></section><section class="section" id="database_connection_arguments"><div class="titlepage"><div><div><h4 class="title">3.3.2.2. Database connection arguments</h4></div></div></div><div class="table" id="idm45308031212944"><p class="title"><strong>Table 3.2. Database connection arguments</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 17%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45308025930960" scope="col">Field</th><th align="left" valign="top" id="idm45308025929872" scope="col">Type</th><th align="left" valign="top" id="idm45308025928784" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45308025930960">
									<p>
										<span class="strong strong"><strong>DB_CONNECTION_ARGS</strong></span>
									</p>
									</td><td align="left" valign="top" headers="idm45308025929872">
									<p>
										Object
									</p>
									</td><td align="left" valign="top" headers="idm45308025928784">
									<p>
										Optional connection arguments for the database, such as timeouts and SSL
									</p>
									</td></tr><tr><td align="left" valign="top" headers="idm45308025930960">
									<p>
										   <span class="strong strong"><strong>.autorollback</strong></span>
									</p>
									</td><td align="left" valign="top" headers="idm45308025929872">
									<p>
										Boolean
									</p>
									</td><td align="left" valign="top" headers="idm45308025928784">
									<p>
										Whether to use thread-local connections<br/>  <br/> Should <span class="strong strong"><strong>ALWAYS</strong></span> be <code class="literal">true</code>
									</p>
									</td></tr><tr><td align="left" valign="top" headers="idm45308025930960">
									<p>
										   <span class="strong strong"><strong>.threadlocals</strong></span>
									</p>
									</td><td align="left" valign="top" headers="idm45308025929872">
									<p>
										Boolean
									</p>
									</td><td align="left" valign="top" headers="idm45308025928784">
									<p>
										Whether to use auto-rollback connections <br/>  <br/> Should <span class="strong strong"><strong>ALWAYS</strong></span> be <code class="literal">true</code>
									</p>
									</td></tr></tbody></table></div></div><section class="section" id="postgresql_ssl_connection_arguments"><div class="titlepage"><div><div><h5 class="title">3.3.2.2.1. PostgreSQL SSL connection arguments</h5></div></div></div><p>
							A sample PostgreSQL SSL configuration is given below:
						</p><pre class="screen">DB_CONNECTION_ARGS:
  sslmode: verify-ca
  sslrootcert: /path/to/cacert</pre><p>
							The <code class="literal">sslmode</code> option determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the server. There are six modes:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<span class="strong strong"><strong>disable:</strong></span> only try a non-SSL connection
								</li><li class="listitem">
									<span class="strong strong"><strong>allow:</strong></span> first try a non-SSL connection; if that fails, try an SSL connection
								</li><li class="listitem">
									<span class="strong strong"><strong>prefer:</strong></span> (default) first try an SSL connection; if that fails, try a non-SSL connection
								</li><li class="listitem">
									<span class="strong strong"><strong>require:</strong></span> only try an SSL connection. If a root CA file is present, verify the certificate in the same way as if verify-ca was specified
								</li><li class="listitem">
									<span class="strong strong"><strong>verify-ca:</strong></span> only try an SSL connection, and verify that the server certificate is issued by a trusted certificate authority (CA)
								</li><li class="listitem">
									<span class="strong strong"><strong>verify-full:</strong></span> only try an SSL connection, verify that the server certificate is issued by a trusted CA and that the requested server host name matches that in the certificate
								</li></ul></div><p>
							More information on the valid arguments for PostgreSQL is available at <a class="link" href="https://www.postgresql.org/docs/current/libpq-connect.html">https://www.postgresql.org/docs/current/libpq-connect.html</a>.
						</p></section><section class="section" id="mysql_ssl_connection_arguments"><div class="titlepage"><div><div><h5 class="title">3.3.2.2.2. MySQL SSL connection arguments</h5></div></div></div><p>
							A sample MySQL SSL configuration follows:
						</p><pre class="screen">DB_CONNECTION_ARGS:
  ssl:
    ca: /path/to/cacert</pre><p>
							Information on the valid connection arguments for MySQL is available at <a class="link" href="https://dev.mysql.com/doc/refman/8.0/en/connecting-using-uri-or-key-value-pairs.html">https://dev.mysql.com/doc/refman/8.0/en/connecting-using-uri-or-key-value-pairs.html</a>.
						</p></section></section></section><section class="section" id="operator-managed-postgres"><div class="titlepage"><div><div><h3 class="title">3.3.3. Using the managed PostgreSQL</h3></div></div></div><p>
					Recommendations:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Database backups should be performed regularly using either the supplied tools on the Postgres image or your own backup infrastructure. The Operator does not currently ensure the Postgres database is backed up.
						</li><li class="listitem">
							Restoring the Postgres database from a backup must be done using Postgres tools and procedures. Be aware that your Quay <code class="literal">Pods</code> should not be running while the database restore is in progress.
						</li><li class="listitem">
							Database disk space is allocated automatically by the Operator with 50 GiB. This number represents a usable amount of storage for most small to medium Red Hat Quay installations but may not be sufficient for your use cases. Resizing the database volume is currently not handled by the Operator.
						</li></ul></div></section></section><section class="section" id="operator-preconfig-tls-routes"><div class="titlepage"><div><div><h2 class="title">3.4. Configuring TLS and routes</h2></div></div></div><p>
				Support for OpenShift Container Platform Edge-Termination Routes has been added by way of a new managed component, <code class="literal">tls</code>. This separates the <code class="literal">route</code> component from TLS and allows users to configure both separately. <code class="literal">EXTERNAL_TLS_TERMINATION: true</code> is the opinionated setting. Managed <code class="literal">tls</code> means that the default cluster wildcard cert is used. Unmanaged <code class="literal">tls</code> means that the user provided cert/key pair will be injected into the <code class="literal">Route</code>.
			</p><p>
				<code class="literal">ssl.cert</code> and <code class="literal">ssl.key</code> are now moved to a separate, persistent Secret, which ensures that the cert/key pair is not re-generated upon every reconcile. These are now formatted as <code class="literal">edge</code> routes and mounted to the same directory in the Quay container.
			</p><p>
				Multiple permutations are possible when configuring TLS and Routes, but the following rules apply:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						If TLS is <code class="literal">managed</code>, then route must also be <code class="literal">managed</code>
					</li><li class="listitem">
						If TLS is <code class="literal">unmanaged</code> then you must supply certs, either with the config tool or directly in the config bundle
					</li></ul></div><p>
				The following table outlines the valid options:
			</p><div class="table" id="idm45308031033200"><p class="title"><strong>Table 3.3. Valid configuration options for TLS and routes</strong></p><div class="table-contents"><table class="gt-4-cols lt-7-rows"><colgroup><col style="width: 18%; " class="col_1"/><col style="width: 18%; " class="col_2"/><col style="width: 18%; " class="col_3"/><col style="width: 18%; " class="col_4"/><col style="width: 27%; " class="col_5"/></colgroup><thead><tr><th align="left" valign="top" id="idm45308034075616" scope="col">Option</th><th align="left" valign="top" id="idm45308034074528" scope="col">Route</th><th align="left" valign="top" id="idm45308034073440" scope="col">TLS</th><th align="left" valign="top" id="idm45308031065344" scope="col">Certs provided</th><th align="left" valign="top" id="idm45308031064256" scope="col">Result</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45308034075616">
							<p>
								My own load balancer handles TLS
							</p>
							</td><td align="left" valign="top" headers="idm45308034074528">
							<p>
								Managed
							</p>
							</td><td align="left" valign="top" headers="idm45308034073440">
							<p>
								Managed
							</p>
							</td><td align="left" valign="top" headers="idm45308031065344">
							<p>
								No
							</p>
							</td><td align="left" valign="top" headers="idm45308031064256">
							<p>
								Edge Route with default wildcard cert
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45308034075616">
							<p>
								Red Hat Quay handles TLS
							</p>
							</td><td align="left" valign="top" headers="idm45308034074528">
							<p>
								Managed
							</p>
							</td><td align="left" valign="top" headers="idm45308034073440">
							<p>
								Unmanaged
							</p>
							</td><td align="left" valign="top" headers="idm45308031065344">
							<p>
								Yes
							</p>
							</td><td align="left" valign="top" headers="idm45308031064256">
							<p>
								Passthrough route with certs mounted inside the pod
							</p>
							</td></tr><tr><td align="left" valign="top" headers="idm45308034075616">
							<p>
								Red Hat Quay handles TLS
							</p>
							</td><td align="left" valign="top" headers="idm45308034074528">
							<p>
								Unmanaged
							</p>
							</td><td align="left" valign="top" headers="idm45308034073440">
							<p>
								Unmanaged
							</p>
							</td><td align="left" valign="top" headers="idm45308031065344">
							<p>
								Yes
							</p>
							</td><td align="left" valign="top" headers="idm45308031064256">
							<p>
								Certificates are set inside the quay pod but route must be created manually
							</p>
							</td></tr></tbody></table></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					Red Hat Quay 3.6 does not support builders when TLS is managed by the Operator.
				</p></div></div><section class="section" id="creating_the_config_bundle_secret_with_tls_cert_key_pair"><div class="titlepage"><div><div><h3 class="title">3.4.1. Creating the config bundle secret with TLS cert, key pair:</h3></div></div></div><p>
					To add your own TLS cert and key, include them in the config bundle secret as follows:
				</p><pre class="programlisting language-bash">$ oc create secret generic --from-file config.yaml=./config.yaml --from-file ssl.cert=./ssl.cert --from-file ssl.key=./ssl.key config-bundle-secret</pre></section></section><section class="section" id="operator-components-unmanaged-other"><div class="titlepage"><div><div><h2 class="title">3.5. Configuring other components</h2></div></div></div><section class="section" id="operator-unmanaged-redis"><div class="titlepage"><div><div><h3 class="title">3.5.1. Using external Redis</h3></div></div></div><p>
					If you wish to use an external Redis database, set the component as unmanaged in the <code class="literal">QuayRegistry</code> instance:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a configuration file <code class="literal">config.yaml</code> with the necessary redis fields:
						</p><pre class="programlisting language-yaml">BUILDLOGS_REDIS:
    host: quay-server.example.com
    password: strongpassword
    port: 6379

USER_EVENTS_REDIS:
    host: quay-server.example.com
    password: strongpassword
    port: 6379</pre></li><li class="listitem"><p class="simpara">
							Create a Secret using the configuration file
						</p><pre class="screen">$ oc create secret generic --from-file config.yaml=./config.yaml config-bundle-secret</pre></li><li class="listitem"><p class="simpara">
							Create a QuayRegistry YAML file <code class="literal">quayregistry.yaml</code> which marks redis component as unmanaged and references the created Secret:
						</p><pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: config-bundle-secret
  components:
    - kind: redis
      managed: false</pre></li><li class="listitem">
							Deploy the registry
						</li></ol></div><section class="section" id="config-fields-redis"><div class="titlepage"><div><div><h4 class="title">3.5.1.1. Redis configuration fields</h4></div></div></div><section class="section" id="build_logs"><div class="titlepage"><div><div><h5 class="title">3.5.1.1.1. Build logs</h5></div></div></div><div class="table" id="idm45308028560688"><p class="title"><strong>Table 3.4. Build logs configuration</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 17%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45308028770592" scope="col">Field</th><th align="left" valign="top" id="idm45308028769504" scope="col">Type</th><th align="left" valign="top" id="idm45308028768416" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45308028770592">
										<p>
											<span class="strong strong"><strong>BUILDLOGS_REDIS</strong></span><br/> (Required)
										</p>
										</td><td align="left" valign="top" headers="idm45308028769504">
										<p>
											Object
										</p>
										</td><td align="left" valign="top" headers="idm45308028768416">
										<p>
											Redis connection details for build logs caching
										</p>
										</td></tr><tr><td align="left" valign="top" headers="idm45308028770592">
										<p>
											   <span class="strong strong"><strong>.host</strong></span> <br/>    (Required)
										</p>
										</td><td align="left" valign="top" headers="idm45308028769504">
										<p>
											String
										</p>
										</td><td align="left" valign="top" headers="idm45308028768416">
										<p>
											The hostname at which Redis is accessible<br/>  <br/><span class="strong strong"><strong>Example:</strong></span><br/><code class="literal">quay-server.example.com</code>
										</p>
										</td></tr><tr><td align="left" valign="top" headers="idm45308028770592">
										<p>
											   <span class="strong strong"><strong>.port</strong></span> <br/>    (Required)
										</p>
										</td><td align="left" valign="top" headers="idm45308028769504">
										<p>
											Number
										</p>
										</td><td align="left" valign="top" headers="idm45308028768416">
										<p>
											The port at which Redis is accessible<br/>  <br/><span class="strong strong"><strong>Example:</strong></span><br/><code class="literal">6379</code>
										</p>
										</td></tr><tr><td align="left" valign="top" headers="idm45308028770592">
										<p>
											   <span class="strong strong"><strong>.password</strong></span>
										</p>
										</td><td align="left" valign="top" headers="idm45308028769504">
										<p>
											String
										</p>
										</td><td align="left" valign="top" headers="idm45308028768416">
										<p>
											The port at which Redis is accessible<br/>  <br/><span class="strong strong"><strong>Example:</strong></span><br/><code class="literal">strongpassword</code>
										</p>
										</td></tr></tbody></table></div></div></section><section class="section" id="user_events"><div class="titlepage"><div><div><h5 class="title">3.5.1.1.2. User events</h5></div></div></div><div class="table" id="idm45308025858112"><p class="title"><strong>Table 3.5. User events config</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 17%; " class="col_2"/><col style="width: 33%; " class="col_3"/></colgroup><thead><tr><th align="left" valign="top" id="idm45308025564496" scope="col">Field</th><th align="left" valign="top" id="idm45308025563408" scope="col">Type</th><th align="left" valign="top" id="idm45308025562320" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm45308025564496">
										<p>
											<span class="strong strong"><strong>USER_EVENTS_REDIS</strong></span><br/> (Required)
										</p>
										</td><td align="left" valign="top" headers="idm45308025563408">
										<p>
											Object
										</p>
										</td><td align="left" valign="top" headers="idm45308025562320">
										<p>
											Redis connection details for user event handling
										</p>
										</td></tr><tr><td align="left" valign="top" headers="idm45308025564496">
										<p>
											   <span class="strong strong"><strong>.host</strong></span> <br/>    (Required)
										</p>
										</td><td align="left" valign="top" headers="idm45308025563408">
										<p>
											String
										</p>
										</td><td align="left" valign="top" headers="idm45308025562320">
										<p>
											The hostname at which Redis is accessible<br/>  <br/><span class="strong strong"><strong>Example:</strong></span><br/><code class="literal">quay-server.example.com</code>
										</p>
										</td></tr><tr><td align="left" valign="top" headers="idm45308025564496">
										<p>
											   <span class="strong strong"><strong>.port</strong></span> <br/>    (Required)
										</p>
										</td><td align="left" valign="top" headers="idm45308025563408">
										<p>
											Number
										</p>
										</td><td align="left" valign="top" headers="idm45308025562320">
										<p>
											The port at which Redis is accessible<br/>  <br/><span class="strong strong"><strong>Example:</strong></span><br/><code class="literal">6379</code>
										</p>
										</td></tr><tr><td align="left" valign="top" headers="idm45308025564496">
										<p>
											   <span class="strong strong"><strong>.password</strong></span>
										</p>
										</td><td align="left" valign="top" headers="idm45308025563408">
										<p>
											String
										</p>
										</td><td align="left" valign="top" headers="idm45308025562320">
										<p>
											The port at which Redis is accessible<br/>  <br/><span class="strong strong"><strong>Example:</strong></span><br/><code class="literal">strongpassword</code>
										</p>
										</td></tr></tbody></table></div></div></section><section class="section" id="example_redis_configuration"><div class="titlepage"><div><div><h5 class="title">3.5.1.1.3. Example redis configuration</h5></div></div></div><pre class="screen">BUILDLOGS_REDIS:
    host: quay-server.example.com
    password: strongpassword
    port: 6379

USER_EVENTS_REDIS:
    host: quay-server.example.com
    password: strongpassword
    port: 6379</pre></section></section></section><section class="section" id="operator-unmanaged-hpa"><div class="titlepage"><div><div><h3 class="title">3.5.2. Disabling the Horizontal Pod Autoscaler</h3></div></div></div><p>
					<code class="literal">HorizontalPodAutoscalers</code> have been added to the Clair, Quay, and Mirror pods, so that they now automatically scale during load spikes.
				</p><p>
					As HPA is configured by default to be <code class="literal">managed</code>, the number of pods for Quay, Clair and repository mirroring is set to two. This facilitates the avoidance of downtime when updating / reconfiguring Quay via the Operator or during rescheduling events.
				</p><p>
					If you wish to disable autoscaling or create your own <code class="literal">HorizontalPodAutoscaler</code>, simply specify the component as unmanaged in the <code class="literal">QuayRegistry</code> instance:
				</p><pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  components:
    - kind: horizontalpodautoscaler
      managed: false</pre></section><section class="section" id="operator-unmanaged-route"><div class="titlepage"><div><div><h3 class="title">3.5.3. Disabling Route Component</h3></div></div></div><p>
					To prevent the Operator from creating a <code class="literal">Route</code>:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Mark the component as unmanaged in the <code class="literal">QuayRegistry</code>:
						</p><pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  components:
    - kind: route
      managed: false</pre></li><li class="listitem"><p class="simpara">
							Specify that you want Quay to handle TLS in the configuration, by editing the <code class="literal">config.yaml</code> file:
						</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">...
EXTERNAL_TLS_TERMINATION: false
...
SERVER_HOSTNAME: example-registry-quay-quay-enterprise.apps.user1.example.com
...
PREFERRED_URL_SCHEME: https
...</pre>
							</p></div><p class="simpara">
							If you do not configure the unmanaged Route correctly, you will see an error similar to the following:
						</p><pre class="programlisting language-json">{
  {
    "kind":"QuayRegistry",
    "namespace":"quay-enterprise",
    "name":"example-registry",
    "uid":"d5879ba5-cc92-406c-ba62-8b19cf56d4aa",
    "apiVersion":"quay.redhat.com/v1",
    "resourceVersion":"2418527"
  },
  "reason":"ConfigInvalid",
  "message":"required component `route` marked as unmanaged, but `configBundleSecret` is missing necessary fields"
}</pre></li></ol></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Disabling the default <code class="literal">Route</code> means you are now responsible for creating a <code class="literal">Route</code>, <code class="literal">Service</code>, or <code class="literal">Ingress</code> in order to access the Quay instance and that whatever DNS you use must match the <code class="literal">SERVER_HOSTNAME</code> in the Quay config.
					</p></div></div></section><section class="section" id="operator-unmanaged-monitoring"><div class="titlepage"><div><div><h3 class="title">3.5.4. Unmanaged monitoring</h3></div></div></div><p>
					If you install the Quay Operator in a single namespace, the monitoring component is automatically set to 'unmanaged'. To enable monitoring in this scenario, see the section <a class="xref" href="#monitoring-single-namespace" title="8.2. Enabling monitoring when Operator is installed in a single namespace">Section 8.2, “Enabling monitoring when Operator is installed in a single namespace”</a>.
				</p><p>
					To disable monitoring explicitly:
				</p><pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  components:
    - kind: monitoring
      managed: false</pre></section><section class="section" id="operator-unmanaged-mirroring"><div class="titlepage"><div><div><h3 class="title">3.5.5. Unmanaged mirroring</h3></div></div></div><p>
					To disable mirroring explicitly:
				</p><pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  components:
    - kind: mirroring
      managed: false</pre></section></section></section><section class="chapter" id="operator-deploy"><div class="titlepage"><div><div><h1 class="title">Chapter 4. Deploying Quay using the Quay Operator</h1></div></div></div><p>
			The Operator can be deployed from the command line or from the OpenShift console, but the fundamental steps are the same.
		</p><section class="section" id="operator-deploy-cli"><div class="titlepage"><div><div><h2 class="title">4.1. Deploying Red Hat Quay from the command line</h2></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Create a namespace, for example, <code class="literal">quay-enterprise</code>.
					</li><li class="listitem">
						Create a secret for the config bundle, if you want to pre-configure any aspects of the deployment
					</li><li class="listitem"><p class="simpara">
						Create a <code class="literal">QuayRegistry</code> custom resource in a file called <code class="literal">quayregistry.yaml</code>
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								For a minimal deployment, using all the defaults:
							</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml:</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								If you want to have some components unmanaged, add this information in the <code class="literal">spec</code> field. For example, a minimal deployment might look like:
							</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml:</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  components:
    - kind: clair
      managed: false
    - kind: horizontalpodautoscaler
      managed: false
    - kind: mirror
      managed: false
    - kind: monitoring
      managed: false</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								If you have created a config bundle, for example, <code class="literal">init-config-bundle-secret</code>, reference it in the <code class="literal">quayregistry.yaml</code> file:
							</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml:</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: init-config-bundle-secret</pre>
								</p></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Create the <code class="literal">QuayRegistry</code> in specified namespace:
					</p><pre class="programlisting language-sh">$ oc create -f quayregistry.yaml</pre></li><li class="listitem">
						See the section <a class="link" href="#operator-monitor-deploy-cli" title="4.1.4. Monitoring and debugging the deployment process">Monitoring and debugging the deployment process</a> for information on how to track the progress of the deployment.
					</li><li class="listitem"><p class="simpara">
						Wait until the <code class="literal">status.registryEndpoint</code> is populated.
					</p><pre class="programlisting language-sh">$ oc get quayregistry -n quay-enterprise example-registry -o jsonpath="{.status.registryEndpoint}" -w</pre></li></ol></div><section class="section" id="operator-deploy-view-pods-cli"><div class="titlepage"><div><div><h3 class="title">4.1.1. Viewing created components using the command line</h3></div></div></div><p>
					Use the <code class="literal">oc get pods</code> command to view the deployed components:
				</p><pre class="screen">$ oc get pods -n quay-enterprise

NAME                                                   READY   STATUS      RESTARTS   AGE
example-registry-clair-app-5ffc9f77d6-jwr9s            1/1     Running     0          3m42s
example-registry-clair-app-5ffc9f77d6-wgp7d            1/1     Running     0          3m41s
example-registry-clair-postgres-54956d6d9c-rgs8l       1/1     Running     0          3m5s
example-registry-quay-app-79c6b86c7b-8qnr2             1/1     Running     4          3m42s
example-registry-quay-app-79c6b86c7b-xk85f             1/1     Running     4          3m41s
example-registry-quay-app-upgrade-5kl5r                0/1     Completed   4          3m50s
example-registry-quay-config-editor-597b47c995-svqrl   1/1     Running     0          3m42s
example-registry-quay-database-b466fc4d7-tfrnx         1/1     Running     2          3m42s
example-registry-quay-mirror-6d9bd78756-6lj6p          1/1     Running     0          2m58s
example-registry-quay-mirror-6d9bd78756-bv6gq          1/1     Running     0          2m58s
example-registry-quay-postgres-init-dzbmx              0/1     Completed   0          3m43s
example-registry-quay-redis-8bd67b647-skgqx            1/1     Running     0          3m42s</pre></section><section class="section" id="operator-deploy-hpa"><div class="titlepage"><div><div><h3 class="title">4.1.2. Horizontal Pod Autoscaling (HPA)</h3></div></div></div><p>
					A default deployment shows the following running pods:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Two pods for the Quay application itself (<code class="literal">example-registry-quay-app-*`</code>)
						</li><li class="listitem">
							One Redis pod for Quay logging (<code class="literal">example-registry-quay-redis-*</code>)
						</li><li class="listitem">
							One database pod for PostgreSQL used by Quay for metadata storage (<code class="literal">example-registry-quay-database-*</code>)
						</li><li class="listitem">
							One pod for the Quay config editor (<code class="literal">example-registry-quay-config-editor-*</code>)
						</li><li class="listitem">
							Two Quay mirroring pods (<code class="literal">example-registry-quay-mirror-*</code>)
						</li><li class="listitem">
							Two pods for the Clair application (<code class="literal">example-registry-clair-app-*</code>)
						</li><li class="listitem">
							One PostgreSQL pod for Clair (<code class="literal">example-registry-clair-postgres-*</code>)
						</li></ul></div><p>
					As HPA is configured by default to be <code class="literal">managed</code>, the number of pods for Quay, Clair and repository mirroring is set to two. This facilitates the avoidance of downtime when updating / reconfiguring Quay via the Operator or during rescheduling events.
				</p><pre class="programlisting language-terminal">$ oc get hpa -n quay-enterprise
NAME                           REFERENCE                                 TARGETS           MINPODS   MAXPODS   REPLICAS   AGE
example-registry-clair-app     Deployment/example-registry-clair-app     16%/90%, 0%/90%   2         10        2          13d
example-registry-quay-app      Deployment/example-registry-quay-app      31%/90%, 1%/90%   2         20        2          13d
example-registry-quay-mirror   Deployment/example-registry-quay-mirror   27%/90%, 0%/90%   2         20        2          13d</pre></section><section class="section" id="first-user-api"><div class="titlepage"><div><div><h3 class="title">4.1.3. Using the API to create the first user</h3></div></div></div><p>
					When using the API to create the first user, the following conditions must be met:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The config option <code class="literal">FEATURE_USER_INITIALIZE</code> must be set to <code class="literal">true</code>
						</li><li class="listitem">
							No users can already exist in the database
						</li></ul></div><p>
					For more information on pre-configuring the deployment, see the section <a class="link" href="#config-preconfigure-automation" title="3.1. Pre-configuring Quay for automation">Pre-configuring Quay for automation</a>
				</p><section class="section" id="invoking_the_api"><div class="titlepage"><div><div><h4 class="title">4.1.3.1. Invoking the API</h4></div></div></div><p>
						Using the <code class="literal">status.registryEndpoint</code> URL, invoke the <code class="literal">/api/v1/user/initialize</code> API, passing in the username, password and email address. You can also request an OAuth token by specifying <code class="literal">"access_token": true</code>.
					</p><pre class="programlisting language-bash">$  curl -X POST -k  https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/user/initialize --header 'Content-Type: application/json' --data '{ "username": "quayadmin", "password":"quaypass123", "email": "quayadmin@example.com", "access_token": true}'</pre><pre class="programlisting language-yaml">{"access_token":"6B4QTRSTSD1HMIG915VPX7BMEZBVB9GPNY2FC2ED", "email":"quayadmin@example.com","encrypted_password":"1nZMLH57RIE5UGdL/yYpDOHLqiNCgimb6W9kfF8MjZ1xrfDpRyRs9NUnUuNuAitW","username":"quayadmin"}</pre><p>
						If successful, the method returns an object with the username, email and encrypted password. If a user already exists in the database, an error is returned:
					</p><pre class="programlisting language-bash">$  curl -X POST -k  https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/user/initialize --header 'Content-Type: application/json' --data '{ "username": "quayuser2", "password":"quaypass123", "email": "quayuser2@example.com"}'</pre><pre class="programlisting language-yaml">{"message":"Cannot initialize user in a non-empty database"}</pre><p>
						The password must be at least 8 characters and contain no whitespace:
					</p><pre class="programlisting language-bash"> $  curl -X POST -k  https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/user/initialize --header 'Content-Type: application/json' --data '{ "username": "quayadmin", "password":"pass123", "email": "quayadmin@example.com"}'</pre><pre class="programlisting language-yaml">{"message":"Failed to initialize user: Invalid password, password must be at least 8 characters and contain no whitespace."}</pre></section><section class="section" id="using_the_oauth_token"><div class="titlepage"><div><div><h4 class="title">4.1.3.2. Using the OAuth token</h4></div></div></div><p>
						You can now invoke the rest of the Quay API specifying the returned OAuth code. For example, to get a list of the current users:
					</p><pre class="programlisting language-bash">$ curl -X GET -k -H "Authorization: Bearer 6B4QTRSTSD1HMIG915VPX7BMEZBVB9GPNY2FC2ED" https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/superuser/users/</pre><pre class="programlisting language-yaml">{
    "users": [
        {
            "kind": "user",
            "name": "quayadmin",
            "username": "quayadmin",
            "email": "quayadmin@example.com",
            "verified": true,
            "avatar": {
                "name": "quayadmin",
                "hash": "3e82e9cbf62d25dec0ed1b4c66ca7c5d47ab9f1f271958298dea856fb26adc4c",
                "color": "#e7ba52",
                "kind": "user"
            },
            "super_user": true,
            "enabled": true
        }
    ]
}</pre><p>
						In this instance, the details for the <code class="literal">quayadmin</code> user are returned as it is the only user that has been created so far.
					</p><section class="section" id="create_organization"><div class="titlepage"><div><div><h5 class="title">4.1.3.2.1. Create organization</h5></div></div></div><p>
							To create an organization, use a POST call to <code class="literal">api/v1/organization/</code> endpoint:
						</p><pre class="programlisting language-bash">$ curl -X POST -k --header 'Content-Type: application/json' -H "Authorization: Bearer 6B4QTRSTSD1HMIG915VPX7BMEZBVB9GPNY2FC2ED" https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/organization/ --data '{"name": "testorg", "email": "testorg@example.com"}'</pre><pre class="programlisting language-yaml">"Created"</pre></section><section class="section" id="get_organization_details"><div class="titlepage"><div><div><h5 class="title">4.1.3.2.2. Get organization details</h5></div></div></div><p>
							To retrieve the details of the organization you created:
						</p><pre class="programlisting language-bash">$ curl -X GET -k --header 'Content-Type: application/json' -H "Authorization: Bearer 6B4QTRSTSD1HMIG915VPX7BMEZBVB9GPNY2FC2ED" https://min-registry-quay-quay-enterprise.apps.docs.quayteam.org/api/v1/organization/testorg</pre><pre class="programlisting language-yaml">{
    "name": "testorg",
    "email": "testorg@example.com",
    "avatar": {
        "name": "testorg",
        "hash": "5f113632ad532fc78215c9258a4fb60606d1fa386c91b141116a1317bf9c53c8",
        "color": "#a55194",
        "kind": "user"
    },
    "is_admin": true,
    "is_member": true,
    "teams": {
        "owners": {
            "name": "owners",
            "description": "",
            "role": "admin",
            "avatar": {
                "name": "owners",
                "hash": "6f0e3a8c0eb46e8834b43b03374ece43a030621d92a7437beb48f871e90f8d90",
                "color": "#c7c7c7",
                "kind": "team"
            },
            "can_view": true,
            "repo_count": 0,
            "member_count": 1,
            "is_synced": false
        }
    },
    "ordered_teams": [
        "owners"
    ],
    "invoice_email": false,
    "invoice_email_address": null,
    "tag_expiration_s": 1209600,
    "is_free_account": true
}</pre></section></section></section><section class="section" id="operator-monitor-deploy-cli"><div class="titlepage"><div><div><h3 class="title">4.1.4. Monitoring and debugging the deployment process</h3></div></div></div><p>
					Red Hat Quay 3.6 provides new functionality to troubleshoot problems during the deployment phase. The status in the QuayRegistry object can help you monitor the health of the components during the deployment an help you debug any problems that may arise:
				</p><pre class="screen">$ oc get quayregistry -n quay-enterprise -o yaml</pre><p>
					Immediately after deployment, the QuayRegistry object will show the basic configuration:
				</p><pre class="programlisting language-yaml">apiVersion: v1
items:
- apiVersion: quay.redhat.com/v1
  kind: QuayRegistry
  metadata:
    creationTimestamp: "2021-09-14T10:51:22Z"
    generation: 3
    name: example-registry
    namespace: quay-enterprise
    resourceVersion: "50147"
    selfLink: /apis/quay.redhat.com/v1/namespaces/quay-enterprise/quayregistries/example-registry
    uid: e3fc82ba-e716-4646-bb0f-63c26d05e00e
  spec:
    components:
    - kind: postgres
      managed: true
    - kind: clair
      managed: true
    - kind: redis
      managed: true
    - kind: horizontalpodautoscaler
      managed: true
    - kind: objectstorage
      managed: true
    - kind: route
      managed: true
    - kind: mirror
      managed: true
    - kind: monitoring
      managed: true
    - kind: tls
      managed: true
    configBundleSecret: example-registry-config-bundle-kt55s
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""</pre><p>
					Use the <code class="literal">oc get pods</code> command to view the current state of the deployed components:
				</p><pre class="screen">$ oc get pods -n quay-enterprise

NAME                                                   READY   STATUS              RESTARTS   AGE
example-registry-clair-app-86554c6b49-ds7bl            0/1     ContainerCreating   0          2s
example-registry-clair-app-86554c6b49-hxp5s            0/1     Running             1          17s
example-registry-clair-postgres-68d8857899-lbc5n       0/1     ContainerCreating   0          17s
example-registry-quay-app-upgrade-h2v7h                0/1     ContainerCreating   0          9s
example-registry-quay-config-editor-5f646cbcb7-lbnc2   0/1     ContainerCreating   0          17s
example-registry-quay-database-66f495c9bc-wqsjf        0/1     ContainerCreating   0          17s
example-registry-quay-mirror-854c88457b-d845g          0/1     Init:0/1            0          2s
example-registry-quay-mirror-854c88457b-fghxv          0/1     Init:0/1            0          17s
example-registry-quay-postgres-init-bktdt              0/1     Terminating         0          17s
example-registry-quay-redis-f9b9d44bf-4htpz            0/1     ContainerCreating   0          17s</pre><p>
					While the deployment is in progress, the QuayRegistry object will show the current status. In this instance, database migrations are taking place, and other components are waiting until this completes.
				</p><pre class="programlisting language-yaml">  status:
    conditions:
    - lastTransitionTime: "2021-09-14T10:52:04Z"
      lastUpdateTime: "2021-09-14T10:52:04Z"
      message: all objects created/updated successfully
      reason: ComponentsCreationSuccess
      status: "False"
      type: RolloutBlocked
    - lastTransitionTime: "2021-09-14T10:52:05Z"
      lastUpdateTime: "2021-09-14T10:52:05Z"
      message: running database migrations
      reason: MigrationsInProgress
      status: "False"
      type: Available
    configEditorCredentialsSecret: example-registry-quay-config-editor-credentials-btbkcg8dc9
    configEditorEndpoint: https://example-registry-quay-config-editor-quay-enterprise.apps.docs.quayteam.org
    lastUpdated: 2021-09-14 10:52:05.371425635 +0000 UTC
    unhealthyComponents:
      clair:
      - lastTransitionTime: "2021-09-14T10:51:32Z"
        lastUpdateTime: "2021-09-14T10:51:32Z"
        message: 'Deployment example-registry-clair-postgres: Deployment does not have minimum availability.'
        reason: MinimumReplicasUnavailable
        status: "False"
        type: Available
      - lastTransitionTime: "2021-09-14T10:51:32Z"
        lastUpdateTime: "2021-09-14T10:51:32Z"
        message: 'Deployment example-registry-clair-app: Deployment does not have minimum availability.'
        reason: MinimumReplicasUnavailable
        status: "False"
        type: Available
      mirror:
      - lastTransitionTime: "2021-09-14T10:51:32Z"
        lastUpdateTime: "2021-09-14T10:51:32Z"
        message: 'Deployment example-registry-quay-mirror: Deployment does not have minimum availability.'
        reason: MinimumReplicasUnavailable
        status: "False"
        type: Available</pre><p>
					When the deployment process finishes successfully, the status in the QuayRegistry object shows no unhealthy components:
				</p><pre class="programlisting language-yaml">  status:
    conditions:
    - lastTransitionTime: "2021-09-14T10:52:36Z"
      lastUpdateTime: "2021-09-14T10:52:36Z"
      message: all registry component healthchecks passing
      reason: HealthChecksPassing
      status: "True"
      type: Available
    - lastTransitionTime: "2021-09-14T10:52:46Z"
      lastUpdateTime: "2021-09-14T10:52:46Z"
      message: all objects created/updated successfully
      reason: ComponentsCreationSuccess
      status: "False"
      type: RolloutBlocked
    configEditorCredentialsSecret: example-registry-quay-config-editor-credentials-hg7gg7h57m
    configEditorEndpoint: https://example-registry-quay-config-editor-quay-enterprise.apps.docs.quayteam.org
    currentVersion: 3.6.0
    lastUpdated: 2021-09-14 10:52:46.104181633 +0000 UTC
    registryEndpoint: https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org
    unhealthyComponents: {}</pre></section></section><section class="section" id="operator-deploy-ui"><div class="titlepage"><div><div><h2 class="title">4.2. Deploying Red Hat Quay from the OpenShift console</h2></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Create a namespace, for example, <code class="literal">quay-enterprise</code>.
					</li><li class="listitem">
						Select Operators → Installed Operators, then select the Quay Operator to navigate to the Operator detail view.
					</li><li class="listitem">
						Click 'Create Instance' on the 'Quay Registry' tile under 'Provided APIs'.
					</li><li class="listitem">
						Optionally change the 'Name' of the <code class="literal">QuayRegistry</code>. This will affect the hostname of the registry. All other fields have been populated with defaults.
					</li><li class="listitem">
						Click 'Create' to submit the <code class="literal">QuayRegistry</code> to be deployed by the Quay Operator.
					</li><li class="listitem">
						You should be redirected to the <code class="literal">QuayRegistry</code> list view. Click on the <code class="literal">QuayRegistry</code> you just created to see the details view.
					</li><li class="listitem">
						Once the 'Registry Endpoint' has a value, click it to access your new Quay registry via the UI. You can now select 'Create Account' to create a user and sign in.
					</li></ol></div><section class="section" id="operator-first-user"><div class="titlepage"><div><div><h3 class="title">4.2.1. Using the Quay UI to create the first user</h3></div></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						This procedure assumes that the <code class="literal">FEATURE_USER_CREATION</code> config option has not been set to <code class="literal">false.</code> If it is <code class="literal">false</code>, then the <code class="literal">Create Account</code> functionality on the UI will be disabled, and you will have to use the API to create the first user.
					</p></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							In the OpenShift console, navigate to Operators → Installed Operators, with the appropriate namespace / project.
						</li><li class="listitem"><p class="simpara">
							Click on the newly installed QuayRegistry, to view the details:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/config-editor-details-operator-36.png" alt="QuayRegistry details"/></span>
						</p></li><li class="listitem">
							Once the <code class="literal">Registry Endpoint</code> has a value, navigate to this URL in your browser
						</li><li class="listitem"><p class="simpara">
							Select 'Create Account' in the Quay registry UI to create a user
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/create-account-1.png" alt="Create Account"/></span>
						</p></li><li class="listitem"><p class="simpara">
							Enter details for username, password, email and click <code class="literal">Create Account</code>
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/create-account-2.png" alt="Enter account details"/></span>
						</p></li><li class="listitem"><p class="simpara">
							You are automatically logged in to the Quay registry
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/create-account-3.png" alt="Initial log in"/></span>
						</p></li></ol></div></section></section></section><section class="chapter" id="operator-config-cli"><div class="titlepage"><div><div><h1 class="title">Chapter 5. Configuring Quay on OpenShift using the command line and API</h1></div></div></div><p>
			Once deployed, you can configure the Quay application by editing the Quay configuration bundle secret <code class="literal">spec.configBundleSecret</code> and you can also change the managed status of components in the <code class="literal">spec.components</code> object of the QuayRegistry resource
		</p><p>
			The Operator does not watch the <code class="literal">spec.configBundleSecret</code> resource for changes, so it is recommended that configuration changes be made to a new <code class="literal">Secret</code> resource and that the <code class="literal">spec.configBundleSecret</code> field is updated to reflect the change. In the event there are issues with the new configuration, it is simple to revert the value of <code class="literal">spec.configBundleSecret</code> to the older <code class="literal">Secret</code>.
		</p><p>
			The procedure for changing the configuration involves:
		</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
					Determining the current endpoints and secrets
				</li><li class="listitem">
					Downloading the existing configuration bundle, if Red Hat Quay has already been deployed on OpenShift
				</li><li class="listitem">
					Creating or updating the <code class="literal">config.yaml</code> configuration file
				</li><li class="listitem">
					Assembling any SSL certs required for Quay, or custom SSL certs needed for services
				</li><li class="listitem">
					Creating a new config bundle secret, using the config file and any certs
				</li><li class="listitem">
					Creating or updating the registry, referencing the new config bundle secret and specifying any over-rides for managing components
				</li><li class="listitem">
					Monitoring the deployment to ensure successful completion and that the configuration changes have taken effect
				</li></ol></div><p>
			Alternatively, you can use the config editor UI to configure the Quay application, as described in the section <a class="xref" href="#operator-config-ui" title="Chapter 6. Using the config tool to reconfigure Quay on OpenShift">Chapter 6, <em>Using the config tool to reconfigure Quay on OpenShift</em></a>.
		</p><section class="section" id="operator-config-cli-access"><div class="titlepage"><div><div><h2 class="title">5.1. Determining QuayRegistry endpoints and secrets</h2></div></div></div><p>
				You can examine the QuayRegistry resource, using <code class="literal">oc describe quayregistry</code> or <code class="literal">oc get quayregistry -o yaml</code>, to determine the current endpoints and secrets:
			</p><pre class="programlisting language-yaml">$ oc get quayregistry example-registry -n quay-enterprise -o yaml

apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  ...
  name: example-registry
  namespace: quay-enterprise
  ...
spec:
  components:
  ...
  configBundleSecret: example-registry-quay-config-bundle-fjpnm
status:
  configEditorCredentialsSecret: example-registry-quay-config-editor-credentials-kk55dc7299
  configEditorEndpoint: https://example-registry-quay-config-editor-quay-enterprise.apps.docs.quayteam.org
  currentVersion: 3.6.0
  lastUpdated: 2021-09-21 11:18:13.285192787 +0000 UTC
  registryEndpoint: https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org
  unhealthyComponents: {}</pre><p>
				The relevant fields are:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">registryEndpoint</code>: The URL for your registry, for browser access to the registry UI, and for the registry API endpoint
					</li><li class="listitem">
						<code class="literal">configBundleSecret</code>: The config bundle secret, containing the <code class="literal">config.yaml</code> file and any SSL certs
					</li><li class="listitem">
						<code class="literal">configEditorEndpoint</code>: The URL for the config editor tool, for browser access to the config tool, and for the configuration API
					</li><li class="listitem">
						<code class="literal">configEditorCredentialsSecret</code>: The secret containing the username (typically <code class="literal">quayconfig</code>) and the password for the config editor tool
					</li></ul></div><p>
				To determine the username and password for the config editor tool:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Retrieve the secret:
					</p><pre class="programlisting language-yaml">$ oc get secret -n quay-enterprise example-registry-quay-config-editor-credentials-kk55dc7299 -o yaml

apiVersion: v1
data:
  password: SkZwQkVKTUN0a1BUZmp4dA==
  username: cXVheWNvbmZpZw==
kind: Secret</pre></li><li class="listitem"><p class="simpara">
						Decode the username:
					</p><pre class="screen">$ echo 'cXVheWNvbmZpZw==' | base64 --decode

quayconfig</pre></li><li class="listitem"><p class="simpara">
						Decode the password:
					</p><pre class="screen">$ echo 'SkZwQkVKTUN0a1BUZmp4dA==' | base64 --decode

JFpBEJMCtkPTfjxt</pre></li></ol></div></section><section class="section" id="operator-config-cli-download"><div class="titlepage"><div><div><h2 class="title">5.2. Downloading the existing configuration</h2></div></div></div><p>
				There are a number of methods for accessing the current configuration:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Using the config editor endpoint, specifying the username and password for the config editor:
					</p><pre class="programlisting language-bash">$ curl -k -u quayconfig:JFpBEJMCtkPTfjxt https://example-registry-quay-config-editor-quay-enterprise.apps.docs.quayteam.org/api/v1/config</pre><pre class="programlisting language-yaml">{
    "config.yaml": {
        "ALLOW_PULLS_WITHOUT_STRICT_LOGGING": false,
        "AUTHENTICATION_TYPE": "Database",
        ...
        "USER_RECOVERY_TOKEN_LIFETIME": "30m"
    },
    "certs": {
        "extra_ca_certs/service-ca.crt": "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURVVENDQWptZ0F3SUJBZ0lJRE9kWFhuUXFjMUF3RFFZSktvWklodmNOQVFFTEJRQXdOakUwTURJR0ExVUUKQXd3cmIzQmxibk5vYVdaMExYTmxjblpwWTJVdGMyVnlkbWx1WnkxemFXZHVaWEpBTVRZek1UYzNPREV3TXpBZQpGdzB5TVRBNU1UWXdOelF4TkRKYUZ..."
    }
}</pre></li><li class="listitem"><p class="simpara">
						Using the config bundle secret
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Get the secret data:
							</p><pre class="programlisting language-bash">$ oc get secret -n quay-enterprise example-registry-quay-config-bundle-jkfhs -o jsonpath='{.data}'</pre><pre class="programlisting language-yaml">{
    "config.yaml": "QUxMT1dfUFVMTFNfV0lUSE9VVF9TVFJJQ1RfTE9HR0lORzogZmFsc2UKQVVUSEVOVElDQVRJT05fVFlQRTogRGF0YWJhc2UKQVZBVEFSX0tJTkQ6IGxvY2FsCkRBVEFCQVNFX1NFQ1JFVF9LRVk6IHhlOEc1VDBNbkllaGxNQzNkTjd3MWR5WWxwVmo0a0R2enlxZ3l6Ulp5ZjFpODBmWWU3VDUxU1FPZ3hXelpocFlqYlVxNzRKaDllVVVEVWpyCkRFR
...
OgotIDJ3ClRFQU1fUkVTWU5DX1NUQUxFX1RJTUU6IDYwbQpURVNUSU5HOiBmYWxzZQpVU0VSX1JFQ09WRVJZX1RPS0VOX0xJRkVUSU1FOiAzMG0K",
    "extra_ca_cert_service-ca.crt": "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURVVENDQWptZ0F3SUJBZ0lJRE9kWFhuUXFjMUF3RFFZSktvWklodmNOQVFFTEJRQXdOakUwTURJR0ExVUUKQXd3cmIzQmxibk5vYVdaMExYTmxjblpwWTJVdGMyVnlkbWx1WnkxemFXZHVaWEpBTVRZek1UYzNPREV3TXpBZQpGdzB5TVRBNU1UWXdOelF4TkRKYUZ3MHl
...
XSW1jaApkQXZTWGpFUnZOZEZzN3pHK1VzTmZwN0ZIQkJVWkY4L2RZNWJCR2MwWTVaY0J6bFNjQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K"
}</pre></li><li class="listitem"><p class="simpara">
								Decode the data:
							</p><pre class="programlisting language-bash">$ echo 'QUxMT1dfUFVMTFN...U1FOiAzMG0K' | base64 --decode</pre><pre class="programlisting language-yaml">ALLOW_PULLS_WITHOUT_STRICT_LOGGING: false
AUTHENTICATION_TYPE: Database
...
TAG_EXPIRATION_OPTIONS:
- 2w
TEAM_RESYNC_STALE_TIME: 60m
TESTING: false
USER_RECOVERY_TOKEN_LIFETIME: 30m</pre></li></ol></div></li></ol></div></section><section class="section" id="operator-custom-ssl-certs-config-bundle"><div class="titlepage"><div><div><h2 class="title">5.3. Using the config bundle to configure custom SSL certs</h2></div></div></div><p>
				You can configure custom SSL certs either before initial deployment or after Red Hat Quay is deployed on OpenShift, by creating a new config bundle secret. If you are adding the cert(s) to an existing deployment, you must include the complete existing <code class="literal">config.yaml</code> in the new config bundle secret, even if you are not making any configuration changes.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the secret using embedded data or using files:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Embed the configuration details directly in the Secret resource YAML file, for example:
							</p><div class="formalpara"><p class="title"><strong>custom-ssl-config-bundle.yaml</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: custom-ssl-config-bundle-secret
  namespace: quay-enterprise
data:
  config.yaml: |
    ALLOW_PULLS_WITHOUT_STRICT_LOGGING: false
    AUTHENTICATION_TYPE: Database
    ...
  extra_ca_cert_my-custom-ssl.crt: |
    -----BEGIN CERTIFICATE-----
    MIIDsDCCApigAwIBAgIUCqlzkHjF5i5TXLFy+sepFrZr/UswDQYJKoZIhvcNAQEL
    BQAwbzELMAkGA1UEBhMCSUUxDzANBgNVBAgMBkdBTFdBWTEPMA0GA1UEBwwGR0FM
    ....
    -----END CERTIFICATE-----</pre>
								</p></div><p class="simpara">
								Next, create the secret from the YAML file:
							</p><pre class="screen">$ oc create  -f custom-ssl-config-bundle.yaml</pre></li><li class="listitem"><p class="simpara">
								Alternatively, you can create files containing the desired information, and then create the secret from those files:
							</p><pre class="screen">$ oc create secret generic custom-ssl-config-bundle-secret \
  --from-file=config.yaml \
  --from-file=extra_ca_cert_my-custom-ssl.crt=my-custom-ssl.crt</pre></li></ol></div></li><li class="listitem"><p class="simpara">
						Create or update the QuayRegistry YAML file <code class="literal">quayregistry.yaml</code>, referencing the created Secret, for example:
					</p><div class="formalpara"><p class="title"><strong>quayregistry.yaml</strong></p><p>
							
<pre class="programlisting language-yaml">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: custom-ssl-config-bundle-secret</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						Deploy or update the registry using the YAML file:
					</p><pre class="screen">oc apply -f quayregistry.yaml</pre></li></ol></div></section></section><section class="chapter" id="operator-config-ui"><div class="titlepage"><div><div><h1 class="title">Chapter 6. Using the config tool to reconfigure Quay on OpenShift</h1></div></div></div><section class="section" id="operator-config-ui-access"><div class="titlepage"><div><div><h2 class="title">6.1. Accessing the config editor</h2></div></div></div><p>
				In the Details section of the QuayRegistry screen, the endpoint for the config editor is available, along with a link to the secret containing the credentials for logging into the config editor:
			</p><p>
				<span class="inlinemediaobject"><img src="images/config-editor-details-openshift.png" alt="Config editor details"/></span>
			</p><section class="section" id="retrieving_the_config_editor_credentials"><div class="titlepage"><div><div><h3 class="title">6.1.1. Retrieving the config editor credentials</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Click on the link for the config editor secret:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/config-editor-secret.png" alt="Config editor secret"/></span>
						</p></li><li class="listitem"><p class="simpara">
							In the Data section of the Secret details screen, click <code class="literal">Reveal values</code> to see the credentials for logging in to the config editor:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/config-editor-secret-reveal.png" alt="Config editor secret reveal"/></span>
						</p></li></ol></div></section><section class="section" id="logging_in_to_the_config_editor"><div class="titlepage"><div><div><h3 class="title">6.1.2. Logging in to the config editor</h3></div></div></div><p>
					Browse to the config editor endpoint and then enter the username, typically <code class="literal">quayconfig</code>, and the corresponding password to access the config tool:
				</p><p>
					<span class="inlinemediaobject"><img src="images/config-editor-ui.png" alt="Config editor user interface"/></span>
				</p></section><section class="section" id="operator-config-ui-change"><div class="titlepage"><div><div><h3 class="title">6.1.3. Changing configuration</h3></div></div></div><p>
					In this example of updating the configuration, a superuser is added via the config editor tool:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Add an expiration period, for example <code class="literal">4w</code>, for the time machine functionality:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/ui-time-machine-add.png" alt="Add expiration period"/></span>
						</p></li><li class="listitem">
							Select <code class="literal">Validate Configuration Changes</code> to ensure that the changes are valid
						</li><li class="listitem"><p class="simpara">
							Apply the changes by pressing the <code class="literal">Reconfigure Quay</code> button:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/config-editor-reconfigure.png" alt="Reconfigure"/></span>
						</p></li><li class="listitem"><p class="simpara">
							The config tool notifies you that the change has been submitted to Quay:
						</p><p class="simpara">
							<span class="inlinemediaobject"><img src="images/config-editor-reconfigured.png" alt="Reconfigured"/></span>
						</p></li></ol></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Reconfiguring Red Hat Quay using the config tool UI can lead to the registry being unavailable for a short time, while the updated configuration is applied.
					</p></div></div></section></section><section class="section" id="operator-config-ui-monitoring"><div class="titlepage"><div><div><h2 class="title">6.2. Monitoring reconfiguration in the UI</h2></div></div></div><section class="section" id="quayregistry_resource"><div class="titlepage"><div><div><h3 class="title">6.2.1. QuayRegistry resource</h3></div></div></div><p>
					After reconfiguring the Operator, you can track the progress of the redeployment in the YAML tab for the specific instance of QuayRegistry, in this case, <code class="literal">example-registry</code>:
				</p><p>
					<span class="inlinemediaobject"><img src="images/ui-monitor-deploy-update.png" alt="ui monitor deploy update"/></span>
				</p><p>
					Each time the status changes, you will be prompted to reload the data to see the updated version. Eventually, the Operator will reconcile the changes, and there will be no unhealthy components reported.
				</p><p>
					<span class="inlinemediaobject"><img src="images/ui-monitor-deploy-done.png" alt="ui monitor deploy done"/></span>
				</p></section><section class="section" id="events"><div class="titlepage"><div><div><h3 class="title">6.2.2. Events</h3></div></div></div><p>
					The Events tab for the QuayRegistry shows some events related to the redeployment:
				</p><p>
					<span class="inlinemediaobject"><img src="images/ui-monitor-deploy-streaming-events.png" alt="ui monitor deploy streaming events"/></span>
				</p><p>
					Streaming events, for all resources in the namespace that are affected by the reconfiguration, are available in the OpenShift console under Home → Events:
				</p><p>
					<span class="inlinemediaobject"><img src="images/ui-monitor-deploy-streaming-events.png" alt="ui monitor deploy streaming events"/></span>
				</p></section></section><section class="section" id="operator-config-ui-updated"><div class="titlepage"><div><div><h2 class="title">6.3. Accessing updated information after reconfiguration</h2></div></div></div><section class="section" id="accessing_the_updated_config_tool_credentials_in_the_ui"><div class="titlepage"><div><div><h3 class="title">6.3.1. Accessing the updated config tool credentials in the UI</h3></div></div></div><p>
					Since a new pod has been created for the config tool, a new secret will have been created, and you will need to use the updated password when you next attempt to login:
				</p><p>
					<span class="inlinemediaobject"><img src="images/config-editor-secret-updated.png" alt="Config editor secret updated"/></span>
				</p></section><section class="section" id="accessing_the_updated_config_yaml_in_the_ui"><div class="titlepage"><div><div><h3 class="title">6.3.2. Accessing the updated config.yaml in the UI</h3></div></div></div><p>
					Use the config bundle to access the updated <code class="literal">config.yaml</code> file.
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							On the QuayRegistry details screen, click on the Config Bundle Secret
						</li><li class="listitem">
							In the Data section of the Secret details screen, click Reveal values to see the <code class="literal">config.yaml</code> file
						</li><li class="listitem"><p class="simpara">
							Check that the change has been applied. In this case, <code class="literal">4w</code> should be in the list of <code class="literal">TAG_EXPIRATION_OPTIONS</code>:
						</p><pre class="programlisting language-yaml">...
SERVER_HOSTNAME: example-quay-openshift-operators.apps.docs.quayteam.org
SETUP_COMPLETE: true
SUPER_USERS:
- quayadmin
TAG_EXPIRATION_OPTIONS:
- 2w
- 4w
...</pre></li></ol></div></section></section><section class="section" id="config-ui-custom-ssl-certs"><div class="titlepage"><div><div><h2 class="title">6.4. Custom SSL certificates UI</h2></div></div></div><p>
				The config tool can be used to load custom certificates to facilitate access to resources such as external databases. Select the custom certs to be uploaded, ensuring that they are in PEM format, with an extension <code class="literal">.crt</code>.
			</p><p>
				<span class="inlinemediaobject"><img src="images/ui-custom-ssl-certs.png" alt="Custom SSL certificates"/></span>
			</p><p>
				The config tool also displays a list of any uploaded certificates. Once you upload your custom SSL cert, it will appear in the list:
			</p><p>
				<span class="inlinemediaobject"><img src="images/ui-custom-ssl-certs-uploaded.png" alt="Custom SSL certificates"/></span>
			</p></section><section class="section" id="operator-external-access"><div class="titlepage"><div><div><h2 class="title">6.5. External Access to the Registry</h2></div></div></div><p>
				When running on OpenShift, the <code class="literal">Routes</code> API is available and will automatically be used as a managed component. After creating the <code class="literal">QuayRegistry</code>, the external access point can be found in the status block of the <code class="literal">QuayRegistry</code>:
			</p><pre class="programlisting language-yaml">status:
  registryEndpoint: some-quay.my-namespace.apps.mycluster.com</pre></section></section><section class="chapter" id="quay_operator_features"><div class="titlepage"><div><div><h1 class="title">Chapter 7. Quay Operator features</h1></div></div></div><section class="section" id="operator-console-monitoring-alerting"><div class="titlepage"><div><div><h2 class="title">7.1. Console monitoring and alerting</h2></div></div></div><p>
				Red Hat Quay 3.7 provides support for monitoring Quay instances that were deployed using the Operator, from inside the OpenShift console. The new monitoring features include a Grafana dashboard, access to individual metrics, and alerting to notify for frequently restarting Quay pods.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					To enable the monitoring features, the Operator must be installed in "all namespaces" mode.
				</p></div></div><section class="section" id="dashboard"><div class="titlepage"><div><div><h3 class="title">7.1.1. Dashboard</h3></div></div></div><p>
					In the OpenShift console, navigate to Monitoring → Dashboards and search for the dashboard of your desired Quay registry instance:
				</p><p>
					<span class="inlinemediaobject"><img src="images/choose-dashboard.png" alt="Choose Quay dashboard"/></span>
				</p><p>
					The dashboard shows various statistics including:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The number of Organizations, Repositories, Users and Robot accounts
						</li><li class="listitem">
							CPU Usage and Max Memory Usage
						</li><li class="listitem">
							Rates of Image Pulls and Pushes, and Authentication requests
						</li><li class="listitem">
							API request rate
						</li><li class="listitem">
							Latencies
						</li></ul></div><p>
					<span class="inlinemediaobject"><img src="images/console-dashboard-1.png" alt="Console dashboard"/></span>
				</p></section><section class="section" id="metrics"><div class="titlepage"><div><div><h3 class="title">7.1.2. Metrics</h3></div></div></div><p>
					You can see the underlying metrics behind the Quay dashboard, by accessing Monitoring → Metrics in the UI. In the Expression field, enter the text <code class="literal">quay_</code> to see the list of metrics available:
				</p><p>
					<span class="inlinemediaobject"><img src="images/quay-metrics.png" alt="Quay metrics"/></span>
				</p><p>
					Select a sample metric, for example, <code class="literal">quay_org_rows</code>:
				</p><p>
					<span class="inlinemediaobject"><img src="images/quay-metrics-org-rows.png" alt="Number of Quay organizations"/></span>
				</p><p>
					This metric shows the number of organizations in the registry, and it is directly surfaced in the dashboard as well.
				</p></section><section class="section" id="alerting"><div class="titlepage"><div><div><h3 class="title">7.1.3. Alerting</h3></div></div></div><p>
					An alert is raised if the Quay pods restart too often. The alert can be configured by accessing the Alerting rules tab from Monitoring → Alerting in the consol UI and searching for the Quay-specific alert:
				</p><p>
					<span class="inlinemediaobject"><img src="images/alerting-rules.png" alt="Alerting rules"/></span>
				</p><p>
					Select the QuayPodFrequentlyRestarting rule detail to configure the alert:
				</p><p>
					<span class="inlinemediaobject"><img src="images/quay-pod-frequently-restarting.png" alt="Alerting rule details"/></span>
				</p></section></section><section class="section" id="clair-openshift-airgap-update"><div class="titlepage"><div><div><h2 class="title">7.2. Manually updating the vulnerability databases for Clair in an air-gapped OpenShift cluster</h2></div></div></div><p>
				Clair utilizes packages called <code class="literal">updaters</code> that encapsulate the logic of fetching and parsing different vulnerability databases. Clair supports running updaters in a different environment and importing the results. This is aimed at supporting installations that disallow the Clair cluster from talking to the Internet directly.
			</p><p>
				To manually update the vulnerability databases for Clair in an air-gapped OpenShift cluster, use the following steps:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Obtain the <code class="literal">clairctl</code> program
					</li><li class="listitem">
						Retrieve the Clair config
					</li><li class="listitem">
						Use <code class="literal">clairctl</code> to export the updaters bundle from a Clair instance that has access to the internet
					</li><li class="listitem">
						Update the Clair config in the air-gapped OpenShift cluster to allow access to the Clair database
					</li><li class="listitem">
						Transfer the updaters bundle from the system with internet access, to make it available inside the air-gapped environment
					</li><li class="listitem">
						Use <code class="literal">clairctl</code> to import the updaters bundle into the Clair instance for the air-gapped OpenShift cluster
					</li></ul></div><section class="section" id="clair-clairctl"><div class="titlepage"><div><div><h3 class="title">7.2.1. Obtaining clairctl</h3></div></div></div><p>
					To obtain the <code class="literal">clairctl</code> program from a Clair deployment in an OpenShift cluster, use the <code class="literal">oc cp</code> command, for example:
				</p><pre class="screen">$ oc -n quay-enterprise cp example-registry-clair-app-64dd48f866-6ptgw:/usr/bin/clairctl ./clairctl
$ chmod u+x ./clairctl</pre><p>
					For a standalone Clair deployment, use the <code class="literal">podman cp</code> command, for example:
				</p><pre class="screen">$ sudo podman cp clairv4:/usr/bin/clairctl ./clairctl
$ chmod u+x ./clairctl</pre></section><section class="section" id="retrieving_the_clair_config"><div class="titlepage"><div><div><h3 class="title">7.2.2. Retrieving the Clair config</h3></div></div></div><section class="section" id="clair-openshift-config"><div class="titlepage"><div><div><h4 class="title">7.2.2.1. Clair on OpenShift config</h4></div></div></div><p>
						To retrieve the configuration file for a Clair instance deployed using the OpenShift Operator, retrieve and decode the config secret using the appropriate namespace, and save it to file, for example:
					</p><pre class="screen">$ kubectl get secret -n quay-enterprise example-registry-clair-config-secret  -o "jsonpath={$.data['config\.yaml']}" | base64 -d &gt; clair-config.yaml</pre><p>
						An excerpt from a Clair configuration file is shown below:
					</p><div class="formalpara"><p class="title"><strong>clair-config.yaml</strong></p><p>
							
<pre class="programlisting language-yaml">http_listen_addr: :8080
introspection_addr: ""
log_level: info
indexer:
    connstring: host=example-registry-clair-postgres port=5432 dbname=postgres user=postgres password=postgres sslmode=disable
    scanlock_retry: 10
    layer_scan_concurrency: 5
    migrations: true
    scanner:
        package: {}
        dist: {}
        repo: {}
    airgap: false
matcher:
    connstring: host=example-registry-clair-postgres port=5432 dbname=postgres user=postgres password=postgres sslmode=disable
    max_conn_pool: 100
    indexer_addr: ""
    migrations: true
    period: null
    disable_updaters: false
notifier:
    connstring: host=example-registry-clair-postgres port=5432 dbname=postgres user=postgres password=postgres sslmode=disable
    migrations: true
    indexer_addr: ""
    matcher_addr: ""
    poll_interval: 5m
    delivery_interval: 1m
    ...</pre>
						</p></div></section><section class="section" id="clair-standalone-config-location"><div class="titlepage"><div><div><h4 class="title">7.2.2.2. Standalone Clair config</h4></div></div></div><p>
						For standalone Clair deployments, the config file is the one specified in CLAIR_CONF environment variable in the <code class="literal">podman run</code> command, for example:
					</p><pre class="literallayout">sudo podman run -d --rm --name clairv4 \
  -p 8081:8081 -p 8089:8089 \
  -e CLAIR_CONF=/clair/config.yaml -e CLAIR_MODE=combo \
  -v /etc/clairv4/config:/clair:Z \
  registry.redhat.io/quay/clair-rhel8:v3.7.0</pre></section></section><section class="section" id="clair-export-bundle"><div class="titlepage"><div><div><h3 class="title">7.2.3. Exporting the updaters bundle</h3></div></div></div><p>
					From a Clair instance that has access to the internet, use <code class="literal">clairctl</code> with the appropriate configuration file to export the updaters bundle:
				</p><pre class="screen">$ ./clairctl --config ./config.yaml export-updaters updates.gz</pre></section><section class="section" id="clair-openshift-airgap-database"><div class="titlepage"><div><div><h3 class="title">7.2.4. Configuring access to the Clair database in the air-gapped OpenShift cluster</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Use <code class="literal">kubectl</code> to determine the Clair database service:
						</p><pre class="screen">$ kubectl get svc -n quay-enterprise

NAME                                  TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                             AGE
example-registry-clair-app            ClusterIP      172.30.224.93    &lt;none&gt;        80/TCP,8089/TCP                     4d21h
example-registry-clair-postgres       ClusterIP      172.30.246.88    &lt;none&gt;        5432/TCP                            4d21h
...</pre></li><li class="listitem"><p class="simpara">
							Forward the Clair database port so that it is accessible from the local machine, for example:
						</p><pre class="screen">$ kubectl port-forward -n quay-enterprise service/example-registry-clair-postgres 5432:5432</pre></li><li class="listitem"><p class="simpara">
							Update the Clair configuration file, replacing the value of the <code class="literal">host</code> in the multiple <code class="literal">connstring</code> fields with <code class="literal">localhost</code>, for example:
						</p><div class="formalpara"><p class="title"><strong>clair-config.yaml</strong></p><p>
								
<pre class="programlisting language-yaml">    ...
    connstring: host=localhost port=5432 dbname=postgres user=postgres password=postgres sslmode=disable
    ...</pre>
							</p></div></li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						As an alternative to using <code class="literal">kubectl port-forward</code>, you can use <code class="literal">kubefwd</code> instead. With this method, there is no need to modify the <code class="literal">connstring</code> field in the Clair configuration file to use <code class="literal">localhost</code>.
					</p></div></div></section><section class="section" id="clair-openshift-airgap-import-bundle"><div class="titlepage"><div><div><h3 class="title">7.2.5. Importing the updaters bundle into the air-gapped environment</h3></div></div></div><p>
					After transferring the updaters bundle to the air-gapped environment, use <code class="literal">clairctl</code> to import the bundle into the Clair database deployed by the OpenShift Operator:
				</p><pre class="screen">$ ./clairctl --config ./clair-config.yaml import-updaters updates.gz</pre></section></section><section class="section" id="fips-overview"><div class="titlepage"><div><div><h2 class="title">7.3. FIPS readiness and compliance</h2></div></div></div><p>
				FIPS (the Federal Information Processing Standard developed by the National Institute of Standards and Technology, NIST) is regarded as the gold standard for securing and encrypting sensitive data, particularly in heavily regulated areas such as banking, healthcare and the public sector. Red Hat Enterprise Linux and Red Hat OpenShift Container Platform support this standard by providing a FIPS mode in which the system would only allow usage of certain, FIPS-validated cryptographic modules, like <code class="literal">openssl</code>. This ensures FIPS compliance.
			</p><p>
				Red Hat Quay supports running on RHEL and OCP in FIPS mode in production since version 3.5. Furthermore, Red Hat Quay itself also commits to exclusively using cryptography libraries that are validated or are in the process of being validated by NIST. Red Hat Quay 3.5 has pending FIPS 140-2 validation based on the RHEL 8.3 cryptography libraries. As soon as that validation is finalized, Red Hat Quay will be officially FIPS compliant.
			</p></section></section><section class="chapter" id="advanced_concepts"><div class="titlepage"><div><div><h1 class="title">Chapter 8. Advanced Concepts</h1></div></div></div><section class="section" id="operator-deploy-infrastructure"><div class="titlepage"><div><div><h2 class="title">8.1. Deploying Quay on infrastructure nodes</h2></div></div></div><p>
				By default, Quay-related pods are placed on arbitrary worker nodes when using the Operator to deploy the registry. The OpenShift Container Platform documentation shows how to use machine sets to configure nodes to only host infrastructure components (see <a class="link" href="https://docs.openshift.com/container-platform/4.7/machine_management/creating-infrastructure-machinesets.html">https://docs.openshift.com/container-platform/4.7/machine_management/creating-infrastructure-machinesets.html</a>).
			</p><p>
				If you are not using OCP MachineSet resources to deploy infra nodes, this section shows you how to manually label and taint nodes for infrastructure purposes.
			</p><p>
				Once you have configured your infrastructure nodes, either manually or using machine sets, you can then control the placement of Quay pods on these nodes using node selectors and tolerations.
			</p><section class="section" id="label_and_taint_nodes_for_infrastructure_use"><div class="titlepage"><div><div><h3 class="title">8.1.1. Label and taint nodes for infrastructure use</h3></div></div></div><p>
					In the cluster used in this example, there are three master nodes and six worker nodes:
				</p><pre class="screen">$ oc get nodes
NAME                                               STATUS   ROLES    AGE     VERSION
user1-jcnp6-master-0.c.quay-devel.internal         Ready    master   3h30m   v1.20.0+ba45583
user1-jcnp6-master-1.c.quay-devel.internal         Ready    master   3h30m   v1.20.0+ba45583
user1-jcnp6-master-2.c.quay-devel.internal         Ready    master   3h30m   v1.20.0+ba45583
user1-jcnp6-worker-b-65plj.c.quay-devel.internal   Ready    worker   3h21m   v1.20.0+ba45583
user1-jcnp6-worker-b-jr7hc.c.quay-devel.internal   Ready    worker   3h21m   v1.20.0+ba45583
user1-jcnp6-worker-c-jrq4v.c.quay-devel.internal   Ready    worker   3h21m   v1.20.0+ba45583
user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal   Ready    worker   3h21m   v1.20.0+ba45583
user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal   Ready    worker   3h22m   v1.20.0+ba45583
user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal   Ready    worker   3h21m   v1.20.0+ba45583</pre><p>
					Label the final three worker nodes for infrastructure use:
				</p><pre class="screen">$ oc label node --overwrite user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal node-role.kubernetes.io/infra=
$ oc label node --overwrite user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal node-role.kubernetes.io/infra=
$ oc label node --overwrite user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal node-role.kubernetes.io/infra=</pre><p>
					Now, when you list the nodes in the cluster, the last 3 worker nodes will have an added role of <code class="literal">infra</code>:
				</p><pre class="screen">$ oc get nodes
NAME                                               STATUS   ROLES          AGE     VERSION
user1-jcnp6-master-0.c.quay-devel.internal         Ready    master         4h14m   v1.20.0+ba45583
user1-jcnp6-master-1.c.quay-devel.internal         Ready    master         4h15m   v1.20.0+ba45583
user1-jcnp6-master-2.c.quay-devel.internal         Ready    master         4h14m   v1.20.0+ba45583
user1-jcnp6-worker-b-65plj.c.quay-devel.internal   Ready    worker         4h6m    v1.20.0+ba45583
user1-jcnp6-worker-b-jr7hc.c.quay-devel.internal   Ready    worker         4h5m    v1.20.0+ba45583
user1-jcnp6-worker-c-jrq4v.c.quay-devel.internal   Ready    worker         4h5m    v1.20.0+ba45583
user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal   Ready    infra,worker   4h6m    v1.20.0+ba45583
user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal   Ready    infra,worker   4h6m    v1.20.0+ba45583
user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal   Ready    infra,worker   4h6m    v1.20.0+ba45583</pre><p>
					With an infra node being assigned as a worker, there is a chance that user workloads could get inadvertently assigned to an infra node. To avoid this, you can apply a taint to the infra node and then add tolerations for the pods you want to control.
				</p><pre class="screen">$ oc adm taint nodes user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal node-role.kubernetes.io/infra:NoSchedule
$ oc adm taint nodes user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal node-role.kubernetes.io/infra:NoSchedule
$ oc adm taint nodes user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal node-role.kubernetes.io/infra:NoSchedule</pre></section><section class="section" id="create_a_project_with_node_selector_and_toleration"><div class="titlepage"><div><div><h3 class="title">8.1.2. Create a Project with node selector and toleration</h3></div></div></div><p>
					If you have already deployed Quay using the Quay Operator, remove the installed operator and any specific namespace(s) you created for the deployment.
				</p><p>
					Create a Project resource, specifying a node selector and toleration as shown in the following example:
				</p><div class="formalpara"><p class="title"><strong>quay-registry.yaml</strong></p><p>
						
<pre class="screen">kind: Project
apiVersion: project.openshift.io/v1
metadata:
  name: quay-registry
  annotations:
    openshift.io/node-selector: 'node-role.kubernetes.io/infra='
    scheduler.alpha.kubernetes.io/defaultTolerations: &gt;-
      [{"operator": "Exists", "effect": "NoSchedule", "key":
      "node-role.kubernetes.io/infra"}
      ]</pre>
					</p></div><p>
					Use the <code class="literal">oc apply</code> command to create the project:
				</p><pre class="screen">$ oc apply -f quay-registry.yaml
project.project.openshift.io/quay-registry created</pre><p>
					Any subsequent resources created in the <code class="literal">quay-registry</code> namespace should now be scheduled on the dedicated infrastructure nodes.
				</p></section><section class="section" id="install_the_quay_operator_in_the_namespace"><div class="titlepage"><div><div><h3 class="title">8.1.3. Install the Quay Operator in the namespace</h3></div></div></div><p>
					When installing the Quay Operator, specify the appropriate project namespace explicitly, in this case <code class="literal">quay-registry</code>. This will result in the operator pod itself landing on one of the three infrastructure nodes:
				</p><pre class="screen">$ oc get pods -n quay-registry -o wide
NAME                                    READY   STATUS    RESTARTS   AGE   IP            NODE                                              
quay-operator.v3.4.1-6f6597d8d8-bd4dp   1/1     Running   0          30s   10.131.0.16   user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal</pre></section><section class="section" id="create_the_registry"><div class="titlepage"><div><div><h3 class="title">8.1.4. Create the registry</h3></div></div></div><p>
					Create the registry as explained earlier, and then wait for the deployment to be ready. When you list the Quay pods, you should now see that they have only been scheduled on the three nodes that you have labelled for infrastructure purposes:
				</p><pre class="screen">$ oc get pods -n quay-registry -o wide
NAME                                                   READY   STATUS      RESTARTS   AGE     IP            NODE                                                
example-registry-clair-app-789d6d984d-gpbwd            1/1     Running     1          5m57s   10.130.2.80   user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal
example-registry-clair-postgres-7c8697f5-zkzht         1/1     Running     0          4m53s   10.129.2.19   user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal
example-registry-quay-app-56dd755b6d-glbf7             1/1     Running     1          5m57s   10.129.2.17   user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal
example-registry-quay-config-editor-7bf9bccc7b-dpc6d   1/1     Running     0          5m57s   10.131.0.23   user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal
example-registry-quay-database-8dc7cfd69-dr2cc         1/1     Running     0          5m43s   10.129.2.18   user1-jcnp6-worker-c-pwxfp.c.quay-devel.internal
example-registry-quay-mirror-78df886bcc-v75p9          1/1     Running     0          5m16s   10.131.0.24   user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal
example-registry-quay-postgres-init-8s8g9              0/1     Completed   0          5m54s   10.130.2.79   user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal
example-registry-quay-redis-5688ddcdb6-ndp4t           1/1     Running     0          5m56s   10.130.2.78   user1-jcnp6-worker-d-m9gg4.c.quay-devel.internal
quay-operator.v3.4.1-6f6597d8d8-bd4dp                  1/1     Running     0          22m     10.131.0.16   user1-jcnp6-worker-d-h5tv2.c.quay-devel.internal</pre></section></section><section class="section" id="monitoring-single-namespace"><div class="titlepage"><div><div><h2 class="title">8.2. Enabling monitoring when Operator is installed in a single namespace</h2></div></div></div><p>
				When Red Hat Quay Operator is installed in a single namespace, the monitoring component is unmanaged. To configure monitoring, you need to enable it for user-defined namespaces in OpenShift Container Platform. For more information, see the OCP documentation for <a class="link" href="https://docs.openshift.com/container-platform/4.7/monitoring/configuring-the-monitoring-stack.html">Configuring the monitoring stack</a> and <a class="link" href="https://docs.openshift.com/container-platform/4.7/monitoring/enabling-monitoring-for-user-defined-projects.html">Enabling monitoring for user-defined projects</a>.
			</p><p>
				The following steps show you how to configure monitoring for Quay, based on the OCP documentation.
			</p><section class="section" id="creating_a_cluster_monitoring_config_map"><div class="titlepage"><div><div><h3 class="title">8.2.1. Creating a cluster monitoring config map</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Check whether the <code class="literal">cluster-monitoring-config</code> ConfigMap object exists:
						</p><pre class="screen">$ oc -n openshift-monitoring get configmap cluster-monitoring-config

Error from server (NotFound): configmaps "cluster-monitoring-config" not found</pre></li><li class="listitem"><p class="simpara">
							If the ConfigMap object does not exist: 
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Create the following YAML manifest. In this example, the file is called <code class="literal">cluster-monitoring-config.yaml</code>:
								</p><pre class="screen">$ cat cluster-monitoring-config.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |</pre></li><li class="listitem"><p class="simpara">
									Create the ConfigMap object:
								</p><pre class="screen">$ oc apply -f cluster-monitoring-config.yaml configmap/cluster-monitoring-config created</pre><pre class="screen">$ oc -n openshift-monitoring get configmap cluster-monitoring-config

NAME                        DATA   AGE
cluster-monitoring-config   1      12s</pre></li></ol></div></li></ol></div></section><section class="section" id="creating_a_user_defined_workload_monitoring_config_map"><div class="titlepage"><div><div><h3 class="title">8.2.2. Creating a user-defined workload monitoring config map</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Check whether the <code class="literal">user-workload-monitoring-config</code> ConfigMap object exists:
						</p><pre class="screen">$ oc -n openshift-user-workload-monitoring get configmap user-workload-monitoring-config

Error from server (NotFound): configmaps "user-workload-monitoring-config" not found</pre></li><li class="listitem"><p class="simpara">
							If the ConfigMap object does not exist:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Create the following YAML manifest. In this example, the file is called <code class="literal">user-workload-monitoring-config.yaml</code>:
								</p><pre class="screen">$ cat user-workload-monitoring-config.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: user-workload-monitoring-config
  namespace: openshift-user-workload-monitoring
data:
  config.yaml: |</pre></li><li class="listitem"><p class="simpara">
									Create the ConfigMap object:
								</p><pre class="screen">$ oc apply -f user-workload-monitoring-config.yaml

configmap/user-workload-monitoring-config created</pre></li></ol></div></li></ol></div></section><section class="section" id="enable_monitoring_for_user_defined_projects"><div class="titlepage"><div><div><h3 class="title">8.2.3. Enable monitoring for user-defined projects</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Check whether monitoring for user-defined projects is running:
						</p><pre class="screen">$ oc get pods -n openshift-user-workload-monitoring

No resources found in openshift-user-workload-monitoring namespace.</pre></li><li class="listitem"><p class="simpara">
							Edit the  <code class="literal">cluster-monitoring-config</code> ConfigMap:
						</p><pre class="screen">$ oc -n openshift-monitoring edit configmap cluster-monitoring-config</pre><p class="simpara">
							 
						</p></li><li class="listitem"><p class="simpara">
							Set <code class="literal">enableUserWorkload: true</code> to enable monitoring for user-defined projects on the cluster:
						</p><pre class="programlisting language-yaml">apiVersion: v1
data:
  config.yaml: |
    enableUserWorkload: true
kind: ConfigMap
metadata:
  annotations:</pre></li><li class="listitem"><p class="simpara">
							Save the file to apply the changes and then check that the appropriate pods are running:
						</p><pre class="screen">$ oc get pods -n openshift-user-workload-monitoring

NAME                                   READY   STATUS    RESTARTS   AGE
prometheus-operator-6f96b4b8f8-gq6rl   2/2     Running   0          15s
prometheus-user-workload-0             5/5     Running   1          12s
prometheus-user-workload-1             5/5     Running   1          12s
thanos-ruler-user-workload-0           3/3     Running   0          8s
thanos-ruler-user-workload-1           3/3     Running   0          8s</pre><p class="simpara">
							 
						</p></li></ol></div></section><section class="section" id="create_a_service_object_to_expose_quay_metrics"><div class="titlepage"><div><div><h3 class="title">8.2.4. Create a Service object to expose Quay metrics</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a YAML file for the Service object:
						</p><pre class="screen">$ cat quay-service.yaml

apiVersion: v1
kind: Service
metadata:
  annotations:
  labels:
    quay-component: monitoring
    quay-operator/quayregistry: example-registry
  name: example-registry-quay-metrics
  namespace: quay-enterprise
spec:
  ports:
  - name: quay-metrics
    port: 9091
    protocol: TCP
    targetPort: 9091
  selector:
    quay-component: quay-app
    quay-operator/quayregistry: example-registry
  type: ClusterIP</pre><p class="simpara">
							   
						</p></li><li class="listitem"><p class="simpara">
							Create the Service object:
						</p><pre class="screen">$  oc apply -f quay-service.yaml

service/example-registry-quay-metrics created</pre></li></ol></div></section><section class="section" id="create_a_servicemonitor_object"><div class="titlepage"><div><div><h3 class="title">8.2.5. Create a ServiceMonitor object</h3></div></div></div><p>
					Configure OpenShift Monitoring to scrape the metrics by creating a ServiceMonitor resource.
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a YAML file for the ServiceMonitor resource:
						</p><pre class="screen">$ cat quay-service-monitor.yaml

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    quay-operator/quayregistry: example-registry
  name: example-registry-quay-metrics-monitor
  namespace: quay-enterprise
spec:
  endpoints:
  - port: quay-metrics
  namespaceSelector:
    any: true
  selector:
    matchLabels:
      quay-component: monitoring</pre></li><li class="listitem"><p class="simpara">
							Create the ServiceMonitor:
						</p><pre class="screen">$  oc apply -f quay-service-monitor.yaml

servicemonitor.monitoring.coreos.com/example-registry-quay-metrics-monitor created</pre></li></ol></div></section><section class="section" id="view_the_metrics_in_openshift"><div class="titlepage"><div><div><h3 class="title">8.2.6. View the metrics in OpenShift</h3></div></div></div><p>
					You can access the metrics in the OpenShift console under Monitoring → Metrics. In the Expression field, enter the text <code class="literal">quay_</code> to see the list of metrics available:
				</p><p>
					<span class="inlinemediaobject"><img src="images/metrics-single-namespace.png" alt="Quay metrics"/></span>
				</p><p>
					For example, if you have added users to your registry, select the <code class="literal">quay-users_rows</code> metric:
				</p><p>
					<span class="inlinemediaobject"><img src="images/metrics-single-namespace-users.png" alt="Quay metrics"/></span>
				</p></section></section><section class="section" id="operator-resize-storage"><div class="titlepage"><div><div><h2 class="title">8.3. Resizing Managed Storage</h2></div></div></div><p>
				The Quay Operator creates default object storage using the defaults provided by RHOCS when creating a <code class="literal">NooBaa</code> object (50 Gib). There are two ways to extend this storage; you can resize an existing PVC or add more PVCs to a new storage pool.
			</p><section class="section" id="resize_noobaa_pvc"><div class="titlepage"><div><div><h3 class="title">8.3.1. Resize Noobaa PVC</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Log into the OpenShift console and select <code class="literal">Storage</code> → <code class="literal">Persistent Volume Claims</code>.
						</li><li class="listitem">
							Select the <code class="literal">PersistentVolumeClaim</code> named like <code class="literal">noobaa-default-backing-store-noobaa-pvc-*</code>.
						</li><li class="listitem">
							From the Action menu, select <code class="literal">Expand PVC</code>.
						</li><li class="listitem">
							Enter the new size of the Persistent Volume Claim and select <code class="literal">Expand</code>.
						</li></ol></div><p>
					After a few minutes (depending on the size of the PVC), the expanded size should reflect in the PVC’s <code class="literal">Capacity</code> field.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Expanding CSI volumes is a Technology Preview feature only. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html/storage/expanding-persistent-volumes">https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html/storage/expanding-persistent-volumes</a>.
					</p></div></div></section><section class="section" id="add_another_storage_pool"><div class="titlepage"><div><div><h3 class="title">8.3.2. Add Another Storage Pool</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Log into the OpenShift console and select <code class="literal">Networking</code> → <code class="literal">Routes</code>. Make sure the <code class="literal">openshift-storage</code> project is selected.
						</li><li class="listitem">
							Click on the <code class="literal">Location</code> field for the <code class="literal">noobaa-mgmt</code> Route.
						</li><li class="listitem">
							Log into the Noobaa Management Console.
						</li><li class="listitem">
							On the main dashboard, under <code class="literal">Storage Resources</code>, select <code class="literal">Add Storage Resources</code>.
						</li><li class="listitem">
							Select <code class="literal">Deploy Kubernetes Pool</code>
						</li><li class="listitem">
							Enter a new pool name. Click <code class="literal">Next</code>.
						</li><li class="listitem">
							Choose the number of Pods to manage the pool and set the size per node. Click <code class="literal">Next</code>.
						</li><li class="listitem">
							Click <code class="literal">Deploy</code>.
						</li></ol></div><p>
					After a few minutes, the additional storage pool will be added to the Noobaa resources and available for use by Red Hat Quay.
				</p></section></section><section class="section" id="operator-customize-images"><div class="titlepage"><div><div><h2 class="title">8.4. Customizing Default Operator Images</h2></div></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					Using this mechanism is not supported for production Quay environments and is strongly encouraged only for development/testing purposes. There is no guarantee your deployment will work correctly when using non-default images with the Quay Operator.
				</p></div></div><p>
				In certain circumstances, it may be useful to override the default images used by the Operator. This can be done by setting one or more environment variables in the Quay Operator <code class="literal">ClusterServiceVersion</code>.
			</p><section class="section" id="environment_variables"><div class="titlepage"><div><div><h3 class="title">8.4.1. Environment Variables</h3></div></div></div><p>
					The following environment variables are used in the Operator to override component images:
				</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"/><col style="width: 50%; " class="col_2"/></colgroup><tbody><tr><td align="left" valign="top">
								<p>
									Environment Variable
								</p>
								</td><td align="left" valign="top">
								<p>
									Component
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									<code class="literal">RELATED_IMAGE_COMPONENT_QUAY</code>
								</p>
								</td><td align="left" valign="top">
								<p>
									<code class="literal">base</code>
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									<code class="literal">RELATED_IMAGE_COMPONENT_CLAIR</code>
								</p>
								</td><td align="left" valign="top">
								<p>
									<code class="literal">clair</code>
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									<code class="literal">RELATED_IMAGE_COMPONENT_POSTGRES</code>
								</p>
								</td><td align="left" valign="top">
								<p>
									<code class="literal">postgres</code> and <code class="literal">clair</code> databases
								</p>
								</td></tr><tr><td align="left" valign="top">
								<p>
									<code class="literal">RELATED_IMAGE_COMPONENT_REDIS</code>
								</p>
								</td><td align="left" valign="top">
								<p>
									<code class="literal">redis</code>
								</p>
								</td></tr></tbody></table></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Override images <span class="strong strong"><strong>must</strong></span> be referenced by manifest (@sha256:), not by tag (:latest).
					</p></div></div></section><section class="section" id="applying_overrides_to_a_running_operator"><div class="titlepage"><div><div><h3 class="title">8.4.2. Applying Overrides to a Running Operator</h3></div></div></div><p>
					When the Quay Operator is installed in a cluster via the <a class="link" href="https://docs.openshift.com/container-platform/4.6/operators/understanding/olm/olm-understanding-olm.html">Operator Lifecycle Manager (OLM)</a>, the managed component container images can be easily overridden by modifying the <code class="literal">ClusterServiceVersion</code> object, which is OLM’s representation of a running Operator in the cluster. Find the Quay Operator’s <code class="literal">ClusterServiceVersion</code> either by using a Kubernetes UI or <code class="literal">kubectl</code>/<code class="literal">oc</code>:
				</p><pre class="screen">$ oc get clusterserviceversions -n &lt;your-namespace&gt;</pre><p>
					Using the UI, <code class="literal">oc edit</code>, or any other method, modify the Quay <code class="literal">ClusterServiceVersion</code> to include the environment variables outlined above to point to the override images:
				</p><p>
					<span class="strong strong"><strong>JSONPath</strong></span>: <code class="literal">spec.install.spec.deployments[0].spec.template.spec.containers[0].env</code>
				</p><pre class="programlisting language-yaml">- name: RELATED_IMAGE_COMPONENT_QUAY
  value: quay.io/projectquay/quay@sha256:c35f5af964431673f4ff5c9e90bdf45f19e38b8742b5903d41c10cc7f6339a6d
- name: RELATED_IMAGE_COMPONENT_CLAIR
  value: quay.io/projectquay/clair@sha256:70c99feceb4c0973540d22e740659cd8d616775d3ad1c1698ddf71d0221f3ce6
- name: RELATED_IMAGE_COMPONENT_POSTGRES
  value: centos/postgresql-10-centos7@sha256:de1560cb35e5ec643e7b3a772ebaac8e3a7a2a8e8271d9e91ff023539b4dfb33
- name: RELATED_IMAGE_COMPONENT_REDIS
  value: centos/redis-32-centos7@sha256:06dbb609484330ec6be6090109f1fa16e936afcf975d1cbc5fff3e6c7cae7542</pre><p>
					Note that this is done at the Operator level, so every QuayRegistry will be deployed using these same overrides.
				</p></section></section><section class="section" id="operator-cloudfront"><div class="titlepage"><div><div><h2 class="title">8.5. AWS S3 CloudFront</h2></div></div></div><p>
				If you use AWS S3 CloudFront for backend registry storage, specify the private key as shown in the following example:
			</p><pre class="literallayout">$ oc create secret generic --from-file config.yaml=./config_awss3cloudfront.yaml --from-file default-cloudfront-signing-key.pem=./default-cloudfront-signing-key.pem test-config-bundle</pre></section></section><section class="chapter" id="red-hat-quay-builders-enhancement"><div class="titlepage"><div><div><h1 class="title">Chapter 9. Red Hat Quay build enhancements</h1></div></div></div><p>
			Prior to Red Hat Quay 3.7, Quay ran <code class="literal">podman</code> commands in virtual machines launched by pods. Running builds on virtual platforms requires enabling nested virtualization, which is not featured in Red Hat Enterprise Linux or OpenShift Container Platform. As a result, builds had to run on bare-metal clusters, which is an inefficient use of resources.
		</p><p>
			With Red Hat Quay 3.7., the bare-metal constraint required to run builds has been removed by adding an additional build option which does not contain the virtual machine layer. As a result, builds can be run on virtualized platforms. Backwards compatibility to run previous build configurations are also available.
		</p><section class="section" id="red-hat-quay-builds-architecture"><div class="titlepage"><div><div><h2 class="title">9.1. Red Hat Quay enhanced build architecture</h2></div></div></div><p>
				The preceding image shows the expected design flow and architecture of the enhanced build features:
			</p><p>
				<span class="inlinemediaobject"><img src="images/quay-builds-architecture.png" alt="Enhanced Quay builds architecture"/></span>
			</p><p>
				With this enhancement, the build manager first creates the <code class="literal">Job Object</code>. Then, the <code class="literal">Job Object</code> then creates a pod using the <code class="literal">quay-builder-image</code>. The <code class="literal">quay-builder-image</code> will contain the <code class="literal">quay-builder binary</code> and the <code class="literal">Podman</code> service. The created pod runs as <code class="literal">unprivileged</code>. The <code class="literal">quay-builder binary</code> then builds the image while communicating status and retrieving build information from the Build Manager.
			</p></section><section class="section" id="red-hat-quay-build-limitations"><div class="titlepage"><div><div><h2 class="title">9.2. Red Hat Quay build limitations</h2></div></div></div><p>
				Running builds in Red Hat Quay in an unprivileged context might cause some commands that were working under the previous build strategy to fail. Attempts to change the build strategy could potentially cause performance issues and reliability with the build.
			</p><p>
				Running builds direclty in a container will not have the same isolation as using virtual machines. Changing the build environment might also caused builds that were previously working to fail.
			</p></section><section class="section" id="builders-virtual-environment"><div class="titlepage"><div><div><h2 class="title">9.3. Creating a Red Hat Quay builders environment with OpenShift</h2></div></div></div><section class="section" id="openshift_tls_component"><div class="titlepage"><div><div><h3 class="title">9.3.1. OpenShift TLS component</h3></div></div></div><p>
					The Red Hat Quay 3.6 Operator has introduced the <code class="literal">tls</code> component which allows you to control TLS configuration.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Red Hat Quay 3.6 does not support builders when the TLS component is managed by the Operator.
					</p></div></div><p>
					If you set <code class="literal">tls</code> to <code class="literal">unmanaged</code>, you supply your own <code class="literal">ssl.cert</code> and <code class="literal">ssl.key</code> files. In this instance, if you want your cluster to support builders, you must add both the Quay route and the builder route name to the SAN list in the cert, or alternatively use a wildcard. To add the builder route, use the following format:
				</p><pre class="programlisting language-bash">[quayregistry-cr-name]-quay-builder-[ocp-namespace].[ocp-domain-name]:443</pre></section><section class="section" id="red-hat-quay-quota-builders-establishment"><div class="titlepage"><div><div><h3 class="title">9.3.2. Using OpenShift Container Platform for Red Hat Quay builders</h3></div></div></div><p>
					The following procedure describes how you can implement the builders feature in Red Hat Quay.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Builders require SSL certificates. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/deploy_red_hat_quay_for_proof-of-concept_non-production_purposes/advanced_red_hat_quay_deployment#using_ssl_to_protect_connections_to_red_hat_quay">Adding TLS certificates to the Red Hat Quay container</a>.
						</li><li class="listitem">
							If you are using AWS S3 storage, you must modify your storage bucket in the AWS console, prior to running builders. See "Modifying your AWS S3 storage bucket" in the following section for the required parameters.
						</li></ul></div><div class="admonition note"><div class="admonition_header">Procedure</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								This procedure assumes you already have a cluster provisioned and a Quay Operator running.
							</li><li class="listitem">
								This procedure is for setting up a virtual namespace on OpenShift Container Platform.
							</li></ul></div></div></div><section class="section" id="red-hat-quay-setting-up-builders"><div class="titlepage"><div><div><h4 class="title">9.3.2.1. Preparing OpenShift Container Platform for virtual builders</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Log in to your Red Hat Quay cluster using a cluster admin account.
							</li><li class="listitem"><p class="simpara">
								Create a new project where your virtual builders will be run (e.g., <code class="literal">virtual-builders</code>).
							</p><pre class="programlisting language-terminal">$ oc new-project virtual-builders</pre></li><li class="listitem"><p class="simpara">
								Create a <code class="literal">ServiceAccount</code> in this <code class="literal">Project</code> that will be used to run builds.
							</p><pre class="programlisting language-terminal">$ oc create sa -n virtual-builders quay-builder</pre></li><li class="listitem"><p class="simpara">
								Provide the created service account with editing permissions so that it can run the build:
							</p><pre class="programlisting language-terminal">$ oc adm policy -n virtual-builders add-role-to-user edit system:serviceaccount:virtual-builders:quay-builder</pre></li><li class="listitem"><p class="simpara">
								Grant the Quay builder <code class="literal">anyuid scc</code> permissions:
							</p><pre class="programlisting language-terminal">$ oc adm policy -n virtual-builders add-scc-to-user anyuid -z quay-builder</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									This action requires cluster admin privileges. This is required because builders must run as the Podman user for unprivileged or rootless builds to work.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Obtain the token for the Quay builder service account:
							</p><pre class="programlisting language-terminal">$ oc sa get-token -n virtual-builders quay-builder</pre><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
									
<pre class="programlisting language-terminal">eyJhbGciOiJSUzI1NiIsImtpZCI6IldfQUJkaDVmb3ltTHZ0dGZMYjhIWnYxZTQzN2dJVEJxcDJscldSdEUtYWsifQ...</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								Determine the builder route:
							</p><pre class="programlisting language-terminal">$ oc get route -n quay-enterprise</pre><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
									
<pre class="programlisting language-terminal">NAME                                  HOST/PORT                                                                    PATH   SERVICES                              PORT   TERMINATION     WILDCARD
...
example-registry-quay-builder         example-registry-quay-builder-quay-enterprise.apps.docs.quayteam.org                example-registry-quay-app             grpc   edge/Redirect   None
...</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								Generate a self-signed SSL certificate with the .crt extension:
							</p><pre class="screen">$ SECRET=$(oc get sa openshift-apiserver-sa --namespace=openshift-apiserver -o json | jq -r '.secrets[] | select(.name | contains("openshift-apiserver-sa-token"))'.name)</pre><pre class="screen">$ oc get secret $SECRET -n openshift-apiserver -o json | jq  '.data."ca.crt"' -r | base64 -d &gt; extra_ca_cert_build_cluster.crt</pre></li><li class="listitem"><p class="simpara">
								Locate the secret for you config bundle in the Console, and choose Actions → Edit Secret and add the appropriate builder configuration:
							</p><pre class="programlisting language-yaml">FEATURE_USER_INITIALIZE: true
BROWSER_API_CALLS_XHR_ONLY: false
SUPER_USERS:
- &lt;superusername&gt;
FEATURE_USER_CREATION: false
FEATURE_QUOTA_MANAGEMENT: true
FEATURE_BUILD_SUPPORT: True
BUILDMAN_HOSTNAME: &lt;sample_build_route&gt; <span id="CO3-1"/><span class="callout">1</span>
BUILD_MANAGER:
  - ephemeral
  - ALLOWED_WORKER_COUNT: 1
    ORCHESTRATOR_PREFIX: buildman/production/
    ORCHESTRATOR:
      REDIS_HOST: &lt;sample_redis_hostname&gt; <span id="CO3-2"/><span class="callout">2</span>
      REDIS_PASSWORD: ""
      REDIS_SSL: false
      REDIS_SKIP_KEYSPACE_EVENT_SETUP: false
    EXECUTORS:
      - EXECUTOR: kubernetesPodman
        NAME: openshift
        BUILDER_NAMESPACE: &lt;sample_builder_namespace&gt; <span id="CO3-3"/><span class="callout">3</span>
        SETUP_TIME: 180
        MINIMUM_RETRY_THRESHOLD:
        BUILDER_CONTAINER_IMAGE: &lt;sample_builder_container_image&gt; <span id="CO3-4"/><span class="callout">4</span>
        # Kubernetes resource options
        K8S_API_SERVER: &lt;sample_k8s_api_server&gt; <span id="CO3-5"/><span class="callout">5</span>
        K8S_API_TLS_CA: &lt;sample_crt_file&gt; <span id="CO3-6"/><span class="callout">6</span>
        VOLUME_SIZE: 8G
        KUBERNETES_DISTRIBUTION: openshift
        CONTAINER_MEMORY_LIMITS: 300Mi
        CONTAINER_CPU_LIMITS: 1G <span id="CO3-7"/><span class="callout">7</span>
        CONTAINER_MEMORY_REQUEST: 300Mi
        CONTAINER_CPU_REQUEST: 1G
        NODE_SELECTOR_LABEL_KEY: ""
        NODE_SELECTOR_LABEL_VALUE: ""
        SERVICE_ACCOUNT_NAME: &lt;sample_service_account_name&gt;
        SERVICE_ACCOUNT_TOKEN: &lt;sample_account_token&gt; <span id="CO3-8"/><span class="callout">8</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO3-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The build route is obtained by running <code class="literal">oc get route -n</code> with the name of your OpenShift Operators namespace. A port must be provided at the end of the route, for example, and it should follow the following format: <code class="literal">[quayregistry-cr-name]-quay-builder-[ocp-namespace].[ocp-domain-name]:443</code>.
									</div></dd><dt><a href="#CO3-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										If your Redis host has a password or SSL certificates, you must update accordingly.
									</div></dd><dt><a href="#CO3-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Set to match the name of your virtual builders namespace, for example, <code class="literal">virtual-builders</code>.
									</div></dd><dt><a href="#CO3-4"><span class="callout">4</span></a> </dt><dd><div class="para">
										For early access, the <code class="literal">BUILDER_CONTAINER_IMAGE</code> is currently <code class="literal">quay.io/projectquay/quay-builder:3.7.0-rc.2</code>. Note that this might change during the early access window. In the event this happens, customers will be alerted.
									</div></dd><dt><a href="#CO3-5"><span class="callout">5</span></a> </dt><dd><div class="para">
										Obtained by running <code class="literal">oc cluster-info</code>.
									</div></dd><dt><a href="#CO3-6"><span class="callout">6</span></a> </dt><dd><div class="para">
										You must manually create and add your custom CA cert, for example, <code class="literal">K8S_API_TLS_CA: extra_ca_cert_build_cluster.crt</code>
									</div></dd><dt><a href="#CO3-7"><span class="callout">7</span></a> </dt><dd><div class="para">
										For virtual builds, you must ensure that there are enough resources in your cluster.
									</div></dd><dt><a href="#CO3-8"><span class="callout">8</span></a> </dt><dd><div class="para">
										Obtained when running <code class="literal">oc create sa</code>.
									</div></dd></dl></div><div class="formalpara"><p class="title"><strong>Sample config</strong></p><p>
									
<pre class="programlisting language-yaml">FEATURE_USER_INITIALIZE: true
BROWSER_API_CALLS_XHR_ONLY: false
SUPER_USERS:
- quayadmin
FEATURE_USER_CREATION: false
FEATURE_QUOTA_MANAGEMENT: true
FEATURE_BUILD_SUPPORT: True
BUILDMAN_HOSTNAME: example-registry-quay-builder-quay-enterprise.apps.docs.quayteam.org:443
BUILD_MANAGER:
  - ephemeral
  - ALLOWED_WORKER_COUNT: 1
    ORCHESTRATOR_PREFIX: buildman/production/
    ORCHESTRATOR:
      REDIS_HOST: example-registry-quay-redis
      REDIS_PASSWORD: ""
      REDIS_SSL: false
      REDIS_SKIP_KEYSPACE_EVENT_SETUP: false
    EXECUTORS:
      - EXECUTOR: kubernetesPodman
        NAME: openshift
        BUILDER_NAMESPACE: virtual-builders
        SETUP_TIME: 180
        MINIMUM_RETRY_THRESHOLD:
        BUILDER_CONTAINER_IMAGE: quay.io/projectquay/quay-builder:3.7.0-rc.2
        # Kubernetes resource options
        K8S_API_SERVER: api.docs.quayteam.org:6443
        K8S_API_TLS_CA: /conf/stack/extra_ca_certs/build_cluster.crt
        VOLUME_SIZE: 8G
        KUBERNETES_DISTRIBUTION: openshift
        CONTAINER_MEMORY_LIMITS: 1Gi
        CONTAINER_CPU_LIMITS: 1080m
        CONTAINER_MEMORY_REQUEST: 1Gi
        CONTAINER_CPU_REQUEST: 580m
        NODE_SELECTOR_LABEL_KEY: ""
        NODE_SELECTOR_LABEL_VALUE: ""
        SERVICE_ACCOUNT_NAME: quay-builder
        SERVICE_ACCOUNT_TOKEN: "eyJhbGciOiJSUzI1NiIsImtpZCI6IldfQUJkaDVmb3ltTHZ0dGZMYjhIWnYxZTQzN2dJVEJxcDJscldSdEUtYWsifQ"</pre>
								</p></div></li></ol></div></section><section class="section" id="red-hat-quay-manual-ssl-for-builders"><div class="titlepage"><div><div><h4 class="title">9.3.2.2. Manually adding SSL certificates.</h4></div></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Due to a known issue with the configuration tool, you must manually add your custom SSL certificates to properly run builders. Use the following procedure to manually add custom SSL certificates. For more information creating SSL certificates, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/deploy_red_hat_quay_for_proof-of-concept_non-production_purposes/advanced_red_hat_quay_deployment#using_ssl_to_protect_connections_to_red_hat_quay">Adding TLS certificates to the Red Hat Quay container</a>.
								</li></ul></div></div></div><section class="section" id="create_and_sign_certs"><div class="titlepage"><div><div><h5 class="title">9.3.2.2.1. Create and sign certs</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Create a certificate authority and sign a certificate. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/deploy_red_hat_quay_for_proof-of-concept_non-production_purposes/advanced_red_hat_quay_deployment#create-a-ca-and-sign-a-certificate">Create a Certificate Authority and sign a certificate</a>.
								</p><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
												Add an <code class="literal">alt_name</code> for the URL of your Quay registry.
											</li><li class="listitem">
												Add an <code class="literal">alt_name</code> for the <code class="literal">BUILDMAN_HOSTNAME</code> that is specified in your config.yaml.
											</li></ul></div><pre class="programlisting language-terminal">[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
subjectAltName = @alt_names
[alt_names]
DNS.1 = example-registry-quay-quay-enterprise.apps.docs.quayteam.org
DNS.2 = example-registry-quay-builder-quay-enterprise.apps.docs.quayteam.org</pre></div></div><div class="formalpara"><p class="title"><strong>Sample commands</strong></p><p>
										
<pre class="programlisting language-terminal">$ openssl genrsa -out rootCA.key 2048
$ openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.pem
$ openssl genrsa -out ssl.key 2048
$ openssl req -new -key ssl.key -out ssl.csr
$ openssl x509 -req -in ssl.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out ssl.cert -days 356 -extensions v3_req -extfile openssl.cnf</pre>
									</p></div></li></ol></div></section><section class="section" id="set_tls_to_unmanaged"><div class="titlepage"><div><div><h5 class="title">9.3.2.2.2. Set TLS to unmanaged</h5></div></div></div><p>
							In your Quay Registry yaml, set <code class="literal">kind: tls</code> to <code class="literal">managed: false</code>:
						</p><pre class="programlisting language-yaml">  - kind: tls
    managed: false</pre><p>
							In the events, you should see that the change is blocked until you set up the appropriate config:
						</p><pre class="programlisting language-yaml">    - lastTransitionTime: '2022-03-28T12:56:49Z'
      lastUpdateTime: '2022-03-28T12:56:49Z'
      message: &gt;-
        required component `tls` marked as unmanaged, but `configBundleSecret`
        is missing necessary fields
      reason: ConfigInvalid
      status: 'True'</pre></section><section class="section" id="create_temporary_secrets"><div class="titlepage"><div><div><h5 class="title">9.3.2.2.3. Create temporary secrets</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Create a secret in your default namespace for the CA cert:
								</p><pre class="screen">$ oc create secret generic -n quay-enterprise temp-crt --from-file extra_ca_cert_build_cluster.crt</pre></li><li class="listitem"><p class="simpara">
									Create a secret in your default namespace for the ssl.key and ssl.cert files:
								</p><pre class="screen">$ oc create secret generic -n quay-enterprise quay-config-ssl --from-file ssl.cert --from-file ssl.key</pre></li></ol></div></section><section class="section" id="copy_secret_data_to_config_yaml"><div class="titlepage"><div><div><h5 class="title">9.3.2.2.4. Copy secret data to config.yaml</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
									Locate the new secrets in the console UI at <span class="strong strong"><strong>Workloads</strong></span> → <span class="strong strong"><strong>Secrets</strong></span>.
								</li><li class="listitem"><p class="simpara">
									For each secret, locate the YAML view:
								</p><pre class="programlisting language-yaml">kind: Secret
apiVersion: v1
metadata:
  name: temp-crt
  namespace: quay-enterprise
  uid: a4818adb-8e21-443a-a8db-f334ace9f6d0
  resourceVersion: '9087855'
  creationTimestamp: '2022-03-28T13:05:30Z'
...
data:
  extra_ca_cert_build_cluster.crt: &gt;-
    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURNakNDQWhxZ0F3SUJBZ0l....
type: Opaque</pre><pre class="programlisting language-yaml">kind: Secret
apiVersion: v1
metadata:
  name: quay-config-ssl
  namespace: quay-enterprise
  uid: 4f5ae352-17d8-4e2d-89a2-143a3280783c
  resourceVersion: '9090567'
  creationTimestamp: '2022-03-28T13:10:34Z'
...
data:
  ssl.cert: &gt;-
    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVaakNDQTA2Z0F3SUJBZ0lVT...
  ssl.key: &gt;-
    LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFcFFJQkFBS0NBUUVBc...
type: Opaque</pre></li><li class="listitem"><p class="simpara">
									Locate the secret for your Quay Registry configuration bundle in the UI, or via the command line by running a command such as:
								</p><pre class="programlisting language-terminal">$ oc get quayregistries.quay.redhat.com -o jsonpath="{.items[0].spec.configBundleSecret}{'\n'}"  -n quay-enterprise</pre></li><li class="listitem"><p class="simpara">
									Edit the YAML for your config bundle secret, adding the data from the two secrets you created:
								</p><pre class="programlisting language-yaml">kind: Secret
apiVersion: v1
metadata:
  name: init-config-bundle-secret
  namespace: quay-enterprise
  uid: 4724aca5-bff0-406a-9162-ccb1972a27c1
  resourceVersion: '4383160'
  creationTimestamp: '2022-03-22T12:35:59Z'
...
data:
  config.yaml: &gt;-
    RkVBVFVSRV9VU0VSX0lOSVRJQUxJWkU6IHRydWUKQlJ...
  extra_ca_cert_build_cluster.crt: &gt;-
    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURNakNDQWhxZ0F3SUJBZ0ldw....
  ssl.cert: &gt;-
    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVaakNDQTA2Z0F3SUJBZ0lVT...
  ssl.key: &gt;-
    LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFcFFJQkFBS0NBUUVBc...
type: Opaque</pre></li><li class="listitem"><p class="simpara">
									Click <span class="strong strong"><strong>Save</strong></span>. You should see the pods being re-started:
								</p><pre class="programlisting language-terminal">$ oc get pods -n quay-enterprise</pre><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
										
<pre class="programlisting language-terminal">NAME                                                   READY   STATUS              RESTARTS   AGE
...
example-registry-quay-app-6786987b99-vgg2v             0/1     ContainerCreating   0          2s
example-registry-quay-app-7975d4889f-q7tvl             1/1     Running             0          5d21h
example-registry-quay-app-7975d4889f-zn8bb             1/1     Running             0          5d21h
example-registry-quay-app-upgrade-lswsn                0/1     Completed           0          6d1h
example-registry-quay-config-editor-77847fc4f5-nsbbv   0/1     ContainerCreating   0          2s
example-registry-quay-config-editor-c6c4d9ccd-2mwg2    1/1     Running             0          5d21h
example-registry-quay-database-66969cd859-n2ssm        1/1     Running             0          6d1h
example-registry-quay-mirror-764d7b68d9-jmlkk          1/1     Terminating         0          5d21h
example-registry-quay-mirror-764d7b68d9-jqzwg          1/1     Terminating         0          5d21h
example-registry-quay-redis-7cc5f6c977-956g8           1/1     Running             0          5d21h</pre>
									</p></div></li><li class="listitem"><p class="simpara">
									After your Quay registry has reconfigured, check that your Quay app pods are running:
								</p><pre class="programlisting language-terminal">$ oc get pods -n quay-enterprise</pre><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
										
<pre class="programlisting language-terminal">example-registry-quay-app-6786987b99-sz6kb             1/1     Running            0          7m45s
example-registry-quay-app-6786987b99-vgg2v             1/1     Running            0          9m1s
example-registry-quay-app-upgrade-lswsn                0/1     Completed          0          6d1h
example-registry-quay-config-editor-77847fc4f5-nsbbv   1/1     Running            0          9m1s
example-registry-quay-database-66969cd859-n2ssm        1/1     Running            0          6d1h
example-registry-quay-mirror-758fc68ff7-5wxlp          1/1     Running            0          8m29s
example-registry-quay-mirror-758fc68ff7-lbl82          1/1     Running            0          8m29s
example-registry-quay-redis-7cc5f6c977-956g8           1/1     Running            0          5d21h</pre>
									</p></div></li><li class="listitem"><p class="simpara">
									In your browser, access the registry endpoint and validate that the certificate has been updated appropriately:
								</p><pre class="programlisting language-terminal">Common Name (CN)	example-registry-quay-quay-enterprise.apps.docs.quayteam.org
Organisation (O)	DOCS
Organisational Unit (OU)	QUAY</pre></li></ol></div></section></section><section class="section" id="red-hat-quay-builders-ui"><div class="titlepage"><div><div><h4 class="title">9.3.2.3. Using the UI to create a build trigger</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Log in to your Quay repository.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Create New Repository</strong></span> and create a new registry, for example, <code class="literal">testrepo</code>.
							</li><li class="listitem"><p class="simpara">
								On the <span class="strong strong"><strong>Repositories</strong></span> page, click <span class="strong strong"><strong>Builds</strong></span> tab on the left hand pane. Alternatively, use the corresponding URL directly, for example:
							</p><pre class="screen">https://example-registry-quay-quay-enterprise.apps.docs.quayteam.org/repository/quayadmin/testrepo?tab=builds</pre><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									In some cases, the builder might have issues resolving hostnames. This issue might be related to the <code class="literal">dnsPolicy</code> being set to <code class="literal">default</code> on the job object. Currently, there is no workaround for this issue. It will be resolved in a future version of Red Hat Quay.
								</p></div></div></li><li class="listitem">
								Click <span class="strong strong"><strong>Create Build Trigger</strong></span> → <span class="strong strong"><strong>Custom Git Repository Push</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Enter the HTTPS or SSH style URL used to clone your Git repository, then click <span class="strong strong"><strong>Continue</strong></span>. For example:
							</p><pre class="screen">https://github.com/gabriel-rh/actions_test.git</pre></li><li class="listitem">
								Check <span class="strong strong"><strong>Tag manifest with the branch or tag name</strong></span> and then click <span class="strong strong"><strong>Continue</strong></span>.
							</li><li class="listitem">
								Enter the location of the Dockerfile to build when the trigger is invoked, for example, <code class="literal">/Dockerfile</code> and click <span class="strong strong"><strong>Continue</strong></span>.
							</li><li class="listitem">
								Enter the location of the context for the Docker build, for example, <code class="literal">/</code>, and click <span class="strong strong"><strong>Continue</strong></span>.
							</li><li class="listitem">
								If warranted, create a Robot Account. Otherwise, click <span class="strong strong"><strong>Continue</strong></span>.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Continue</strong></span> to verify the parameters.
							</li><li class="listitem">
								On the <span class="strong strong"><strong>Builds</strong></span> page, click <span class="strong strong"><strong>Options</strong></span> icon of your Trigger Name, and then click <span class="strong strong"><strong>Run Trigger Now</strong></span>.
							</li><li class="listitem">
								Enter a commit SHA from the Git repository and click <span class="strong strong"><strong>Start Build</strong></span>.
							</li><li class="listitem"><p class="simpara">
								You can check the status of your build by clicking the commit in the <span class="strong strong"><strong>Build History</strong></span> page, or by running <code class="literal">oc get pods -n virtual-builders</code>.
							</p><pre class="screen"> $ oc get pods -n virtual-builders
NAME                                               READY   STATUS    RESTARTS   AGE
f192fe4a-c802-4275-bcce-d2031e635126-9l2b5-25lg2   1/1     Running   0          7s</pre><pre class="screen">$ oc get pods -n virtual-builders
NAME                                               READY   STATUS        RESTARTS   AGE
f192fe4a-c802-4275-bcce-d2031e635126-9l2b5-25lg2   1/1     Terminating   0          9s</pre><pre class="screen">$ oc get pods -n virtual-builders
No resources found in virtual-builders namespace.</pre></li><li class="listitem"><p class="simpara">
								When the build is finished, you can check the status of the tag under <span class="strong strong"><strong>Tags</strong></span> on the left hand pane.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									With early access, full build logs and timestamps of builds are currently unavailable.
								</p></div></div></li></ol></div></section><section class="section" id="red-hat-quay-s3-bucket-modify"><div class="titlepage"><div><div><h4 class="title">9.3.2.4. Modifying your AWS S3 storage bucket</h4></div></div></div><p>
						If you are using AWS S3 storage, you must modify your storage bucket in the AWS console, prior to running builders.
					</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Log in to your AWS console at <a class="link" href="https://s3.console.aws.amazon.com">s3.console.aws.com</a>.
							</li><li class="listitem">
								In the search bar, search for <code class="literal">S3</code> and then click <span class="strong strong"><strong>S3</strong></span>.
							</li><li class="listitem">
								Click the name of your bucket, for example, <code class="literal">myawsbucket</code>.
							</li><li class="listitem">
								Click the <span class="strong strong"><strong>Permissions</strong></span> tab.
							</li><li class="listitem"><p class="simpara">
								Under <span class="strong strong"><strong>Cross-origin resource sharing (CORS)</strong></span>, include the following parameters:
							</p><pre class="programlisting language-yaml">  [
      {
          "AllowedHeaders": [
              "Authorization"
          ],
          "AllowedMethods": [
              "GET"
          ],
          "AllowedOrigins": [
              "*"
          ],
          "ExposeHeaders": [],
          "MaxAgeSeconds": 3000
      },
      {
          "AllowedHeaders": [
              "Content-Type",
              "x-amz-acl",
              "origin"
          ],
          "AllowedMethods": [
              "PUT"
          ],
          "AllowedOrigins": [
              "*"
          ],
          "ExposeHeaders": [],
          "MaxAgeSeconds": 3000
      }
  ]</pre></li></ol></div></section></section></section></section><section class="chapter" id="georepl-intro"><div class="titlepage"><div><div><h1 class="title">Chapter 10. Geo-replication</h1></div></div></div><p>
			Geo-replication allows multiple, geographically distributed Quay deployments to work as a single registry from the perspective of a client or user. It significantly improves push and pull performance in a globally-distributed Quay setup. Image data is asynchronously replicated in the background with transparent failover / redirect for clients.
		</p><p>
			With Red Hat Quay 3.7, deployments of Red Hat Quay with geo-replication is supported by standalone and Operator deployments.
		</p><section class="section" id="geo_replication_features"><div class="titlepage"><div><div><h2 class="title">10.1. Geo-replication features</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						When geo-replication is configured, container image pushes will be written to the preferred storage engine for that Red Hat Quay instance (typically the nearest storage backend within the region).
					</li><li class="listitem">
						After the initial push, image data will be replicated in the background to other storage engines.
					</li><li class="listitem">
						The list of replication locations is configurable and those can be different storage backends.
					</li><li class="listitem">
						An image pull will always use the closest available storage engine, to maximize pull performance.
					</li><li class="listitem">
						If replication hasn’t been completed yet, the pull will use the source storage backend instead.
					</li></ul></div></section><section class="section" id="georepl-prereqs"><div class="titlepage"><div><div><h2 class="title">10.2. Geo-replication requirements and constraints</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						A single database, and therefore all metadata and Quay configuration, is shared across all regions.
					</li><li class="listitem">
						A single Redis cache is shared across the entire Quay setup and needs to accessible by all Quay pods.
					</li><li class="listitem">
						The exact same configuration should be used across all regions, with exception of the storage backend, which can be configured explicitly using the <code class="literal">QUAY_DISTRIBUTED_STORAGE_PREFERENCE</code> environment variable.
					</li><li class="listitem">
						Geo-Replication requires object storage in each region. It does not work with local storage or NFS.
					</li><li class="listitem">
						Each region must be able to access every storage engine in each region (requires a network path).
					</li><li class="listitem">
						Alternatively, the storage proxy option can be used.
					</li><li class="listitem">
						The entire storage backend (all blobs) is replicated. This is in contrast to repository mirroring, which can be limited to an organization or repository or image.
					</li><li class="listitem">
						All Quay instances must share the same entrypoint, typically via load balancer.
					</li><li class="listitem">
						All Quay instances must have the same set of superusers, as they are defined inside the common configuration file.
					</li><li class="listitem">
						Geo-Replication requires SSL/TSL certificates and keys. For more information, see <a class="link" href="https://dxp-docs.ext.us-west.aws.prod.paas.redhat.com/documentation/en-us/red_hat_quay/3.6/html-single/deploy_red_hat_quay_for_proof-of-concept_non-production_purposes/index#using_ssl_to_protect_connections_to_red_hat_quay">Using SSL to protect connections to Red Hat Quay</a>.
					</li></ul></div><p>
				If the above requirements cannot be met, you should instead use two or more distinct Quay deployments and take advantage of repository mirroring functionality.
			</p></section><section class="section" id="georepl-arch-operator"><div class="titlepage"><div><div><h2 class="title">10.3. Geo-replication - Quay Operator</h2></div></div></div><section class="section" id="geo_replication_architecture_quay_operator"><div class="titlepage"><div><div><h3 class="title">10.3.1. Geo-replication architecture - Quay Operator</h3></div></div></div><p>
					<span class="inlinemediaobject"><img src="images/178_Quay_architecture_0821_georeplication_openshift.png" alt="Georeplication architecture"/></span>
				</p><p>
					In the example shown above, Quay Operator is deployed in two separate regions, with a common database and a common Redis instance. Localized image storage is provided in each region and image pulls are served from the closest available storage engine. Container image pushes are written to the preferred storage engine for the Quay instance, and will then be replicated, in the background, to the other storage engines.
				</p></section><section class="section" id="georepl-deploy-operator"><div class="titlepage"><div><div><h3 class="title">10.3.2. Setting up geo-replication on Openshift</h3></div></div></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Deploy Quay postgres instance:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Login to the database
								</li><li class="listitem"><p class="simpara">
									Create a database for Quay
								</p><pre class="programlisting language-terminal">CREATE DATABASE quay;</pre></li><li class="listitem"><p class="simpara">
									Enable pg_trm extension inside the database
								</p><pre class="programlisting language-terminal">\c quay;
CREATE EXTENSION IF NOT EXISTS pg_trgm;</pre></li></ol></div></li><li class="listitem"><p class="simpara">
							Deploy a Redis instance:
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										Deploying a Redis instance might be unnecessary if your cloud provider has its own service.
									</li><li class="listitem">
										Deploying a Redis instance is required if you are leveraging Builders.
									</li></ul></div></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Deploy a VM for Redis
								</li><li class="listitem">
									Make sure that it is accessible from the clusters where Quay is running
								</li><li class="listitem">
									Port 6379/TCP must be open
								</li><li class="listitem"><p class="simpara">
									Run Redis inside the instance
								</p><pre class="programlisting language-terminal">sudo dnf install -y podman
podman run -d --name redis -p 6379:6379 redis</pre></li></ol></div></li><li class="listitem"><p class="simpara">
							Create two object storage backends, one for each cluster
						</p><p class="simpara">
							Ideally one object storage bucket will be close to the 1st cluster (primary) while the other will run closer to the 2nd cluster (secondary).
						</p></li><li class="listitem">
							Deploy the clusters with the same config bundle, using environment variable overrides to select the appropriate storage backend for an individual cluster
						</li><li class="listitem">
							Configure a load balancer, to provide a single entry point to the clusters
						</li></ol></div><section class="section" id="configuration"><div class="titlepage"><div><div><h4 class="title">10.3.2.1. Configuration</h4></div></div></div><p>
						The <code class="literal">config.yaml</code> file is shared between clusters, and will contain the details for the common PostgreSQL, Redis and storage backends:
					</p><div class="formalpara"><p class="title"><strong>config.yaml</strong></p><p>
							
<pre class="screen">DB_CONNECTION_ARGS:
  autorollback: true
  threadlocals: true
DB_URI: postgresql://postgres:password@10.19.0.1:5432/quay <span id="CO4-1"/><span class="callout">1</span>
BUILDLOGS_REDIS:
  host: 10.19.0.2
  port: 6379
USER_EVENTS_REDIS:
  host: 10.19.0.2
  port: 6379
DISTRIBUTED_STORAGE_CONFIG:
  usstorage:
    - GoogleCloudStorage
    - access_key: GOOGQGPGVMASAAMQABCDEFG
      bucket_name: georep-test-bucket-0
      secret_key: AYWfEaxX/u84XRA2vUX5C987654321
      storage_path: /quaygcp
  eustorage:
    - GoogleCloudStorage
    - access_key: GOOGQGPGVMASAAMQWERTYUIOP
      bucket_name: georep-test-bucket-1
      secret_key: AYWfEaxX/u84XRA2vUX5Cuj12345678
      storage_path: /quaygcp
DISTRIBUTED_STORAGE_DEFAULT_LOCATIONS:
  - usstorage
  - eustorage
DISTRIBUTED_STORAGE_PREFERENCE:
  - usstorage
  - eustorage</pre>
						</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO4-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								The PostgreSQL DB_URI must also be included in the Clair configuration file. For more information about retrieving the Clair configuration file on OpenShift, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3/html/deploy_red_hat_quay_on_openshift_with_the_quay_operator/quay_operator_features#clair-openshift-config">Retrieving the Clair config</a>.
							</div></dd></dl></div><p>
						Create the <code class="literal">configBundleSecret</code>:
					</p><pre class="programlisting language-terminal">$ oc create secret generic --from-file config.yaml=./config.yaml georep-config-bundle</pre><p>
						In each of the clusters, set the <code class="literal">configBundleSecret</code> and use the <code class="literal">QUAY_DISTRIBUTED_STORAGE_PREFERENCE</code> environmental variable override to configure the appropriate storage for that cluster:
					</p><div class="formalpara"><p class="title"><strong>US cluster</strong></p><p>
							
<pre class="screen">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: georep-config-bundle
  components:
    - kind: postgres
      managed: false
    - kind: clairpostgres
      managed: false
    - kind: redis
      managed: false
    - kind: quay
      managed: true
      overrides:
        env:
          - name: QUAY_DISTRIBUTED_STORAGE_PREFERENCE
            value: usstorage</pre>
						</p></div><div class="formalpara"><p class="title"><strong>European cluster</strong></p><p>
							
<pre class="screen">apiVersion: quay.redhat.com/v1
kind: QuayRegistry
metadata:
  name: example-registry
  namespace: quay-enterprise
spec:
  configBundleSecret: georep-config-bundle
  components:
    - kind: postgres
      managed: false
    - kind: clairpostgres
      managed: false
    - kind: redis
      managed: false
    - kind: quay
      managed: true
      overrides:
        env:
          - name: QUAY_DISTRIBUTED_STORAGE_PREFERENCE
            value: eustorage</pre>
						</p></div></section></section><section class="section" id="georepl-mixed-storage"><div class="titlepage"><div><div><h3 class="title">10.3.3. Mixed storage for geo-replication</h3></div></div></div><p>
					Quay geo-replication supports the use of different, and multiple, replication targets for example, using AWS S3 storage on public cloud and using Ceph storage on-prem. This complicates the key requirement of granting access to all storage backends from all Quay pods and cluster nodes. As a result, it is recommended that you:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Use a VPN to prevent visibility of the internal storage <span class="emphasis"><em>or</em></span>
						</li><li class="listitem">
							Use a token pair that only allows access to the specified bucket used by Quay
						</li></ul></div><p>
					This will result in the public cloud instance of Quay having access to on-prem storage but the network will be encrypted, protected, and will use ACLs, thereby meeting security requirements.
				</p><p>
					If you cannot implement these security measures, it may be preferable to deploy two distinct Quay registries and to use repository mirroring as an alternative to geo-replication.
				</p></section></section></section><section class="chapter" id="operator-upgrade"><div class="titlepage"><div><div><h1 class="title">Chapter 11. Upgrading the Quay Operator Overview</h1></div></div></div><p>
			The Quay Operator follows a <span class="emphasis"><em>synchronized versioning</em></span> scheme, which means that each version of the Operator is tied to the version of Quay and the components that it manages. There is no field on the <code class="literal">QuayRegistry</code> custom resource which sets the version of Quay to deploy; the Operator only knows how to deploy a single version of all components. This scheme was chosen to ensure that all components work well together and to reduce the complexity of the Operator needing to know how to manage the lifecycles of many different versions of Quay on Kubernetes.
		</p><section class="section" id="operator_lifecycle_manager"><div class="titlepage"><div><div><h2 class="title">11.1. Operator Lifecycle Manager</h2></div></div></div><p>
				The Quay Operator should be installed and upgraded using the <a class="link" href="https://docs.openshift.com/container-platform/3.7/operators/understanding/olm/olm-understanding-olm.html">Operator Lifecycle Manager (OLM)</a>. When creating a <code class="literal">Subscription</code> with the default <code class="literal">approvalStrategy: Automatic</code>, OLM will automatically upgrade the Quay Operator whenever a new version becomes available.
			</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
					When the Quay Operator is installed via Operator Lifecycle Manager, it may be configured to support automatic or manual upgrades. This option is shown on the <span class="strong strong"><strong>Operator Hub</strong></span> page for the Quay Operator during installation. It can also be found in the Quay Operator <code class="literal">Subscription</code> object via the <code class="literal">approvalStrategy</code> field. Choosing <code class="literal">Automatic</code> means that your Quay Operator will automatically be upgraded whenever a new Operator version is released. If this is not desirable, then the <code class="literal">Manual</code> approval strategy should be selected.
				</p></div></div></section><section class="section" id="upgrading_the_quay_operator"><div class="titlepage"><div><div><h2 class="title">11.2. Upgrading the Quay Operator</h2></div></div></div><p>
				The standard approach for upgrading installed Operators on OpenShift is documented at <a class="link" href="https://docs.openshift.com/container-platform/4.7/operators/admin/olm-upgrading-operators.html">Upgrading installed Operators</a>.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					In general, Red Hat Quay only supports upgrading from one minor version to the next, for example, 3.4 → 3.5. However, for 3.6, multiple upgrade paths are supported:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							3.3.z → 3.6
						</li><li class="listitem">
							3.4.z → 3.6
						</li><li class="listitem">
							3.5.z → 3.6
						</li></ul></div></div></div><p>
				For users on standalone deployments of Quay wanting to upgrade to 3.6, see the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3.7/html-single/upgrade_red_hat_quay/index#standalone_upgrade">Standalone upgrade</a> guide.
			</p><section class="section" id="upgrading_quay"><div class="titlepage"><div><div><h3 class="title">11.2.1. Upgrading Quay</h3></div></div></div><p>
					To update Quay from one minor version to the next, for example, 3.4 → 3.5, you need to change the update channel for the Quay Operator.
				</p><p>
					For <code class="literal">z</code> stream upgrades, for example, 3.4.2 → 3.4.3, updates are released in the major-minor channel that the user initially selected during install. The procedure to perform a <code class="literal">z</code> stream upgrade depends on the <code class="literal">approvalStrategy</code> as outlined above. If the approval strategy is set to <code class="literal">Automatic</code>, the Quay Operator will upgrade automatically to the newest <code class="literal">z</code> stream. This results in automatic, rolling Quay updates to newer <code class="literal">z</code> streams with little to no downtime. Otherwise, the update must be manually approved before installation can begin.
				</p></section><section class="section" id="upgrade-33-36"><div class="titlepage"><div><div><h3 class="title">11.2.2. Notes on upgrading directly from 3.3.z or 3.4.z to 3.6</h3></div></div></div><section class="section" id="upgrading_with_edge_routing_enabled"><div class="titlepage"><div><div><h4 class="title">11.2.2.1. Upgrading with edge routing enabled</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Previously, when running a 3.3.z version of Red Hat Quay with edge routing enabled, users were unable to upgrade to 3.4.z versions of Red Hat Quay. This has been resolved with the release of Red Hat Quay 3.6.
							</li><li class="listitem"><p class="simpara">
								When upgrading from 3.3.z to 3.6, if <code class="literal">tls.termination</code> is set to <code class="literal">none</code> in your Red Hat Quay 3.3.z deployment, it will change to HTTPS with TLS edge termination and use the default cluster wildcard certificate. For example:
							</p><pre class="programlisting language-yaml">apiVersion: redhatcop.redhat.io/v1alpha1
kind: QuayEcosystem
metadata:
  name: quay33
spec:
  quay:
    imagePullSecretName: redhat-pull-secret
    enableRepoMirroring: true
    image: quay.io/quay/quay:v3.3.4-2
    ...
    externalAccess:
      hostname: quayv33.apps.devcluster.openshift.com
      tls:
        termination: none
    database:
...</pre></li></ul></div></section><section class="section" id="upgrading_with_custom_tls_certificate_key_pairs_without_subject_alternative_names"><div class="titlepage"><div><div><h4 class="title">11.2.2.2. Upgrading with custom TLS certificate/key pairs without Subject Alternative Names</h4></div></div></div><p>
						There is an issue for customers using their own TLS certificate/key pairs without Subject Alternative Names (SANs) when upgrading from Red Hat Quay 3.3.4 to Red Hat Quay 3.6 directly. During the upgrade to Red Hat Quay 3.6, the deployment is blocked, with the error message from the Quay Operator pod logs indicating that the Quay TLS certificate must have SANs.
					</p><p>
						If possible, you should regenerate your TLS certificates with the correct hostname in the SANs. A possible workaround involves defining an environment variable in the <code class="literal">quay-app</code>, <code class="literal">quay-upgrade</code> and <code class="literal">quay-config-editor</code> pods after upgrade to enable CommonName matching:
					</p><pre class="screen"> GODEBUG=x509ignoreCN=0</pre><p>
						The <code class="literal">GODEBUG=x509ignoreCN=0</code> flag enables the legacy behavior of treating the CommonName field on X.509 certificates as a host name when no SANs are present. However, this workaround is not recommended, as it will not persist across a redeployment.
					</p></section><section class="section" id="configuring_clair_v4_when_upgrading_from_3_3_z_or_3_4_z_to_3_6_using_the_quay_operator"><div class="titlepage"><div><div><h4 class="title">11.2.2.3. Configuring Clair v4 when upgrading from 3.3.z or 3.4.z to 3.6 using the Quay Operator</h4></div></div></div><p>
						To set up Clair v4 on a new Red Hat Quay deployment on OpenShift, it is highly recommended to use the Quay Operator. By default, the Quay Operator will install or upgrade a Clair deployment along with your Red Hat Quay deployment and configure Clair security scanning automatically.
					</p><p>
						For instructions on setting up Clair v4 on OpenShift, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_quay/3.7/html-single/manage_red_hat_quay/index#clair-openshift">Setting Up Clair on a Red Hat Quay OpenShift deployment</a>.
					</p></section></section><section class="section" id="changing_the_update_channel_for_an_operator"><div class="titlepage"><div><div><h3 class="title">11.2.3. Changing the update channel for an Operator</h3></div></div></div><p>
					The subscription of an installed Operator specifies an update channel, which is used to track and receive updates for the Operator. To upgrade the Quay Operator to start tracking and receiving updates from a newer channel, change the update channel in the <span class="strong strong"><strong>Subscription</strong></span> tab for the installed Quay Operator. For subscriptions with an <code class="literal">Automatic</code> approval strategy, the upgrade begins automatically and can be monitored on the page that lists the Installed Operators.
				</p></section><section class="section" id="manually_approving_a_pending_operator_upgrade"><div class="titlepage"><div><div><h3 class="title">11.2.4. Manually approving a pending Operator upgrade</h3></div></div></div><p>
					If an installed Operator has the approval strategy in its subscription set to <code class="literal">Manual</code>, when new updates are released in its current update channel, the update must be manually approved before installation can begin. If the Quay Operator has a pending upgrade, this status will be displayed in the list of Installed Operators. In the <code class="literal">Subscription</code> tab for the Quay Operator, you can preview the install plan and review the resources that are listed as available for upgrade. If satisfied, click <code class="literal">Approve</code> and return to the page that lists Installed Operators to monitor the progress of the upgrade.
				</p><p>
					The following image shows the <span class="strong strong"><strong>Subscription</strong></span> tab in the UI, including the update <code class="literal">Channel</code>, the <code class="literal">Approval</code> strategy, the <code class="literal">Upgrade status</code> and the <code class="literal">InstallPlan</code>:
				</p><p>
					<span class="inlinemediaobject"><img src="images/update-channel-approval-strategy.png" alt="Subscription tab including upgrade Channel and Approval strategy"/></span>
				</p><p>
					The list of Installed Operators provides a high-level summary of the current Quay installation:
				</p><p>
					<span class="inlinemediaobject"><img src="images/installed-operators-list.png" alt="Installed Operators"/></span>
				</p></section></section><section class="section" id="upgrading_a_quayregistry"><div class="titlepage"><div><div><h2 class="title">11.3. Upgrading a QuayRegistry</h2></div></div></div><p>
				When the Quay Operator starts, it immediately looks for any <code class="literal">QuayRegistries</code> it can find in the namespace(s) it is configured to watch. When it finds one, the following logic is used:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						If <code class="literal">status.currentVersion</code> is unset, reconcile as normal.
					</li><li class="listitem">
						If <code class="literal">status.currentVersion</code> equals the Operator version, reconcile as normal.
					</li><li class="listitem">
						If <code class="literal">status.currentVersion</code> does not equal the Operator version, check if it can be upgraded. If it can, perform upgrade tasks and set the <code class="literal">status.currentVersion</code> to the Operator’s version once complete. If it cannot be upgraded, return an error and leave the <code class="literal">QuayRegistry</code> and its deployed Kubernetes objects alone.
					</li></ul></div></section><section class="section" id="enabling_features_in_quay_3_6"><div class="titlepage"><div><div><h2 class="title">11.4. Enabling features in Quay 3.6</h2></div></div></div><section class="section" id="console_monitoring_and_alerting"><div class="titlepage"><div><div><h3 class="title">11.4.1. Console monitoring and alerting</h3></div></div></div><p>
					The support for monitoring Quay 3.6 in the OpenShift console requires that the Operator is installed in all namespaces. If you previously installed the Operator in a specific namespace, delete the Operator itself and reinstall it for all namespaces once the upgrade has taken place.
				</p></section><section class="section" id="oci_and_helm_support"><div class="titlepage"><div><div><h3 class="title">11.4.2. OCI and Helm support</h3></div></div></div><p>
					Support for Helm and some OCI artifacts is now enabled by default in Red Hat Quay 3.7. If you want to explicitly enable the feature, for example, if you are upgrading from a version where it is not enabled by default, you need to reconfigure your Quay deployment to enable the use of OCI artifacts using the following properties:
				</p><pre class="programlisting language-yaml">FEATURE_GENERAL_OCI_SUPPORT: true</pre></section></section><section class="section" id="upgrading_a_quayecosystem"><div class="titlepage"><div><div><h2 class="title">11.5. Upgrading a QuayEcosystem</h2></div></div></div><p>
				Upgrades are supported from previous versions of the Operator which used the <code class="literal">QuayEcosystem</code> API for a limited set of configurations. To ensure that migrations do not happen unexpectedly, a special label needs to be applied to the <code class="literal">QuayEcosystem</code> for it to be migrated. A new <code class="literal">QuayRegistry</code> will be created for the Operator to manage, but the old <code class="literal">QuayEcosystem</code> will remain until manually deleted to ensure that you can roll back and still access Quay in case anything goes wrong. To migrate an existing <code class="literal">QuayEcosystem</code> to a new <code class="literal">QuayRegistry</code>, follow these steps:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Add <code class="literal">"quay-operator/migrate": "true"</code> to the <code class="literal">metadata.labels</code> of the <code class="literal">QuayEcosystem</code>.
					</p><pre class="screen">$ oc edit quayecosystem &lt;quayecosystemname&gt;</pre><pre class="programlisting language-yaml">metadata:
  labels:
    quay-operator/migrate: "true"</pre></li><li class="listitem">
						Wait for a <code class="literal">QuayRegistry</code> to be created with the same <code class="literal">metadata.name</code> as your <code class="literal">QuayEcosystem</code>. The <code class="literal">QuayEcosystem</code> will be marked with the label <code class="literal">"quay-operator/migration-complete": "true"</code>.
					</li><li class="listitem">
						Once the <code class="literal">status.registryEndpoint</code> of the new <code class="literal">QuayRegistry</code> is set, access Quay and confirm all data and settings were migrated successfully.
					</li><li class="listitem">
						When you are confident everything worked correctly, you may delete the <code class="literal">QuayEcosystem</code> and Kubernetes garbage collection will clean up all old resources.
					</li></ol></div><section class="section" id="reverting_quayecosystem_upgrade"><div class="titlepage"><div><div><h3 class="title">11.5.1. Reverting QuayEcosystem Upgrade</h3></div></div></div><p>
					If something goes wrong during the automatic upgrade from <code class="literal">QuayEcosystem</code> to <code class="literal">QuayRegistry</code>, follow these steps to revert back to using the <code class="literal">QuayEcosystem</code>:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Delete the <code class="literal">QuayRegistry</code> using either the UI or <code class="literal">kubectl</code>:
						</p><pre class="programlisting language-sh">$ kubectl delete -n &lt;namespace&gt; quayregistry &lt;quayecosystem-name&gt;</pre></li><li class="listitem">
							If external access was provided using a <code class="literal">Route</code>, change the <code class="literal">Route</code> to point back to the original <code class="literal">Service</code> using the UI or <code class="literal">kubectl</code>.
						</li></ol></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						If your <code class="literal">QuayEcosystem</code> was managing the Postgres database, the upgrade process will migrate your data to a new Postgres database managed by the upgraded Operator. Your old database will not be changed or removed but Quay will no longer use it once the migration is complete. If there are issues during the data migration, the upgrade process will exit and it is recommended that you continue with your database as an unmanaged component.
					</p></div></div></section><section class="section" id="supported_quayecosystem_configurations_for_upgrades"><div class="titlepage"><div><div><h3 class="title">11.5.2. Supported QuayEcosystem Configurations for Upgrades</h3></div></div></div><p>
					The Quay Operator will report errors in its logs and in <code class="literal">status.conditions</code> if migrating a <code class="literal">QuayEcosystem</code> component fails or is unsupported. All unmanaged components should migrate successfully because no Kubernetes resources need to be adopted and all the necessary values are already provided in Quay’s <code class="literal">config.yaml</code>.
				</p><p>
					<span class="strong strong"><strong>Database</strong></span>
				</p><p>
					Ephemeral database not supported (<code class="literal">volumeSize</code> field must be set).
				</p><p>
					<span class="strong strong"><strong>Redis</strong></span>
				</p><p>
					Nothing special needed.
				</p><p>
					<span class="strong strong"><strong>External Access</strong></span>
				</p><p>
					Only passthrough <code class="literal">Route</code> access is supported for automatic migration. Manual migration required for other methods.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">LoadBalancer</code> without custom hostname: After the <code class="literal">QuayEcosystem</code> is marked with label <code class="literal">"quay-operator/migration-complete": "true"</code>, delete the <code class="literal">metadata.ownerReferences</code> field from existing <code class="literal">Service</code> <span class="emphasis"><em>before</em></span> deleting the <code class="literal">QuayEcosystem</code> to prevent Kubernetes from garbage collecting the <code class="literal">Service</code> and removing the load balancer. A new <code class="literal">Service</code> will be created with <code class="literal">metadata.name</code> format <code class="literal">&lt;QuayEcosystem-name&gt;-quay-app</code>. Edit the <code class="literal">spec.selector</code> of the existing <code class="literal">Service</code> to match the <code class="literal">spec.selector</code> of the new <code class="literal">Service</code> so traffic to the old load balancer endpoint will now be directed to the new pods. You are now responsible for the old <code class="literal">Service</code>; the Quay Operator will not manage it.
						</li><li class="listitem">
							<code class="literal">LoadBalancer</code>/<code class="literal">NodePort</code>/<code class="literal">Ingress</code> with custom hostname: A new <code class="literal">Service</code> of type <code class="literal">LoadBalancer</code> will be created with <code class="literal">metadata.name</code> format <code class="literal">&lt;QuayEcosystem-name&gt;-quay-app</code>. Change your DNS settings to point to the <code class="literal">status.loadBalancer</code> endpoint provided by the new <code class="literal">Service</code>.
						</li></ul></div><p>
					<span class="strong strong"><strong>Clair</strong></span>
				</p><p>
					Nothing special needed.
				</p><p>
					<span class="strong strong"><strong>Object Storage</strong></span>
				</p><p>
					<code class="literal">QuayEcosystem</code> did not have a managed object storage component, so object storage will always be marked as unmanaged. Local storage is not supported.
				</p><p>
					<span class="strong strong"><strong>Repository Mirroring</strong></span>
				</p><p>
					Nothing special needed.
				</p><h2 id="additional_resources">Additional resources</h2><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							For more details on the Red Hat Quay Operator, see the upstream <a class="link" href="https://github.com/quay/quay-operator/">quay-operator</a> project.
						</li></ul></div></section></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm45308024452896"><h1 class="legalnotice">Legal Notice</h1><div class="para">
		Copyright <span class="trademark"/>© 2022 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></div></div></div><script type="text/javascript">
                        jQuery(document).ready(function() {
                            initSwitchery();
                            jQuery('pre[class*="language-"]').each(function(i, block){hljs.highlightBlock(block);});
                        });
                    </script></body></html>