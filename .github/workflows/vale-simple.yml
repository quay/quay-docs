name: Vale Linting

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  vale:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Vale and AsciiDoctor
        run: |
          # Download and install latest Vale
          VALE_VERSION="3.13.0"
          wget -q "https://github.com/errata-ai/vale/releases/download/v${VALE_VERSION}/vale_${VALE_VERSION}_Linux_64-bit.tar.gz"
          tar -xzf "vale_${VALE_VERSION}_Linux_64-bit.tar.gz" -C /usr/local/bin
          chmod +x /usr/local/bin/vale
          vale --version
          # Install AsciiDoctor (required by AsciiDocDITA package)
          sudo apt-get update -qq
          sudo apt-get install -y -qq ruby-full build-essential
          sudo gem install asciidoctor
          asciidoctor --version

      - name: Sync Vale styles
        run: |
          # Sync Vale styles to download the AsciiDocDITA package
          vale sync || echo "Vale sync completed"

      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v40
        with:
          files: |
            **/*.adoc
            **/*.md

      - name: Verify Vale configuration
        working-directory: ${{ github.workspace }}
        run: |
          echo "Current directory: $(pwd)"
          echo "Checking if .vale.ini exists:"
          ls -la .vale.ini || echo ".vale.ini not found in root"
          echo "Checking Vale version:"
          vale --version
          echo "Checking Vale configuration..."
          vale ls-config || echo "Could not list config"
          echo "Syncing Vale styles (this downloads the package)..."
          vale sync || echo "Vale sync completed (may show warnings)"
          echo "Verifying styles were downloaded:"
          ls -la .vale/styles/ || echo "Styles directory not found"

      - name: Run Vale and post PR comments
        uses: actions/github-script@v7
        if: steps.changed-files.outputs.any_changed == 'true'
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { execSync } = require('child_process');
            const fs = require('fs');
            // Note: 'core' is automatically available in github-script actions
            
            // Get pull request number
            const pullNumber = context.payload.pull_request?.number || context.issue.number;
            const commitId = context.payload.pull_request?.head?.sha;
            const isFork = context.payload.pull_request?.head?.repo?.full_name !== context.payload.pull_request?.base?.repo?.full_name;
            
            console.log(`PR Number: ${pullNumber}, Commit SHA: ${commitId}`);
            console.log(`Is Fork PR: ${isFork}`);
            console.log(`Repository: ${context.repo.owner}/${context.repo.repo}`);
            
            // Check if we can access the PR
            try {
              const prInfo = await github.rest.pulls.get({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: pullNumber
              });
              console.log(`PR title: ${prInfo.data.title}`);
              console.log(`PR state: ${prInfo.data.state}`);
            } catch (error) {
              console.log(`Cannot access PR: ${error.message}`);
              if (isFork) {
                console.log('This is a fork PR. GITHUB_TOKEN has limited permissions on fork PRs.');
                console.log('Consider using a Personal Access Token (PAT) with repo scope for fork PRs.');
              }
            }
            
            // Get changed files
            const changedFiles = `${{ steps.changed-files.outputs.all_changed_files }}`.split(' ').filter(f => f && (f.endsWith('.adoc') || f.endsWith('.md')));
            
            if (changedFiles.length === 0) {
              console.log('No changed files to check');
              return;
            }
            
            console.log(`Checking files: ${changedFiles.join(', ')}`);
            
            // Check if this is a fork PR
            const isFork = context.payload.pull_request?.head?.repo?.full_name !== context.payload.pull_request?.base?.repo?.full_name;
            const pullNumber = context.payload.pull_request?.number || context.issue.number;
            const commitId = context.payload.pull_request?.head?.sha;
            
            console.log(`PR Number: ${pullNumber}, Is Fork: ${isFork}`);
            
            // Run Vale and get JSON output
            // Ensure we're in the workspace directory
            process.chdir(process.env.GITHUB_WORKSPACE || '.');
            
            let valeResults = {};
            try {
              // First try to get output from stdout
              const valeOutput = execSync(`vale --output=JSON ${changedFiles.join(' ')}`, {
                encoding: 'utf-8',
                maxBuffer: 10 * 1024 * 1024,
                stdio: ['pipe', 'pipe', 'pipe']
              });
              if (valeOutput && valeOutput.trim()) {
                valeResults = JSON.parse(valeOutput);
              }
            } catch (error) {
              // Vale returns non-zero exit code when issues are found, but still outputs JSON
              const output = error.stdout || error.stderr || '';
              try {
                if (output && output.trim()) {
                  valeResults = JSON.parse(output);
                }
              } catch (parseError) {
                console.log('Could not parse Vale output as JSON');
                console.log('Raw output:', output);
                console.log('Parse error:', parseError.message);
                return;
              }
            }
            
            
            // Collect ALL issues (process each alert individually)
            let allIssues = [];
            let commentCount = 0;
            
            // Process each file and each alert individually
            for (const [file, alerts] of Object.entries(valeResults)) {
              if (!alerts || alerts.length === 0) continue;
              
              console.log(`\n=== Processing file: ${file} ===`);
              console.log(`Alerts: ${alerts.length}`);
              
              // Ensure file path is relative to repo root (GitHub API requires relative paths)
              let filePath = file;
              const workspace = process.env.GITHUB_WORKSPACE || '.';
              if (filePath.startsWith(workspace)) {
                filePath = filePath.replace(workspace + '/', '');
              } else if (filePath.startsWith('/')) {
                // Absolute path, try to make it relative
                const parts = filePath.split('/');
                filePath = parts.slice(parts.length - 2).join('/'); // Get last 2 parts (e.g., modules/filename.adoc)
              }
              
              // Try to find the actual file path in the repo
              let actualFilePath = filePath;
              try {
                // Check if file exists as-is
                if (!fs.existsSync(filePath)) {
                  // Try to find it in the repo
                  const findResult = execSync(`find . -name "${filePath.split('/').pop()}" -type f | grep -v node_modules | head -1`, { encoding: 'utf-8' });
                  if (findResult.trim()) {
                    actualFilePath = findResult.trim().replace(/^\.\//, '');
                    console.log(`Found file at: ${actualFilePath} (was looking for: ${filePath})`);
                  }
                } else {
                  console.log(`File exists at: ${filePath}`);
                }
              } catch (e) {
                console.log(`Could not verify file path: ${e.message}`);
              }
              
              console.log(`Using file path: ${actualFilePath} (original: ${file})`);
              
              // Process EACH alert individually (don't group by line)
              for (const alert of alerts) {
                const line = alert.Line || 1;
                const severity = alert.Severity || 'warning';
                const check = alert.Check || '';
                const message = alert.Message || '';
                const link = alert.Link ? `\n\n[Learn more](${alert.Link})` : '';
                
                const body = `**${severity}**: ${message}${link}\n\n*Rule: \`${check}\`*`;
                
                // Collect for annotations/fallback
                allIssues.push({
                  file: actualFilePath,
                  line: line,
                  severity: severity,
                  message: message,
                  check: check,
                  body: body
                });
                
                // Try to post comment (only if not a fork PR)
                if (!isFork) {
                  try {
                    await github.rest.pulls.createReviewComment({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      pull_number: pullNumber,
                      commit_id: commitId,
                      path: actualFilePath,
                      line: line,
                      body: body
                    });
                    commentCount++;
                  } catch (error) {
                    console.log(`Error posting comment for ${actualFilePath}:${line}: ${error.message}`);
                  }
                }
              }
            }
            
            console.log(`Total issues found: ${allIssues.length}`);
            console.log(`Posted ${commentCount} comment(s) on the PR`);
            
            // For fork PRs or if comments failed, use workflow annotations
            if (isFork || (commentCount === 0 && allIssues.length > 0)) {
              console.log(`Creating workflow annotations for ${allIssues.length} issue(s)...`);
              
              // Create an annotation for EACH issue individually
              for (const issue of allIssues) {
                if (issue.severity === 'error') {
                  core.error(issue.message, {
                    file: issue.file,
                    startLine: issue.line,
                    endLine: issue.line,
                    title: `Vale: ${issue.check}`
                  });
                } else {
                  core.warning(issue.message, {
                    file: issue.file,
                    startLine: issue.line,
                    endLine: issue.line,
                    title: `Vale: ${issue.check}`
                  });
                }
              }
              
              // Create workflow summary
              let summary = `## ⚠️ Vale Linting Issues Found\n\n`;
              summary += `Found **${allIssues.length} issue(s)** in **${Object.keys(valeResults).length} file(s)**:\n\n`;
              
              // Group by file for summary
              const byFile = {};
              for (const issue of allIssues) {
                if (!byFile[issue.file]) {
                  byFile[issue.file] = [];
                }
                byFile[issue.file].push(issue);
              }
              
              for (const [file, fileIssues] of Object.entries(byFile)) {
                summary += `### \`${file}\`\n\n`;
                for (const issue of fileIssues) {
                  summary += `- **Line ${issue.line}** (${issue.severity}): ${issue.message} - *${issue.check}*\n`;
                }
                summary += `\n`;
              }
              
              if (isFork) {
                summary += `---\n*Note: This is a fork PR. Comments cannot be posted, but all issues are shown in the annotations above.*`;
              } else {
                summary += `---\n*Issues are shown in the annotations above. Comments could not be posted due to permissions.*`;
              }
              
              await core.summary.addRaw(summary).write();
              
              // Fail the workflow to make it visible
              core.setFailed(`Vale found ${allIssues.length} issue(s). See annotations in the Checks tab.`);
            } else if (allIssues.length > 0) {
              console.log(`Successfully posted ${commentCount} comment(s) for ${allIssues.length} issue(s)`);
            }

